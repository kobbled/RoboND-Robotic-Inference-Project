I0810 21:05:18.746016   463 upgrade_proto.cpp:1044] Attempting to upgrade input file specified using deprecated 'solver_type' field (enum)': /opt/DIGITS/digits/jobs/20180810-210516-abe4/solver.prototxt
I0810 21:05:18.746307   463 upgrade_proto.cpp:1051] Successfully upgraded file specified using deprecated 'solver_type' field (enum) to 'type' field (string).
W0810 21:05:18.746318   463 upgrade_proto.cpp:1053] Note that future Caffe releases will only support 'type' field (string) for a solver's type.
I0810 21:05:18.834098   463 caffe.cpp:197] Using GPUs 0
I0810 21:05:18.834493   463 caffe.cpp:202] GPU 0: Tesla K80
I0810 21:05:19.471084   463 solver.cpp:48] Initializing solver from parameters:
test_iter: 53
test_interval: 178
base_lr: 1e-05
display: 22
max_iter: 14240
lr_policy: "step"
gamma: 0.1
momentum: 0.9
weight_decay: 9.9999994e-08
stepsize: 4700
snapshot: 178
snapshot_prefix: "snapshot"
solver_mode: GPU
device_id: 0
net: "train_val.prototxt"
type: "Adam"
I0810 21:05:19.473145   463 solver.cpp:91] Creating training net from net file: train_val.prototxt
I0810 21:05:19.474761   463 net.cpp:323] The NetState phase (0) differed from the phase (1) specified by a rule in layer val_data
I0810 21:05:19.474776   463 net.cpp:323] The NetState phase (0) differed from the phase (1) specified by a rule in layer val_label
I0810 21:05:19.474784   463 net.cpp:323] The NetState phase (0) differed from the phase (1) specified by a rule in layer val_transform
I0810 21:05:19.474846   463 net.cpp:323] The NetState phase (0) differed from the phase (1) specified by a rule in layer cluster
I0810 21:05:19.474856   463 net.cpp:323] The NetState phase (0) differed from the phase (1) specified by a rule in layer cluster_gt
I0810 21:05:19.474861   463 net.cpp:323] The NetState phase (0) differed from the phase (1) specified by a rule in layer score
I0810 21:05:19.474867   463 net.cpp:323] The NetState phase (0) differed from the phase (1) specified by a rule in layer mAP
I0810 21:05:19.475555   463 net.cpp:52] Initializing net from parameters:
state {
phase: TRAIN
}
layer {
name: "train_data"
type: "Data"
top: "data"
include {
phase: TRAIN
}
transform_param {
mean_file: "/opt/DIGITS/digits/jobs/20180810-202617-c692/train_db/mean.binaryproto"
}
data_param {
source: "/opt/DIGITS/digits/jobs/20180810-202617-c692/train_db/features"
batch_size: 10
backend: LMDB
}
}
layer {
name: "train_label"
type: "Data"
top: "label"
include {
phase: TRAIN
}
data_param {
source: "/opt/DIGITS/digits/jobs/20180810-202617-c692/train_db/labels"
batch_size: 10
backend: LMDB
}
}
layer {
name: "train_transform"
type: "DetectNetTransformation"
bottom: "data"
bottom: "label"
top: "transformed_data"
top: "transformed_label"
include {
phase: TRAIN
}
transform_param {
mean_value: 127
}
detectnet_groundtruth_param {
stride: 16
scale_cvg: 0.4
gridbox_type: GRIDBOX_MIN
min_cvg_len: 20
coverage_type: RECTANGULAR
image_size_x: 640
image_size_y: 640
obj_norm: true
crop_bboxes: false
object_class {
src: 1
dst: 0
}
}
detectnet_augmentation_param {
crop_prob: 1
shift_x: 32
shift_y: 32
scale_prob: 0.4
scale_min: 0.8
scale_max: 1.2
flip_prob: 0.5
rotation_prob: 0
max_rotate_degree: 5
hue_rotation_prob: 0.8
hue_rotation: 30
desaturation_prob: 0.8
desaturation_max: 0.8
}
}
layer {
name: "slice-label"
type: "Slice"
bottom: "transformed_label"
top: "foreground-label"
top: "bbox-label"
top: "size-label"
top: "obj-label"
top: "coverage-label"
slice_param {
slice_dim: 1
slice_point: 1
slice_point: 5
slice_point: 7
slice_point: 8
}
}
layer {
name: "coverage-block"
type: "Concat"
bottom: "foreground-label"
bottom: "foreground-label"
bottom: "foreground-label"
bottom: "foreground-label"
top: "coverage-block"
concat_param {
concat_dim: 1
}
}
layer {
name: "size-block"
type: "Concat"
bottom: "size-label"
bottom: "size-label"
top: "size-block"
concat_param {
concat_dim: 1
}
}
layer {
name: "obj-block"
type: "Concat"
bottom: "obj-label"
bottom: "obj-label"
bottom: "obj-label"
bottom: "obj-label"
top: "obj-block"
concat_param {
concat_dim: 1
}
}
layer {
name: "bb-label-norm"
type: "Eltwise"
bottom: "bbox-label"
bottom: "size-block"
top: "bbox-label-norm"
eltwise_param {
operation: PROD
}
}
layer {
name: "bb-obj-norm"
type: "Eltwise"
bottom: "bbox-label-norm"
bottom: "obj-block"
top: "bbox-obj-label-norm"
eltwise_param {
operation: PROD
}
}
layer {
name: "conv1/7x7_s2"
type: "Convolution"
bottom: "transformed_data"
top: "conv1/7x7_s2"
param {
lr_mult: 1
decay_mult: 1
}
param {
lr_mult: 2
decay_mult: 0
}
convolution_param {
num_output: 64
pad: 3
kernel_size: 7
stride: 2
weight_filler {
type: "xavier"
std: 0.1
}
bias_filler {
type: "constant"
value: 0.2
}
}
}
layer {
name: "conv1/relu_7x7"
type: "ReLU"
bottom: "conv1/7x7_s2"
top: "conv1/7x7_s2"
}
layer {
name: "pool1/3x3_s2"
type: "Pooling"
bottom: "conv1/7x7_s2"
top: "pool1/3x3_s2"
pooling_param {
pool: MAX
kernel_size: 3
stride: 2
}
}
layer {
name: "pool1/norm1"
type: "LRN"
bottom: "pool1/3x3_s2"
top: "pool1/norm1"
lrn_param {
local_size: 5
alpha: 0.0001
beta: 0.75
}
}
layer {
name: "conv2/3x3_reduce"
type: "Convolution"
bottom: "pool1/norm1"
top: "conv2/3x3_reduce"
param {
lr_mult: 1
decay_mult: 1
}
param {
lr_mult: 2
decay_mult: 0
}
convolution_param {
num_output: 64
kernel_size: 1
weight_filler {
type: "xavier"
std: 0.1
}
bias_filler {
type: "constant"
value: 0.2
}
}
}
layer {
name: "conv2/relu_3x3_reduce"
type: "ReLU"
bottom: "conv2/3x3_reduce"
top: "conv2/3x3_reduce"
}
layer {
name: "conv2/3x3"
type: "Convolution"
bottom: "conv2/3x3_reduce"
top: "conv2/3x3"
param {
lr_mult: 1
decay_mult: 1
}
param {
lr_mult: 2
decay_mult: 0
}
convolution_param {
num_output: 192
pad: 1
kernel_size: 3
weight_filler {
type: "xavier"
std: 0.03
}
bias_filler {
type: "constant"
value: 0.2
}
}
}
layer {
name: "conv2/relu_3x3"
type: "ReLU"
bottom: "conv2/3x3"
top: "conv2/3x3"
}
layer {
name: "conv2/norm2"
type: "LRN"
bottom: "conv2/3x3"
top: "conv2/norm2"
lrn_param {
local_size: 5
alpha: 0.0001
beta: 0.75
}
}
layer {
name: "pool2/3x3_s2"
type: "Pooling"
bottom: "conv2/norm2"
top: "pool2/3x3_s2"
pooling_param {
pool: MAX
kernel_size: 3
stride: 2
}
}
layer {
name: "inception_3a/1x1"
type: "Convolution"
bottom: "pool2/3x3_s2"
top: "inception_3a/1x1"
param {
lr_mult: 1
decay_mult: 1
}
param {
lr_mult: 2
decay_mult: 0
}
convolution_param {
num_output: 64
kernel_size: 1
weight_filler {
type: "xavier"
std: 0.03
}
bias_filler {
type: "constant"
value: 0.2
}
}
}
layer {
name: "inception_3a/relu_1x1"
type: "ReLU"
bottom: "inception_3a/1x1"
top: "inception_3a/1x1"
}
layer {
name: "inception_3a/3x3_reduce"
type: "Convolution"
bottom: "pool2/3x3_s2"
top: "inception_3a/3x3_reduce"
param {
lr_mult: 1
decay_mult: 1
}
param {
lr_mult: 2
decay_mult: 0
}
convolution_param {
num_output: 96
kernel_size: 1
weight_filler {
type: "xavier"
std: 0.09
}
bias_filler {
type: "constant"
value: 0.2
}
}
}
layer {
name: "inception_3a/relu_3x3_reduce"
type: "ReLU"
bottom: "inception_3a/3x3_reduce"
top: "inception_3a/3x3_reduce"
}
layer {
name: "inception_3a/3x3"
type: "Convolution"
bottom: "inception_3a/3x3_reduce"
top: "inception_3a/3x3"
param {
lr_mult: 1
decay_mult: 1
}
param {
lr_mult: 2
decay_mult: 0
}
convolution_param {
num_output: 128
pad: 1
kernel_size: 3
weight_filler {
type: "xavier"
std: 0.03
}
bias_filler {
type: "constant"
value: 0.2
}
}
}
layer {
name: "inception_3a/relu_3x3"
type: "ReLU"
bottom: "inception_3a/3x3"
top: "inception_3a/3x3"
}
layer {
name: "inception_3a/5x5_reduce"
type: "Convolution"
bottom: "pool2/3x3_s2"
top: "inception_3a/5x5_reduce"
param {
lr_mult: 1
decay_mult: 1
}
param {
lr_mult: 2
decay_mult: 0
}
convolution_param {
num_output: 16
kernel_size: 1
weight_filler {
type: "xavier"
std: 0.2
}
bias_filler {
type: "constant"
value: 0.2
}
}
}
layer {
name: "inception_3a/relu_5x5_reduce"
type: "ReLU"
bottom: "inception_3a/5x5_reduce"
top: "inception_3a/5x5_reduce"
}
layer {
name: "inception_3a/5x5"
type: "Convolution"
bottom: "inception_3a/5x5_reduce"
top: "inception_3a/5x5"
param {
lr_mult: 1
decay_mult: 1
}
param {
lr_mult: 2
decay_mult: 0
}
convolution_param {
num_output: 32
pad: 2
kernel_size: 5
weight_filler {
type: "xavier"
std: 0.03
}
bias_filler {
type: "constant"
value: 0.2
}
}
}
layer {
name: "inception_3a/relu_5x5"
type: "ReLU"
bottom: "inception_3a/5x5"
top: "inception_3a/5x5"
}
layer {
name: "inception_3a/pool"
type: "Pooling"
bottom: "pool2/3x3_s2"
top: "inception_3a/pool"
pooling_param {
pool: MAX
kernel_size: 3
stride: 1
pad: 1
}
}
layer {
name: "inception_3a/pool_proj"
type: "Convolution"
bottom: "inception_3a/pool"
top: "inception_3a/pool_proj"
param {
lr_mult: 1
decay_mult: 1
}
param {
lr_mult: 2
decay_mult: 0
}
convolution_param {
num_output: 32
kernel_size: 1
weight_filler {
type: "xavier"
std: 0.1
}
bias_filler {
type: "constant"
value: 0.2
}
}
}
layer {
name: "inception_3a/relu_pool_proj"
type: "ReLU"
bottom: "inception_3a/pool_proj"
top: "inception_3a/pool_proj"
}
layer {
name: "inception_3a/output"
type: "Concat"
bottom: "inception_3a/1x1"
bottom: "inception_3a/3x3"
bottom: "inception_3a/5x5"
bottom: "inception_3a/pool_proj"
top: "inception_3a/output"
}
layer {
name: "inception_3b/1x1"
type: "Convolution"
bottom: "inception_3a/output"
top: "inception_3b/1x1"
param {
lr_mult: 1
decay_mult: 1
}
param {
lr_mult: 2
decay_mult: 0
}
convolution_param {
num_output: 128
kernel_size: 1
weight_filler {
type: "xavier"
std: 0.03
}
bias_filler {
type: "constant"
value: 0.2
}
}
}
layer {
name: "inception_3b/relu_1x1"
type: "ReLU"
bottom: "inception_3b/1x1"
top: "inception_3b/1x1"
}
layer {
name: "inception_3b/3x3_reduce"
type: "Convolution"
bottom: "inception_3a/output"
top: "inception_3b/3x3_reduce"
param {
lr_mult: 1
decay_mult: 1
}
param {
lr_mult: 2
decay_mult: 0
}
convolution_param {
num_output: 128
kernel_size: 1
weight_filler {
type: "xavier"
std: 0.09
}
bias_filler {
type: "constant"
value: 0.2
}
}
}
layer {
name: "inception_3b/relu_3x3_reduce"
type: "ReLU"
bottom: "inception_3b/3x3_reduce"
top: "inception_3b/3x3_reduce"
}
layer {
name: "inception_3b/3x3"
type: "Convolution"
bottom: "inception_3b/3x3_reduce"
top: "inception_3b/3x3"
param {
lr_mult: 1
decay_mult: 1
}
param {
lr_mult: 2
decay_mult: 0
}
convolution_param {
num_output: 192
pad: 1
kernel_size: 3
weight_filler {
type: "xavier"
std: 0.03
}
bias_filler {
type: "constant"
value: 0.2
}
}
}
layer {
name: "inception_3b/relu_3x3"
type: "ReLU"
bottom: "inception_3b/3x3"
top: "inception_3b/3x3"
}
layer {
name: "inception_3b/5x5_reduce"
type: "Convolution"
bottom: "inception_3a/output"
top: "inception_3b/5x5_reduce"
param {
lr_mult: 1
decay_mult: 1
}
param {
lr_mult: 2
decay_mult: 0
}
convolution_param {
num_output: 32
kernel_size: 1
weight_filler {
type: "xavier"
std: 0.2
}
bias_filler {
type: "constant"
value: 0.2
}
}
}
layer {
name: "inception_3b/relu_5x5_reduce"
type: "ReLU"
bottom: "inception_3b/5x5_reduce"
top: "inception_3b/5x5_reduce"
}
layer {
name: "inception_3b/5x5"
type: "Convolution"
bottom: "inception_3b/5x5_reduce"
top: "inception_3b/5x5"
param {
lr_mult: 1
decay_mult: 1
}
param {
lr_mult: 2
decay_mult: 0
}
convolution_param {
num_output: 96
pad: 2
kernel_size: 5
weight_filler {
type: "xavier"
std: 0.03
}
bias_filler {
type: "constant"
value: 0.2
}
}
}
layer {
name: "inception_3b/relu_5x5"
type: "ReLU"
bottom: "inception_3b/5x5"
top: "inception_3b/5x5"
}
layer {
name: "inception_3b/pool"
type: "Pooling"
bottom: "inception_3a/output"
top: "inception_3b/pool"
pooling_param {
pool: MAX
kernel_size: 3
stride: 1
pad: 1
}
}
layer {
name: "inception_3b/pool_proj"
type: "Convolution"
bottom: "inception_3b/pool"
top: "inception_3b/pool_proj"
param {
lr_mult: 1
decay_mult: 1
}
param {
lr_mult: 2
decay_mult: 0
}
convolution_param {
num_output: 64
kernel_size: 1
weight_filler {
type: "xavier"
std: 0.1
}
bias_filler {
type: "constant"
value: 0.2
}
}
}
layer {
name: "inception_3b/relu_pool_proj"
type: "ReLU"
bottom: "inception_3b/pool_proj"
top: "inception_3b/pool_proj"
}
layer {
name: "inception_3b/output"
type: "Concat"
bottom: "inception_3b/1x1"
bottom: "inception_3b/3x3"
bottom: "inception_3b/5x5"
bottom: "inception_3b/pool_proj"
top: "inception_3b/output"
}
layer {
name: "pool3/3x3_s2"
type: "Pooling"
bottom: "inception_3b/output"
top: "pool3/3x3_s2"
pooling_param {
pool: MAX
kernel_size: 3
stride: 2
}
}
layer {
name: "inception_4a/1x1"
type: "Convolution"
bottom: "pool3/3x3_s2"
top: "inception_4a/1x1"
param {
lr_mult: 1
decay_mult: 1
}
param {
lr_mult: 2
decay_mult: 0
}
convolution_param {
num_output: 192
kernel_size: 1
weight_filler {
type: "xavier"
std: 0.03
}
bias_filler {
type: "constant"
value: 0.2
}
}
}
layer {
name: "inception_4a/relu_1x1"
type: "ReLU"
bottom: "inception_4a/1x1"
top: "inception_4a/1x1"
}
layer {
name: "inception_4a/3x3_reduce"
type: "Convolution"
bottom: "pool3/3x3_s2"
top: "inception_4a/3x3_reduce"
param {
lr_mult: 1
decay_mult: 1
}
param {
lr_mult: 2
decay_mult: 0
}
convolution_param {
num_output: 96
kernel_size: 1
weight_filler {
type: "xavier"
std: 0.09
}
bias_filler {
type: "constant"
value: 0.2
}
}
}
layer {
name: "inception_4a/relu_3x3_reduce"
type: "ReLU"
bottom: "inception_4a/3x3_reduce"
top: "inception_4a/3x3_reduce"
}
layer {
name: "inception_4a/3x3"
type: "Convolution"
bottom: "inception_4a/3x3_reduce"
top: "inception_4a/3x3"
param {
lr_mult: 1
decay_mult: 1
}
param {
lr_mult: 2
decay_mult: 0
}
convolution_param {
num_output: 208
pad: 1
kernel_size: 3
weight_filler {
type: "xavier"
std: 0.03
}
bias_filler {
type: "constant"
value: 0.2
}
}
}
layer {
name: "inception_4a/relu_3x3"
type: "ReLU"
bottom: "inception_4a/3x3"
top: "inception_4a/3x3"
}
layer {
name: "inception_4a/5x5_reduce"
type: "Convolution"
bottom: "pool3/3x3_s2"
top: "inception_4a/5x5_reduce"
param {
lr_mult: 1
decay_mult: 1
}
param {
lr_mult: 2
decay_mult: 0
}
convolution_param {
num_output: 16
kernel_size: 1
weight_filler {
type: "xavier"
std: 0.2
}
bias_filler {
type: "constant"
value: 0.2
}
}
}
layer {
name: "inception_4a/relu_5x5_reduce"
type: "ReLU"
bottom: "inception_4a/5x5_reduce"
top: "inception_4a/5x5_reduce"
}
layer {
name: "inception_4a/5x5"
type: "Convolution"
bottom: "inception_4a/5x5_reduce"
top: "inception_4a/5x5"
param {
lr_mult: 1
decay_mult: 1
}
param {
lr_mult: 2
decay_mult: 0
}
convolution_param {
num_output: 48
pad: 2
kernel_size: 5
weight_filler {
type: "xavier"
std: 0.03
}
bias_filler {
type: "constant"
value: 0.2
}
}
}
layer {
name: "inception_4a/relu_5x5"
type: "ReLU"
bottom: "inception_4a/5x5"
top: "inception_4a/5x5"
}
layer {
name: "inception_4a/pool"
type: "Pooling"
bottom: "pool3/3x3_s2"
top: "inception_4a/pool"
pooling_param {
pool: MAX
kernel_size: 3
stride: 1
pad: 1
}
}
layer {
name: "inception_4a/pool_proj"
type: "Convolution"
bottom: "inception_4a/pool"
top: "inception_4a/pool_proj"
param {
lr_mult: 1
decay_mult: 1
}
param {
lr_mult: 2
decay_mult: 0
}
convolution_param {
num_output: 64
kernel_size: 1
weight_filler {
type: "xavier"
std: 0.1
}
bias_filler {
type: "constant"
value: 0.2
}
}
}
layer {
name: "inception_4a/relu_pool_proj"
type: "ReLU"
bottom: "inception_4a/pool_proj"
top: "inception_4a/pool_proj"
}
layer {
name: "inception_4a/output"
type: "Concat"
bottom: "inception_4a/1x1"
bottom: "inception_4a/3x3"
bottom: "inception_4a/5x5"
bottom: "inception_4a/pool_proj"
top: "inception_4a/output"
}
layer {
name: "inception_4b/1x1"
type: "Convolution"
bottom: "inception_4a/output"
top: "inception_4b/1x1"
param {
lr_mult: 1
decay_mult: 1
}
param {
lr_mult: 2
decay_mult: 0
}
convolution_param {
num_output: 160
kernel_size: 1
weight_filler {
type: "xavier"
std: 0.03
}
bias_filler {
type: "constant"
value: 0.2
}
}
}
layer {
name: "inception_4b/relu_1x1"
type: "ReLU"
bottom: "inception_4b/1x1"
top: "inception_4b/1x1"
}
layer {
name: "inception_4b/3x3_reduce"
type: "Convolution"
bottom: "inception_4a/output"
top: "inception_4b/3x3_reduce"
param {
lr_mult: 1
decay_mult: 1
}
param {
lr_mult: 2
decay_mult: 0
}
convolution_param {
num_output: 112
kernel_size: 1
weight_filler {
type: "xavier"
std: 0.09
}
bias_filler {
type: "constant"
value: 0.2
}
}
}
layer {
name: "inception_4b/relu_3x3_reduce"
type: "ReLU"
bottom: "inception_4b/3x3_reduce"
top: "inception_4b/3x3_reduce"
}
layer {
name: "inception_4b/3x3"
type: "Convolution"
bottom: "inception_4b/3x3_reduce"
top: "inception_4b/3x3"
param {
lr_mult: 1
decay_mult: 1
}
param {
lr_mult: 2
decay_mult: 0
}
convolution_param {
num_output: 224
pad: 1
kernel_size: 3
weight_filler {
type: "xavier"
std: 0.03
}
bias_filler {
type: "constant"
value: 0.2
}
}
}
layer {
name: "inception_4b/relu_3x3"
type: "ReLU"
bottom: "inception_4b/3x3"
top: "inception_4b/3x3"
}
layer {
name: "inception_4b/5x5_reduce"
type: "Convolution"
bottom: "inception_4a/output"
top: "inception_4b/5x5_reduce"
param {
lr_mult: 1
decay_mult: 1
}
param {
lr_mult: 2
decay_mult: 0
}
convolution_param {
num_output: 24
kernel_size: 1
weight_filler {
type: "xavier"
std: 0.2
}
bias_filler {
type: "constant"
value: 0.2
}
}
}
layer {
name: "inception_4b/relu_5x5_reduce"
type: "ReLU"
bottom: "inception_4b/5x5_reduce"
top: "inception_4b/5x5_reduce"
}
layer {
name: "inception_4b/5x5"
type: "Convolution"
bottom: "inception_4b/5x5_reduce"
top: "inception_4b/5x5"
param {
lr_mult: 1
decay_mult: 1
}
param {
lr_mult: 2
decay_mult: 0
}
convolution_param {
num_output: 64
pad: 2
kernel_size: 5
weight_filler {
type: "xavier"
std: 0.03
}
bias_filler {
type: "constant"
value: 0.2
}
}
}
layer {
name: "inception_4b/relu_5x5"
type: "ReLU"
bottom: "inception_4b/5x5"
top: "inception_4b/5x5"
}
layer {
name: "inception_4b/pool"
type: "Pooling"
bottom: "inception_4a/output"
top: "inception_4b/pool"
pooling_param {
pool: MAX
kernel_size: 3
stride: 1
pad: 1
}
}
layer {
name: "inception_4b/pool_proj"
type: "Convolution"
bottom: "inception_4b/pool"
top: "inception_4b/pool_proj"
param {
lr_mult: 1
decay_mult: 1
}
param {
lr_mult: 2
decay_mult: 0
}
convolution_param {
num_output: 64
kernel_size: 1
weight_filler {
type: "xavier"
std: 0.1
}
bias_filler {
type: "constant"
value: 0.2
}
}
}
layer {
name: "inception_4b/relu_pool_proj"
type: "ReLU"
bottom: "inception_4b/pool_proj"
top: "inception_4b/pool_proj"
}
layer {
name: "inception_4b/output"
type: "Concat"
bottom: "inception_4b/1x1"
bottom: "inception_4b/3x3"
bottom: "inception_4b/5x5"
bottom: "inception_4b/pool_proj"
top: "inception_4b/output"
}
layer {
name: "inception_4c/1x1"
type: "Convolution"
bottom: "inception_4b/output"
top: "inception_4c/1x1"
param {
lr_mult: 1
decay_mult: 1
}
param {
lr_mult: 2
decay_mult: 0
}
convolution_param {
num_output: 128
kernel_size: 1
weight_filler {
type: "xavier"
std: 0.03
}
bias_filler {
type: "constant"
value: 0.2
}
}
}
layer {
name: "inception_4c/relu_1x1"
type: "ReLU"
bottom: "inception_4c/1x1"
top: "inception_4c/1x1"
}
layer {
name: "inception_4c/3x3_reduce"
type: "Convolution"
bottom: "inception_4b/output"
top: "inception_4c/3x3_reduce"
param {
lr_mult: 1
decay_mult: 1
}
param {
lr_mult: 2
decay_mult: 0
}
convolution_param {
num_output: 128
kernel_size: 1
weight_filler {
type: "xavier"
std: 0.09
}
bias_filler {
type: "constant"
value: 0.2
}
}
}
layer {
name: "inception_4c/relu_3x3_reduce"
type: "ReLU"
bottom: "inception_4c/3x3_reduce"
top: "inception_4c/3x3_reduce"
}
layer {
name: "inception_4c/3x3"
type: "Convolution"
bottom: "inception_4c/3x3_reduce"
top: "inception_4c/3x3"
param {
lr_mult: 1
decay_mult: 1
}
param {
lr_mult: 2
decay_mult: 0
}
convolution_param {
num_output: 256
pad: 1
kernel_size: 3
weight_filler {
type: "xavier"
std: 0.03
}
bias_filler {
type: "constant"
value: 0.2
}
}
}
layer {
name: "inception_4c/relu_3x3"
type: "ReLU"
bottom: "inception_4c/3x3"
top: "inception_4c/3x3"
}
layer {
name: "inception_4c/5x5_reduce"
type: "Convolution"
bottom: "inception_4b/output"
top: "inception_4c/5x5_reduce"
param {
lr_mult: 1
decay_mult: 1
}
param {
lr_mult: 2
decay_mult: 0
}
convolution_param {
num_output: 24
kernel_size: 1
weight_filler {
type: "xavier"
std: 0.2
}
bias_filler {
type: "constant"
value: 0.2
}
}
}
layer {
name: "inception_4c/relu_5x5_reduce"
type: "ReLU"
bottom: "inception_4c/5x5_reduce"
top: "inception_4c/5x5_reduce"
}
layer {
name: "inception_4c/5x5"
type: "Convolution"
bottom: "inception_4c/5x5_reduce"
top: "inception_4c/5x5"
param {
lr_mult: 1
decay_mult: 1
}
param {
lr_mult: 2
decay_mult: 0
}
convolution_param {
num_output: 64
pad: 2
kernel_size: 5
weight_filler {
type: "xavier"
std: 0.03
}
bias_filler {
type: "constant"
value: 0.2
}
}
}
layer {
name: "inception_4c/relu_5x5"
type: "ReLU"
bottom: "inception_4c/5x5"
top: "inception_4c/5x5"
}
layer {
name: "inception_4c/pool"
type: "Pooling"
bottom: "inception_4b/output"
top: "inception_4c/pool"
pooling_param {
pool: MAX
kernel_size: 3
stride: 1
pad: 1
}
}
layer {
name: "inception_4c/pool_proj"
type: "Convolution"
bottom: "inception_4c/pool"
top: "inception_4c/pool_proj"
param {
lr_mult: 1
decay_mult: 1
}
param {
lr_mult: 2
decay_mult: 0
}
convolution_param {
num_output: 64
kernel_size: 1
weight_filler {
type: "xavier"
std: 0.1
}
bias_filler {
type: "constant"
value: 0.2
}
}
}
layer {
name: "inception_4c/relu_pool_proj"
type: "ReLU"
bottom: "inception_4c/pool_proj"
top: "inception_4c/pool_proj"
}
layer {
name: "inception_4c/output"
type: "Concat"
bottom: "inception_4c/1x1"
bottom: "inception_4c/3x3"
bottom: "inception_4c/5x5"
bottom: "inception_4c/pool_proj"
top: "inception_4c/output"
}
layer {
name: "inception_4d/1x1"
type: "Convolution"
bottom: "inception_4c/output"
top: "inception_4d/1x1"
param {
lr_mult: 1
decay_mult: 1
}
param {
lr_mult: 2
decay_mult: 0
}
convolution_param {
num_output: 112
kernel_size: 1
weight_filler {
type: "xavier"
std: 0.1
}
bias_filler {
type: "constant"
value: 0.2
}
}
}
layer {
name: "inception_4d/relu_1x1"
type: "ReLU"
bottom: "inception_4d/1x1"
top: "inception_4d/1x1"
}
layer {
name: "inception_4d/3x3_reduce"
type: "Convolution"
bottom: "inception_4c/output"
top: "inception_4d/3x3_reduce"
param {
lr_mult: 1
decay_mult: 1
}
param {
lr_mult: 2
decay_mult: 0
}
convolution_param {
num_output: 144
kernel_size: 1
weight_filler {
type: "xavier"
std: 0.1
}
bias_filler {
type: "constant"
value: 0.2
}
}
}
layer {
name: "inception_4d/relu_3x3_reduce"
type: "ReLU"
bottom: "inception_4d/3x3_reduce"
top: "inception_4d/3x3_reduce"
}
layer {
name: "inception_4d/3x3"
type: "Convolution"
bottom: "inception_4d/3x3_reduce"
top: "inception_4d/3x3"
param {
lr_mult: 1
decay_mult: 1
}
param {
lr_mult: 2
decay_mult: 0
}
convolution_param {
num_output: 288
pad: 1
kernel_size: 3
weight_filler {
type: "xavier"
std: 0.1
}
bias_filler {
type: "constant"
value: 0.2
}
}
}
layer {
name: "inception_4d/relu_3x3"
type: "ReLU"
bottom: "inception_4d/3x3"
top: "inception_4d/3x3"
}
layer {
name: "inception_4d/5x5_reduce"
type: "Convolution"
bottom: "inception_4c/output"
top: "inception_4d/5x5_reduce"
param {
lr_mult: 1
decay_mult: 1
}
param {
lr_mult: 2
decay_mult: 0
}
convolution_param {
num_output: 32
kernel_size: 1
weight_filler {
type: "xavier"
std: 0.1
}
bias_filler {
type: "constant"
value: 0.2
}
}
}
layer {
name: "inception_4d/relu_5x5_reduce"
type: "ReLU"
bottom: "inception_4d/5x5_reduce"
top: "inception_4d/5x5_reduce"
}
layer {
name: "inception_4d/5x5"
type: "Convolution"
bottom: "inception_4d/5x5_reduce"
top: "inception_4d/5x5"
param {
lr_mult: 1
decay_mult: 1
}
param {
lr_mult: 2
decay_mult: 0
}
convolution_param {
num_output: 64
pad: 2
kernel_size: 5
weight_filler {
type: "xavier"
std: 0.1
}
bias_filler {
type: "constant"
value: 0.2
}
}
}
layer {
name: "inception_4d/relu_5x5"
type: "ReLU"
bottom: "inception_4d/5x5"
top: "inception_4d/5x5"
}
layer {
name: "inception_4d/pool"
type: "Pooling"
bottom: "inception_4c/output"
top: "inception_4d/pool"
pooling_param {
pool: MAX
kernel_size: 3
stride: 1
pad: 1
}
}
layer {
name: "inception_4d/pool_proj"
type: "Convolution"
bottom: "inception_4d/pool"
top: "inception_4d/pool_proj"
param {
lr_mult: 1
decay_mult: 1
}
param {
lr_mult: 2
decay_mult: 0
}
convolution_param {
num_output: 64
kernel_size: 1
weight_filler {
type: "xavier"
std: 0.1
}
bias_filler {
type: "constant"
value: 0.2
}
}
}
layer {
name: "inception_4d/relu_pool_proj"
type: "ReLU"
bottom: "inception_4d/pool_proj"
top: "inception_4d/pool_proj"
}
layer {
name: "inception_4d/output"
type: "Concat"
bottom: "inception_4d/1x1"
bottom: "inception_4d/3x3"
bottom: "inception_4d/5x5"
bottom: "inception_4d/pool_proj"
top: "inception_4d/output"
}
layer {
name: "inception_4e/1x1"
type: "Convolution"
bottom: "inception_4d/output"
top: "inception_4e/1x1"
param {
lr_mult: 1
decay_mult: 1
}
param {
lr_mult: 2
decay_mult: 0
}
convolution_param {
num_output: 256
kernel_size: 1
weight_filler {
type: "xavier"
std: 0.03
}
bias_filler {
type: "constant"
value: 0.2
}
}
}
layer {
name: "inception_4e/relu_1x1"
type: "ReLU"
bottom: "inception_4e/1x1"
top: "inception_4e/1x1"
}
layer {
name: "inception_4e/3x3_reduce"
type: "Convolution"
bottom: "inception_4d/output"
top: "inception_4e/3x3_reduce"
param {
lr_mult: 1
decay_mult: 1
}
param {
lr_mult: 2
decay_mult: 0
}
convolution_param {
num_output: 160
kernel_size: 1
weight_filler {
type: "xavier"
std: 0.09
}
bias_filler {
type: "constant"
value: 0.2
}
}
}
layer {
name: "inception_4e/relu_3x3_reduce"
type: "ReLU"
bottom: "inception_4e/3x3_reduce"
top: "inception_4e/3x3_reduce"
}
layer {
name: "inception_4e/3x3"
type: "Convolution"
bottom: "inception_4e/3x3_reduce"
top: "inception_4e/3x3"
param {
lr_mult: 1
decay_mult: 1
}
param {
lr_mult: 2
decay_mult: 0
}
convolution_param {
num_output: 320
pad: 1
kernel_size: 3
weight_filler {
type: "xavier"
std: 0.03
}
bias_filler {
type: "constant"
value: 0.2
}
}
}
layer {
name: "inception_4e/relu_3x3"
type: "ReLU"
bottom: "inception_4e/3x3"
top: "inception_4e/3x3"
}
layer {
name: "inception_4e/5x5_reduce"
type: "Convolution"
bottom: "inception_4d/output"
top: "inception_4e/5x5_reduce"
param {
lr_mult: 1
decay_mult: 1
}
param {
lr_mult: 2
decay_mult: 0
}
convolution_param {
num_output: 32
kernel_size: 1
weight_filler {
type: "xavier"
std: 0.2
}
bias_filler {
type: "constant"
value: 0.2
}
}
}
layer {
name: "inception_4e/relu_5x5_reduce"
type: "ReLU"
bottom: "inception_4e/5x5_reduce"
top: "inception_4e/5x5_reduce"
}
layer {
name: "inception_4e/5x5"
type: "Convolution"
bottom: "inception_4e/5x5_reduce"
top: "inception_4e/5x5"
param {
lr_mult: 1
decay_mult: 1
}
param {
lr_mult: 2
decay_mult: 0
}
convolution_param {
num_output: 128
pad: 2
kernel_size: 5
weight_filler {
type: "xavier"
std: 0.03
}
bias_filler {
type: "constant"
value: 0.2
}
}
}
layer {
name: "inception_4e/relu_5x5"
type: "ReLU"
bottom: "inception_4e/5x5"
top: "inception_4e/5x5"
}
layer {
name: "inception_4e/pool"
type: "Pooling"
bottom: "inception_4d/output"
top: "inception_4e/pool"
pooling_param {
pool: MAX
kernel_size: 3
stride: 1
pad: 1
}
}
layer {
name: "inception_4e/pool_proj"
type: "Convolution"
bottom: "inception_4e/pool"
top: "inception_4e/pool_proj"
param {
lr_mult: 1
decay_mult: 1
}
param {
lr_mult: 2
decay_mult: 0
}
convolution_param {
num_output: 128
kernel_size: 1
weight_filler {
type: "xavier"
std: 0.1
}
bias_filler {
type: "constant"
value: 0.2
}
}
}
layer {
name: "inception_4e/relu_pool_proj
I0810 21:05:19.476239   463 layer_factory.hpp:77] Creating layer train_data
I0810 21:05:19.476872   463 net.cpp:94] Creating Layer train_data
I0810 21:05:19.476929   463 net.cpp:409] train_data -> data
I0810 21:05:19.476974   463 data_transformer.cpp:25] Loading mean file from: /opt/DIGITS/digits/jobs/20180810-202617-c692/train_db/mean.binaryproto
I0810 21:05:19.477689   466 db_lmdb.cpp:35] Opened lmdb /opt/DIGITS/digits/jobs/20180810-202617-c692/train_db/features
I0810 21:05:19.560465   463 data_layer.cpp:78] ReshapePrefetch 10, 3, 679, 1124
I0810 21:05:19.560537   463 data_layer.cpp:83] output data size: 10,3,679,1124
I0810 21:05:19.761507   463 net.cpp:144] Setting up train_data
I0810 21:05:19.761546   463 net.cpp:151] Top shape: 10 3 679 1124 (22895880)
I0810 21:05:19.761554   463 net.cpp:159] Memory required for data: 91583520
I0810 21:05:19.761569   463 layer_factory.hpp:77] Creating layer train_label
I0810 21:05:19.762507   463 net.cpp:94] Creating Layer train_label
I0810 21:05:19.762564   463 net.cpp:409] train_label -> label
I0810 21:05:19.763800   472 db_lmdb.cpp:35] Opened lmdb /opt/DIGITS/digits/jobs/20180810-202617-c692/train_db/labels
I0810 21:05:19.764037   463 data_layer.cpp:78] ReshapePrefetch 10, 1, 4, 16
I0810 21:05:19.764113   463 data_layer.cpp:83] output data size: 10,1,4,16
I0810 21:05:19.765442   463 net.cpp:144] Setting up train_label
I0810 21:05:19.765465   463 net.cpp:151] Top shape: 10 1 4 16 (640)
I0810 21:05:19.765471   463 net.cpp:159] Memory required for data: 91586080
I0810 21:05:19.765480   463 layer_factory.hpp:77] Creating layer train_transform
I0810 21:05:19.765625   463 net.cpp:94] Creating Layer train_transform
I0810 21:05:19.765646   463 net.cpp:435] train_transform <- data
I0810 21:05:19.765663   463 net.cpp:435] train_transform <- label
I0810 21:05:19.765676   463 net.cpp:409] train_transform -> transformed_data
I0810 21:05:19.765702   463 net.cpp:409] train_transform -> transformed_label
I0810 21:05:19.766207   463 net.cpp:144] Setting up train_transform
I0810 21:05:19.766223   463 net.cpp:151] Top shape: 10 3 640 640 (12288000)
I0810 21:05:19.766232   463 net.cpp:151] Top shape: 10 9 40 40 (144000)
I0810 21:05:19.766237   463 net.cpp:159] Memory required for data: 141314080
I0810 21:05:19.766244   463 layer_factory.hpp:77] Creating layer slice-label
I0810 21:05:19.766273   463 net.cpp:94] Creating Layer slice-label
I0810 21:05:19.766280   463 net.cpp:435] slice-label <- transformed_label
I0810 21:05:19.766293   463 net.cpp:409] slice-label -> foreground-label
I0810 21:05:19.766309   463 net.cpp:409] slice-label -> bbox-label
I0810 21:05:19.766317   463 net.cpp:409] slice-label -> size-label
I0810 21:05:19.766326   463 net.cpp:409] slice-label -> obj-label
I0810 21:05:19.766335   463 net.cpp:409] slice-label -> coverage-label
I0810 21:05:19.766412   463 net.cpp:144] Setting up slice-label
I0810 21:05:19.766422   463 net.cpp:151] Top shape: 10 1 40 40 (16000)
I0810 21:05:19.766428   463 net.cpp:151] Top shape: 10 4 40 40 (64000)
I0810 21:05:19.766435   463 net.cpp:151] Top shape: 10 2 40 40 (32000)
I0810 21:05:19.766441   463 net.cpp:151] Top shape: 10 1 40 40 (16000)
I0810 21:05:19.766448   463 net.cpp:151] Top shape: 10 1 40 40 (16000)
I0810 21:05:19.766454   463 net.cpp:159] Memory required for data: 141890080
I0810 21:05:19.766460   463 layer_factory.hpp:77] Creating layer foreground-label_slice-label_0_split
I0810 21:05:19.766472   463 net.cpp:94] Creating Layer foreground-label_slice-label_0_split
I0810 21:05:19.766479   463 net.cpp:435] foreground-label_slice-label_0_split <- foreground-label
I0810 21:05:19.766487   463 net.cpp:409] foreground-label_slice-label_0_split -> foreground-label_slice-label_0_split_0
I0810 21:05:19.766497   463 net.cpp:409] foreground-label_slice-label_0_split -> foreground-label_slice-label_0_split_1
I0810 21:05:19.766508   463 net.cpp:409] foreground-label_slice-label_0_split -> foreground-label_slice-label_0_split_2
I0810 21:05:19.766517   463 net.cpp:409] foreground-label_slice-label_0_split -> foreground-label_slice-label_0_split_3
I0810 21:05:19.766571   463 net.cpp:144] Setting up foreground-label_slice-label_0_split
I0810 21:05:19.766580   463 net.cpp:151] Top shape: 10 1 40 40 (16000)
I0810 21:05:19.766587   463 net.cpp:151] Top shape: 10 1 40 40 (16000)
I0810 21:05:19.766594   463 net.cpp:151] Top shape: 10 1 40 40 (16000)
I0810 21:05:19.766602   463 net.cpp:151] Top shape: 10 1 40 40 (16000)
I0810 21:05:19.766607   463 net.cpp:159] Memory required for data: 142146080
I0810 21:05:19.766613   463 layer_factory.hpp:77] Creating layer size-label_slice-label_2_split
I0810 21:05:19.766621   463 net.cpp:94] Creating Layer size-label_slice-label_2_split
I0810 21:05:19.766628   463 net.cpp:435] size-label_slice-label_2_split <- size-label
I0810 21:05:19.766636   463 net.cpp:409] size-label_slice-label_2_split -> size-label_slice-label_2_split_0
I0810 21:05:19.766646   463 net.cpp:409] size-label_slice-label_2_split -> size-label_slice-label_2_split_1
I0810 21:05:19.766682   463 net.cpp:144] Setting up size-label_slice-label_2_split
I0810 21:05:19.766719   463 net.cpp:151] Top shape: 10 2 40 40 (32000)
I0810 21:05:19.766726   463 net.cpp:151] Top shape: 10 2 40 40 (32000)
I0810 21:05:19.766732   463 net.cpp:159] Memory required for data: 142402080
I0810 21:05:19.766738   463 layer_factory.hpp:77] Creating layer obj-label_slice-label_3_split
I0810 21:05:19.766748   463 net.cpp:94] Creating Layer obj-label_slice-label_3_split
I0810 21:05:19.766755   463 net.cpp:435] obj-label_slice-label_3_split <- obj-label
I0810 21:05:19.766765   463 net.cpp:409] obj-label_slice-label_3_split -> obj-label_slice-label_3_split_0
I0810 21:05:19.766777   463 net.cpp:409] obj-label_slice-label_3_split -> obj-label_slice-label_3_split_1
I0810 21:05:19.766788   463 net.cpp:409] obj-label_slice-label_3_split -> obj-label_slice-label_3_split_2
I0810 21:05:19.766798   463 net.cpp:409] obj-label_slice-label_3_split -> obj-label_slice-label_3_split_3
I0810 21:05:19.767248   463 net.cpp:144] Setting up obj-label_slice-label_3_split
I0810 21:05:19.767273   463 net.cpp:151] Top shape: 10 1 40 40 (16000)
I0810 21:05:19.767282   463 net.cpp:151] Top shape: 10 1 40 40 (16000)
I0810 21:05:19.767289   463 net.cpp:151] Top shape: 10 1 40 40 (16000)
I0810 21:05:19.767297   463 net.cpp:151] Top shape: 10 1 40 40 (16000)
I0810 21:05:19.767302   463 net.cpp:159] Memory required for data: 142658080
I0810 21:05:19.767309   463 layer_factory.hpp:77] Creating layer coverage-block
I0810 21:05:19.767328   463 net.cpp:94] Creating Layer coverage-block
I0810 21:05:19.767334   463 net.cpp:435] coverage-block <- foreground-label_slice-label_0_split_0
I0810 21:05:19.767343   463 net.cpp:435] coverage-block <- foreground-label_slice-label_0_split_1
I0810 21:05:19.767352   463 net.cpp:435] coverage-block <- foreground-label_slice-label_0_split_2
I0810 21:05:19.767359   463 net.cpp:435] coverage-block <- foreground-label_slice-label_0_split_3
I0810 21:05:19.767369   463 net.cpp:409] coverage-block -> coverage-block
I0810 21:05:19.767418   463 net.cpp:144] Setting up coverage-block
I0810 21:05:19.767428   463 net.cpp:151] Top shape: 10 4 40 40 (64000)
I0810 21:05:19.767436   463 net.cpp:159] Memory required for data: 142914080
I0810 21:05:19.767443   463 layer_factory.hpp:77] Creating layer size-block
I0810 21:05:19.767453   463 net.cpp:94] Creating Layer size-block
I0810 21:05:19.767460   463 net.cpp:435] size-block <- size-label_slice-label_2_split_0
I0810 21:05:19.767468   463 net.cpp:435] size-block <- size-label_slice-label_2_split_1
I0810 21:05:19.767477   463 net.cpp:409] size-block -> size-block
I0810 21:05:19.767506   463 net.cpp:144] Setting up size-block
I0810 21:05:19.767515   463 net.cpp:151] Top shape: 10 4 40 40 (64000)
I0810 21:05:19.767521   463 net.cpp:159] Memory required for data: 143170080
I0810 21:05:19.767530   463 layer_factory.hpp:77] Creating layer size-block_size-block_0_split
I0810 21:05:19.767554   463 net.cpp:94] Creating Layer size-block_size-block_0_split
I0810 21:05:19.767560   463 net.cpp:435] size-block_size-block_0_split <- size-block
I0810 21:05:19.767570   463 net.cpp:409] size-block_size-block_0_split -> size-block_size-block_0_split_0
I0810 21:05:19.767580   463 net.cpp:409] size-block_size-block_0_split -> size-block_size-block_0_split_1
I0810 21:05:19.767617   463 net.cpp:144] Setting up size-block_size-block_0_split
I0810 21:05:19.767627   463 net.cpp:151] Top shape: 10 4 40 40 (64000)
I0810 21:05:19.767633   463 net.cpp:151] Top shape: 10 4 40 40 (64000)
I0810 21:05:19.767639   463 net.cpp:159] Memory required for data: 143682080
I0810 21:05:19.767645   463 layer_factory.hpp:77] Creating layer obj-block
I0810 21:05:19.767678   463 net.cpp:94] Creating Layer obj-block
I0810 21:05:19.767685   463 net.cpp:435] obj-block <- obj-label_slice-label_3_split_0
I0810 21:05:19.767693   463 net.cpp:435] obj-block <- obj-label_slice-label_3_split_1
I0810 21:05:19.767700   463 net.cpp:435] obj-block <- obj-label_slice-label_3_split_2
I0810 21:05:19.767707   463 net.cpp:435] obj-block <- obj-label_slice-label_3_split_3
I0810 21:05:19.767715   463 net.cpp:409] obj-block -> obj-block
I0810 21:05:19.767758   463 net.cpp:144] Setting up obj-block
I0810 21:05:19.767771   463 net.cpp:151] Top shape: 10 4 40 40 (64000)
I0810 21:05:19.767778   463 net.cpp:159] Memory required for data: 143938080
I0810 21:05:19.767784   463 layer_factory.hpp:77] Creating layer obj-block_obj-block_0_split
I0810 21:05:19.767798   463 net.cpp:94] Creating Layer obj-block_obj-block_0_split
I0810 21:05:19.767807   463 net.cpp:435] obj-block_obj-block_0_split <- obj-block
I0810 21:05:19.767817   463 net.cpp:409] obj-block_obj-block_0_split -> obj-block_obj-block_0_split_0
I0810 21:05:19.767827   463 net.cpp:409] obj-block_obj-block_0_split -> obj-block_obj-block_0_split_1
I0810 21:05:19.767889   463 net.cpp:144] Setting up obj-block_obj-block_0_split
I0810 21:05:19.767899   463 net.cpp:151] Top shape: 10 4 40 40 (64000)
I0810 21:05:19.767905   463 net.cpp:151] Top shape: 10 4 40 40 (64000)
I0810 21:05:19.767910   463 net.cpp:159] Memory required for data: 144450080
I0810 21:05:19.767916   463 layer_factory.hpp:77] Creating layer bb-label-norm
I0810 21:05:19.767928   463 net.cpp:94] Creating Layer bb-label-norm
I0810 21:05:19.767935   463 net.cpp:435] bb-label-norm <- bbox-label
I0810 21:05:19.767943   463 net.cpp:435] bb-label-norm <- size-block_size-block_0_split_0
I0810 21:05:19.767952   463 net.cpp:409] bb-label-norm -> bbox-label-norm
I0810 21:05:19.767987   463 net.cpp:144] Setting up bb-label-norm
I0810 21:05:19.767997   463 net.cpp:151] Top shape: 10 4 40 40 (64000)
I0810 21:05:19.768002   463 net.cpp:159] Memory required for data: 144706080
I0810 21:05:19.768008   463 layer_factory.hpp:77] Creating layer bb-obj-norm
I0810 21:05:19.768024   463 net.cpp:94] Creating Layer bb-obj-norm
I0810 21:05:19.768031   463 net.cpp:435] bb-obj-norm <- bbox-label-norm
I0810 21:05:19.768039   463 net.cpp:435] bb-obj-norm <- obj-block_obj-block_0_split_0
I0810 21:05:19.768049   463 net.cpp:409] bb-obj-norm -> bbox-obj-label-norm
I0810 21:05:19.768074   463 net.cpp:144] Setting up bb-obj-norm
I0810 21:05:19.768084   463 net.cpp:151] Top shape: 10 4 40 40 (64000)
I0810 21:05:19.768090   463 net.cpp:159] Memory required for data: 144962080
I0810 21:05:19.768095   463 layer_factory.hpp:77] Creating layer conv1/7x7_s2
I0810 21:05:19.768119   463 net.cpp:94] Creating Layer conv1/7x7_s2
I0810 21:05:19.768126   463 net.cpp:435] conv1/7x7_s2 <- transformed_data
I0810 21:05:19.768136   463 net.cpp:409] conv1/7x7_s2 -> conv1/7x7_s2
I0810 21:05:19.769963   463 net.cpp:144] Setting up conv1/7x7_s2
I0810 21:05:19.769981   463 net.cpp:151] Top shape: 10 64 320 320 (65536000)
I0810 21:05:19.769989   463 net.cpp:159] Memory required for data: 407106080
I0810 21:05:19.770011   463 layer_factory.hpp:77] Creating layer conv1/relu_7x7
I0810 21:05:19.770023   463 net.cpp:94] Creating Layer conv1/relu_7x7
I0810 21:05:19.770030   463 net.cpp:435] conv1/relu_7x7 <- conv1/7x7_s2
I0810 21:05:19.770040   463 net.cpp:396] conv1/relu_7x7 -> conv1/7x7_s2 (in-place)
I0810 21:05:19.770058   463 net.cpp:144] Setting up conv1/relu_7x7
I0810 21:05:19.770067   463 net.cpp:151] Top shape: 10 64 320 320 (65536000)
I0810 21:05:19.770072   463 net.cpp:159] Memory required for data: 669250080
I0810 21:05:19.770079   463 layer_factory.hpp:77] Creating layer pool1/3x3_s2
I0810 21:05:19.770094   463 net.cpp:94] Creating Layer pool1/3x3_s2
I0810 21:05:19.770102   463 net.cpp:435] pool1/3x3_s2 <- conv1/7x7_s2
I0810 21:05:19.770109   463 net.cpp:409] pool1/3x3_s2 -> pool1/3x3_s2
I0810 21:05:19.770166   463 net.cpp:144] Setting up pool1/3x3_s2
I0810 21:05:19.770176   463 net.cpp:151] Top shape: 10 64 160 160 (16384000)
I0810 21:05:19.770182   463 net.cpp:159] Memory required for data: 734786080
I0810 21:05:19.770189   463 layer_factory.hpp:77] Creating layer pool1/norm1
I0810 21:05:19.770202   463 net.cpp:94] Creating Layer pool1/norm1
I0810 21:05:19.770208   463 net.cpp:435] pool1/norm1 <- pool1/3x3_s2
I0810 21:05:19.770217   463 net.cpp:409] pool1/norm1 -> pool1/norm1
I0810 21:05:19.770272   463 net.cpp:144] Setting up pool1/norm1
I0810 21:05:19.770282   463 net.cpp:151] Top shape: 10 64 160 160 (16384000)
I0810 21:05:19.770304   463 net.cpp:159] Memory required for data: 800322080
I0810 21:05:19.770311   463 layer_factory.hpp:77] Creating layer conv2/3x3_reduce
I0810 21:05:19.770325   463 net.cpp:94] Creating Layer conv2/3x3_reduce
I0810 21:05:19.770334   463 net.cpp:435] conv2/3x3_reduce <- pool1/norm1
I0810 21:05:19.770344   463 net.cpp:409] conv2/3x3_reduce -> conv2/3x3_reduce
I0810 21:05:19.771939   463 net.cpp:144] Setting up conv2/3x3_reduce
I0810 21:05:19.771956   463 net.cpp:151] Top shape: 10 64 160 160 (16384000)
I0810 21:05:19.771963   463 net.cpp:159] Memory required for data: 865858080
I0810 21:05:19.771977   463 layer_factory.hpp:77] Creating layer conv2/relu_3x3_reduce
I0810 21:05:19.771989   463 net.cpp:94] Creating Layer conv2/relu_3x3_reduce
I0810 21:05:19.771996   463 net.cpp:435] conv2/relu_3x3_reduce <- conv2/3x3_reduce
I0810 21:05:19.772006   463 net.cpp:396] conv2/relu_3x3_reduce -> conv2/3x3_reduce (in-place)
I0810 21:05:19.772018   463 net.cpp:144] Setting up conv2/relu_3x3_reduce
I0810 21:05:19.772025   463 net.cpp:151] Top shape: 10 64 160 160 (16384000)
I0810 21:05:19.772032   463 net.cpp:159] Memory required for data: 931394080
I0810 21:05:19.772037   463 layer_factory.hpp:77] Creating layer conv2/3x3
I0810 21:05:19.772052   463 net.cpp:94] Creating Layer conv2/3x3
I0810 21:05:19.772058   463 net.cpp:435] conv2/3x3 <- conv2/3x3_reduce
I0810 21:05:19.772068   463 net.cpp:409] conv2/3x3 -> conv2/3x3
I0810 21:05:19.772920   463 net.cpp:144] Setting up conv2/3x3
I0810 21:05:19.772935   463 net.cpp:151] Top shape: 10 192 160 160 (49152000)
I0810 21:05:19.772941   463 net.cpp:159] Memory required for data: 1128002080
I0810 21:05:19.772953   463 layer_factory.hpp:77] Creating layer conv2/relu_3x3
I0810 21:05:19.772964   463 net.cpp:94] Creating Layer conv2/relu_3x3
I0810 21:05:19.772970   463 net.cpp:435] conv2/relu_3x3 <- conv2/3x3
I0810 21:05:19.772979   463 net.cpp:396] conv2/relu_3x3 -> conv2/3x3 (in-place)
I0810 21:05:19.772989   463 net.cpp:144] Setting up conv2/relu_3x3
I0810 21:05:19.772997   463 net.cpp:151] Top shape: 10 192 160 160 (49152000)
I0810 21:05:19.773002   463 net.cpp:159] Memory required for data: 1324610080
I0810 21:05:19.773010   463 layer_factory.hpp:77] Creating layer conv2/norm2
I0810 21:05:19.773020   463 net.cpp:94] Creating Layer conv2/norm2
I0810 21:05:19.773025   463 net.cpp:435] conv2/norm2 <- conv2/3x3
I0810 21:05:19.773033   463 net.cpp:409] conv2/norm2 -> conv2/norm2
I0810 21:05:19.773075   463 net.cpp:144] Setting up conv2/norm2
I0810 21:05:19.773084   463 net.cpp:151] Top shape: 10 192 160 160 (49152000)
I0810 21:05:19.773090   463 net.cpp:159] Memory required for data: 1521218080
I0810 21:05:19.773097   463 layer_factory.hpp:77] Creating layer pool2/3x3_s2
I0810 21:05:19.773105   463 net.cpp:94] Creating Layer pool2/3x3_s2
I0810 21:05:19.773113   463 net.cpp:435] pool2/3x3_s2 <- conv2/norm2
I0810 21:05:19.773121   463 net.cpp:409] pool2/3x3_s2 -> pool2/3x3_s2
I0810 21:05:19.773160   463 net.cpp:144] Setting up pool2/3x3_s2
I0810 21:05:19.773169   463 net.cpp:151] Top shape: 10 192 80 80 (12288000)
I0810 21:05:19.773175   463 net.cpp:159] Memory required for data: 1570370080
I0810 21:05:19.773181   463 layer_factory.hpp:77] Creating layer pool2/3x3_s2_pool2/3x3_s2_0_split
I0810 21:05:19.773190   463 net.cpp:94] Creating Layer pool2/3x3_s2_pool2/3x3_s2_0_split
I0810 21:05:19.773197   463 net.cpp:435] pool2/3x3_s2_pool2/3x3_s2_0_split <- pool2/3x3_s2
I0810 21:05:19.773207   463 net.cpp:409] pool2/3x3_s2_pool2/3x3_s2_0_split -> pool2/3x3_s2_pool2/3x3_s2_0_split_0
I0810 21:05:19.773217   463 net.cpp:409] pool2/3x3_s2_pool2/3x3_s2_0_split -> pool2/3x3_s2_pool2/3x3_s2_0_split_1
I0810 21:05:19.773228   463 net.cpp:409] pool2/3x3_s2_pool2/3x3_s2_0_split -> pool2/3x3_s2_pool2/3x3_s2_0_split_2
I0810 21:05:19.773238   463 net.cpp:409] pool2/3x3_s2_pool2/3x3_s2_0_split -> pool2/3x3_s2_pool2/3x3_s2_0_split_3
I0810 21:05:19.773332   463 net.cpp:144] Setting up pool2/3x3_s2_pool2/3x3_s2_0_split
I0810 21:05:19.773344   463 net.cpp:151] Top shape: 10 192 80 80 (12288000)
I0810 21:05:19.773367   463 net.cpp:151] Top shape: 10 192 80 80 (12288000)
I0810 21:05:19.773375   463 net.cpp:151] Top shape: 10 192 80 80 (12288000)
I0810 21:05:19.773381   463 net.cpp:151] Top shape: 10 192 80 80 (12288000)
I0810 21:05:19.773388   463 net.cpp:159] Memory required for data: 1766978080
I0810 21:05:19.773394   463 layer_factory.hpp:77] Creating layer inception_3a/1x1
I0810 21:05:19.773408   463 net.cpp:94] Creating Layer inception_3a/1x1
I0810 21:05:19.773416   463 net.cpp:435] inception_3a/1x1 <- pool2/3x3_s2_pool2/3x3_s2_0_split_0
I0810 21:05:19.773427   463 net.cpp:409] inception_3a/1x1 -> inception_3a/1x1
I0810 21:05:19.776017   463 net.cpp:144] Setting up inception_3a/1x1
I0810 21:05:19.776036   463 net.cpp:151] Top shape: 10 64 80 80 (4096000)
I0810 21:05:19.776043   463 net.cpp:159] Memory required for data: 1783362080
I0810 21:05:19.776053   463 layer_factory.hpp:77] Creating layer inception_3a/relu_1x1
I0810 21:05:19.776065   463 net.cpp:94] Creating Layer inception_3a/relu_1x1
I0810 21:05:19.776072   463 net.cpp:435] inception_3a/relu_1x1 <- inception_3a/1x1
I0810 21:05:19.776082   463 net.cpp:396] inception_3a/relu_1x1 -> inception_3a/1x1 (in-place)
I0810 21:05:19.776093   463 net.cpp:144] Setting up inception_3a/relu_1x1
I0810 21:05:19.776100   463 net.cpp:151] Top shape: 10 64 80 80 (4096000)
I0810 21:05:19.776106   463 net.cpp:159] Memory required for data: 1799746080
I0810 21:05:19.776113   463 layer_factory.hpp:77] Creating layer inception_3a/3x3_reduce
I0810 21:05:19.776125   463 net.cpp:94] Creating Layer inception_3a/3x3_reduce
I0810 21:05:19.776131   463 net.cpp:435] inception_3a/3x3_reduce <- pool2/3x3_s2_pool2/3x3_s2_0_split_1
I0810 21:05:19.776142   463 net.cpp:409] inception_3a/3x3_reduce -> inception_3a/3x3_reduce
I0810 21:05:19.777556   463 net.cpp:144] Setting up inception_3a/3x3_reduce
I0810 21:05:19.777807   463 net.cpp:151] Top shape: 10 96 80 80 (6144000)
I0810 21:05:19.777818   463 net.cpp:159] Memory required for data: 1824322080
I0810 21:05:19.777833   463 layer_factory.hpp:77] Creating layer inception_3a/relu_3x3_reduce
I0810 21:05:19.777845   463 net.cpp:94] Creating Layer inception_3a/relu_3x3_reduce
I0810 21:05:19.777853   463 net.cpp:435] inception_3a/relu_3x3_reduce <- inception_3a/3x3_reduce
I0810 21:05:19.777863   463 net.cpp:396] inception_3a/relu_3x3_reduce -> inception_3a/3x3_reduce (in-place)
I0810 21:05:19.777874   463 net.cpp:144] Setting up inception_3a/relu_3x3_reduce
I0810 21:05:19.777882   463 net.cpp:151] Top shape: 10 96 80 80 (6144000)
I0810 21:05:19.777889   463 net.cpp:159] Memory required for data: 1848898080
I0810 21:05:19.777894   463 layer_factory.hpp:77] Creating layer inception_3a/3x3
I0810 21:05:19.777907   463 net.cpp:94] Creating Layer inception_3a/3x3
I0810 21:05:19.777915   463 net.cpp:435] inception_3a/3x3 <- inception_3a/3x3_reduce
I0810 21:05:19.777925   463 net.cpp:409] inception_3a/3x3 -> inception_3a/3x3
I0810 21:05:19.779541   463 net.cpp:144] Setting up inception_3a/3x3
I0810 21:05:19.779558   463 net.cpp:151] Top shape: 10 128 80 80 (8192000)
I0810 21:05:19.779566   463 net.cpp:159] Memory required for data: 1881666080
I0810 21:05:19.779575   463 layer_factory.hpp:77] Creating layer inception_3a/relu_3x3
I0810 21:05:19.779585   463 net.cpp:94] Creating Layer inception_3a/relu_3x3
I0810 21:05:19.779592   463 net.cpp:435] inception_3a/relu_3x3 <- inception_3a/3x3
I0810 21:05:19.779603   463 net.cpp:396] inception_3a/relu_3x3 -> inception_3a/3x3 (in-place)
I0810 21:05:19.779615   463 net.cpp:144] Setting up inception_3a/relu_3x3
I0810 21:05:19.779623   463 net.cpp:151] Top shape: 10 128 80 80 (8192000)
I0810 21:05:19.779628   463 net.cpp:159] Memory required for data: 1914434080
I0810 21:05:19.779634   463 layer_factory.hpp:77] Creating layer inception_3a/5x5_reduce
I0810 21:05:19.779649   463 net.cpp:94] Creating Layer inception_3a/5x5_reduce
I0810 21:05:19.779656   463 net.cpp:435] inception_3a/5x5_reduce <- pool2/3x3_s2_pool2/3x3_s2_0_split_2
I0810 21:05:19.779665   463 net.cpp:409] inception_3a/5x5_reduce -> inception_3a/5x5_reduce
I0810 21:05:19.779953   463 net.cpp:144] Setting up inception_3a/5x5_reduce
I0810 21:05:19.779964   463 net.cpp:151] Top shape: 10 16 80 80 (1024000)
I0810 21:05:19.779973   463 net.cpp:159] Memory required for data: 1918530080
I0810 21:05:19.779981   463 layer_factory.hpp:77] Creating layer inception_3a/relu_5x5_reduce
I0810 21:05:19.779999   463 net.cpp:94] Creating Layer inception_3a/relu_5x5_reduce
I0810 21:05:19.780006   463 net.cpp:435] inception_3a/relu_5x5_reduce <- inception_3a/5x5_reduce
I0810 21:05:19.780015   463 net.cpp:396] inception_3a/relu_5x5_reduce -> inception_3a/5x5_reduce (in-place)
I0810 21:05:19.780025   463 net.cpp:144] Setting up inception_3a/relu_5x5_reduce
I0810 21:05:19.780032   463 net.cpp:151] Top shape: 10 16 80 80 (1024000)
I0810 21:05:19.780038   463 net.cpp:159] Memory required for data: 1922626080
I0810 21:05:19.780045   463 layer_factory.hpp:77] Creating layer inception_3a/5x5
I0810 21:05:19.780055   463 net.cpp:94] Creating Layer inception_3a/5x5
I0810 21:05:19.780062   463 net.cpp:435] inception_3a/5x5 <- inception_3a/5x5_reduce
I0810 21:05:19.780073   463 net.cpp:409] inception_3a/5x5 -> inception_3a/5x5
I0810 21:05:19.782198   463 net.cpp:144] Setting up inception_3a/5x5
I0810 21:05:19.782222   463 net.cpp:151] Top shape: 10 32 80 80 (2048000)
I0810 21:05:19.782229   463 net.cpp:159] Memory required for data: 1930818080
I0810 21:05:19.782239   463 layer_factory.hpp:77] Creating layer inception_3a/relu_5x5
I0810 21:05:19.782253   463 net.cpp:94] Creating Layer inception_3a/relu_5x5
I0810 21:05:19.782259   463 net.cpp:435] inception_3a/relu_5x5 <- inception_3a/5x5
I0810 21:05:19.782269   463 net.cpp:396] inception_3a/relu_5x5 -> inception_3a/5x5 (in-place)
I0810 21:05:19.782282   463 net.cpp:144] Setting up inception_3a/relu_5x5
I0810 21:05:19.782290   463 net.cpp:151] Top shape: 10 32 80 80 (2048000)
I0810 21:05:19.782295   463 net.cpp:159] Memory required for data: 1939010080
I0810 21:05:19.782302   463 layer_factory.hpp:77] Creating layer inception_3a/pool
I0810 21:05:19.782312   463 net.cpp:94] Creating Layer inception_3a/pool
I0810 21:05:19.782320   463 net.cpp:435] inception_3a/pool <- pool2/3x3_s2_pool2/3x3_s2_0_split_3
I0810 21:05:19.782328   463 net.cpp:409] inception_3a/pool -> inception_3a/pool
I0810 21:05:19.782380   463 net.cpp:144] Setting up inception_3a/pool
I0810 21:05:19.782390   463 net.cpp:151] Top shape: 10 192 80 80 (12288000)
I0810 21:05:19.782397   463 net.cpp:159] Memory required for data: 1988162080
I0810 21:05:19.782402   463 layer_factory.hpp:77] Creating layer inception_3a/pool_proj
I0810 21:05:19.782415   463 net.cpp:94] Creating Layer inception_3a/pool_proj
I0810 21:05:19.782423   463 net.cpp:435] inception_3a/pool_proj <- inception_3a/pool
I0810 21:05:19.782433   463 net.cpp:409] inception_3a/pool_proj -> inception_3a/pool_proj
I0810 21:05:19.782719   463 net.cpp:144] Setting up inception_3a/pool_proj
I0810 21:05:19.782732   463 net.cpp:151] Top shape: 10 32 80 80 (2048000)
I0810 21:05:19.782738   463 net.cpp:159] Memory required for data: 1996354080
I0810 21:05:19.782754   463 layer_factory.hpp:77] Creating layer inception_3a/relu_pool_proj
I0810 21:05:19.782765   463 net.cpp:94] Creating Layer inception_3a/relu_pool_proj
I0810 21:05:19.782773   463 net.cpp:435] inception_3a/relu_pool_proj <- inception_3a/pool_proj
I0810 21:05:19.782781   463 net.cpp:396] inception_3a/relu_pool_proj -> inception_3a/pool_proj (in-place)
I0810 21:05:19.782793   463 net.cpp:144] Setting up inception_3a/relu_pool_proj
I0810 21:05:19.782799   463 net.cpp:151] Top shape: 10 32 80 80 (2048000)
I0810 21:05:19.782805   463 net.cpp:159] Memory required for data: 2004546080
I0810 21:05:19.782811   463 layer_factory.hpp:77] Creating layer inception_3a/output
I0810 21:05:19.782820   463 net.cpp:94] Creating Layer inception_3a/output
I0810 21:05:19.782827   463 net.cpp:435] inception_3a/output <- inception_3a/1x1
I0810 21:05:19.782835   463 net.cpp:435] inception_3a/output <- inception_3a/3x3
I0810 21:05:19.782842   463 net.cpp:435] inception_3a/output <- inception_3a/5x5
I0810 21:05:19.782876   463 net.cpp:435] inception_3a/output <- inception_3a/pool_proj
I0810 21:05:19.782887   463 net.cpp:409] inception_3a/output -> inception_3a/output
I0810 21:05:19.782923   463 net.cpp:144] Setting up inception_3a/output
I0810 21:05:19.782932   463 net.cpp:151] Top shape: 10 256 80 80 (16384000)
I0810 21:05:19.782938   463 net.cpp:159] Memory required for data: 2070082080
I0810 21:05:19.782944   463 layer_factory.hpp:77] Creating layer inception_3a/output_inception_3a/output_0_split
I0810 21:05:19.782954   463 net.cpp:94] Creating Layer inception_3a/output_inception_3a/output_0_split
I0810 21:05:19.782961   463 net.cpp:435] inception_3a/output_inception_3a/output_0_split <- inception_3a/output
I0810 21:05:19.782970   463 net.cpp:409] inception_3a/output_inception_3a/output_0_split -> inception_3a/output_inception_3a/output_0_split_0
I0810 21:05:19.782981   463 net.cpp:409] inception_3a/output_inception_3a/output_0_split -> inception_3a/output_inception_3a/output_0_split_1
I0810 21:05:19.782991   463 net.cpp:409] inception_3a/output_inception_3a/output_0_split -> inception_3a/output_inception_3a/output_0_split_2
I0810 21:05:19.783001   463 net.cpp:409] inception_3a/output_inception_3a/output_0_split -> inception_3a/output_inception_3a/output_0_split_3
I0810 21:05:19.783058   463 net.cpp:144] Setting up inception_3a/output_inception_3a/output_0_split
I0810 21:05:19.783068   463 net.cpp:151] Top shape: 10 256 80 80 (16384000)
I0810 21:05:19.783076   463 net.cpp:151] Top shape: 10 256 80 80 (16384000)
I0810 21:05:19.783082   463 net.cpp:151] Top shape: 10 256 80 80 (16384000)
I0810 21:05:19.783088   463 net.cpp:151] Top shape: 10 256 80 80 (16384000)
I0810 21:05:19.783094   463 net.cpp:159] Memory required for data: 2332226080
I0810 21:05:19.783100   463 layer_factory.hpp:77] Creating layer inception_3b/1x1
I0810 21:05:19.783113   463 net.cpp:94] Creating Layer inception_3b/1x1
I0810 21:05:19.783119   463 net.cpp:435] inception_3b/1x1 <- inception_3a/output_inception_3a/output_0_split_0
I0810 21:05:19.783130   463 net.cpp:409] inception_3b/1x1 -> inception_3b/1x1
I0810 21:05:19.783546   463 net.cpp:144] Setting up inception_3b/1x1
I0810 21:05:19.783560   463 net.cpp:151] Top shape: 10 128 80 80 (8192000)
I0810 21:05:19.783565   463 net.cpp:159] Memory required for data: 2364994080
I0810 21:05:19.783574   463 layer_factory.hpp:77] Creating layer inception_3b/relu_1x1
I0810 21:05:19.783583   463 net.cpp:94] Creating Layer inception_3b/relu_1x1
I0810 21:05:19.783589   463 net.cpp:435] inception_3b/relu_1x1 <- inception_3b/1x1
I0810 21:05:19.783599   463 net.cpp:396] inception_3b/relu_1x1 -> inception_3b/1x1 (in-place)
I0810 21:05:19.783610   463 net.cpp:144] Setting up inception_3b/relu_1x1
I0810 21:05:19.783617   463 net.cpp:151] Top shape: 10 128 80 80 (8192000)
I0810 21:05:19.783623   463 net.cpp:159] Memory required for data: 2397762080
I0810 21:05:19.783629   463 layer_factory.hpp:77] Creating layer inception_3b/3x3_reduce
I0810 21:05:19.783640   463 net.cpp:94] Creating Layer inception_3b/3x3_reduce
I0810 21:05:19.783655   463 net.cpp:435] inception_3b/3x3_reduce <- inception_3a/output_inception_3a/output_0_split_1
I0810 21:05:19.783668   463 net.cpp:409] inception_3b/3x3_reduce -> inception_3b/3x3_reduce
I0810 21:05:19.784078   463 net.cpp:144] Setting up inception_3b/3x3_reduce
I0810 21:05:19.784091   463 net.cpp:151] Top shape: 10 128 80 80 (8192000)
I0810 21:05:19.784097   463 net.cpp:159] Memory required for data: 2430530080
I0810 21:05:19.784106   463 layer_factory.hpp:77] Creating layer inception_3b/relu_3x3_reduce
I0810 21:05:19.784116   463 net.cpp:94] Creating Layer inception_3b/relu_3x3_reduce
I0810 21:05:19.784122   463 net.cpp:435] inception_3b/relu_3x3_reduce <- inception_3b/3x3_reduce
I0810 21:05:19.784132   463 net.cpp:396] inception_3b/relu_3x3_reduce -> inception_3b/3x3_reduce (in-place)
I0810 21:05:19.784142   463 net.cpp:144] Setting up inception_3b/relu_3x3_reduce
I0810 21:05:19.784150   463 net.cpp:151] Top shape: 10 128 80 80 (8192000)
I0810 21:05:19.784157   463 net.cpp:159] Memory required for data: 2463298080
I0810 21:05:19.784178   463 layer_factory.hpp:77] Creating layer inception_3b/3x3
I0810 21:05:19.784193   463 net.cpp:94] Creating Layer inception_3b/3x3
I0810 21:05:19.784199   463 net.cpp:435] inception_3b/3x3 <- inception_3b/3x3_reduce
I0810 21:05:19.784210   463 net.cpp:409] inception_3b/3x3 -> inception_3b/3x3
I0810 21:05:19.786494   463 net.cpp:144] Setting up inception_3b/3x3
I0810 21:05:19.786514   463 net.cpp:151] Top shape: 10 192 80 80 (12288000)
I0810 21:05:19.786520   463 net.cpp:159] Memory required for data: 2512450080
I0810 21:05:19.786530   463 layer_factory.hpp:77] Creating layer inception_3b/relu_3x3
I0810 21:05:19.786540   463 net.cpp:94] Creating Layer inception_3b/relu_3x3
I0810 21:05:19.786548   463 net.cpp:435] inception_3b/relu_3x3 <- inception_3b/3x3
I0810 21:05:19.786558   463 net.cpp:396] inception_3b/relu_3x3 -> inception_3b/3x3 (in-place)
I0810 21:05:19.786571   463 net.cpp:144] Setting up inception_3b/relu_3x3
I0810 21:05:19.786577   463 net.cpp:151] Top shape: 10 192 80 80 (12288000)
I0810 21:05:19.786583   463 net.cpp:159] Memory required for data: 2561602080
I0810 21:05:19.786589   463 layer_factory.hpp:77] Creating layer inception_3b/5x5_reduce
I0810 21:05:19.786602   463 net.cpp:94] Creating Layer inception_3b/5x5_reduce
I0810 21:05:19.786609   463 net.cpp:435] inception_3b/5x5_reduce <- inception_3a/output_inception_3a/output_0_split_2
I0810 21:05:19.786620   463 net.cpp:409] inception_3b/5x5_reduce -> inception_3b/5x5_reduce
I0810 21:05:19.786907   463 net.cpp:144] Setting up inception_3b/5x5_reduce
I0810 21:05:19.786919   463 net.cpp:151] Top shape: 10 32 80 80 (2048000)
I0810 21:05:19.786926   463 net.cpp:159] Memory required for data: 2569794080
I0810 21:05:19.786936   463 layer_factory.hpp:77] Creating layer inception_3b/relu_5x5_reduce
I0810 21:05:19.786944   463 net.cpp:94] Creating Layer inception_3b/relu_5x5_reduce
I0810 21:05:19.786952   463 net.cpp:435] inception_3b/relu_5x5_reduce <- inception_3b/5x5_reduce
I0810 21:05:19.786960   463 net.cpp:396] inception_3b/relu_5x5_reduce -> inception_3b/5x5_reduce (in-place)
I0810 21:05:19.786970   463 net.cpp:144] Setting up inception_3b/relu_5x5_reduce
I0810 21:05:19.786978   463 net.cpp:151] Top shape: 10 32 80 80 (2048000)
I0810 21:05:19.786983   463 net.cpp:159] Memory required for data: 2577986080
I0810 21:05:19.786990   463 layer_factory.hpp:77] Creating layer inception_3b/5x5
I0810 21:05:19.787001   463 net.cpp:94] Creating Layer inception_3b/5x5
I0810 21:05:19.787009   463 net.cpp:435] inception_3b/5x5 <- inception_3b/5x5_reduce
I0810 21:05:19.787019   463 net.cpp:409] inception_3b/5x5 -> inception_3b/5x5
I0810 21:05:19.787693   463 net.cpp:144] Setting up inception_3b/5x5
I0810 21:05:19.787705   463 net.cpp:151] Top shape: 10 96 80 80 (6144000)
I0810 21:05:19.787711   463 net.cpp:159] Memory required for data: 2602562080
I0810 21:05:19.787720   463 layer_factory.hpp:77] Creating layer inception_3b/relu_5x5
I0810 21:05:19.787730   463 net.cpp:94] Creating Layer inception_3b/relu_5x5
I0810 21:05:19.787737   463 net.cpp:435] inception_3b/relu_5x5 <- inception_3b/5x5
I0810 21:05:19.787746   463 net.cpp:396] inception_3b/relu_5x5 -> inception_3b/5x5 (in-place)
I0810 21:05:19.787756   463 net.cpp:144] Setting up inception_3b/relu_5x5
I0810 21:05:19.787763   463 net.cpp:151] Top shape: 10 96 80 80 (6144000)
I0810 21:05:19.787770   463 net.cpp:159] Memory required for data: 2627138080
I0810 21:05:19.787775   463 layer_factory.hpp:77] Creating layer inception_3b/pool
I0810 21:05:19.787786   463 net.cpp:94] Creating Layer inception_3b/pool
I0810 21:05:19.787792   463 net.cpp:435] inception_3b/pool <- inception_3a/output_inception_3a/output_0_split_3
I0810 21:05:19.787802   463 net.cpp:409] inception_3b/pool -> inception_3b/pool
I0810 21:05:19.787848   463 net.cpp:144] Setting up inception_3b/pool
I0810 21:05:19.787858   463 net.cpp:151] Top shape: 10 256 80 80 (16384000)
I0810 21:05:19.787863   463 net.cpp:159] Memory required for data: 2692674080
I0810 21:05:19.787869   463 layer_factory.hpp:77] Creating layer inception_3b/pool_proj
I0810 21:05:19.787901   463 net.cpp:94] Creating Layer inception_3b/pool_proj
I0810 21:05:19.787909   463 net.cpp:435] inception_3b/pool_proj <- inception_3b/pool
I0810 21:05:19.787920   463 net.cpp:409] inception_3b/pool_proj -> inception_3b/pool_proj
I0810 21:05:19.800020   463 net.cpp:144] Setting up inception_3b/pool_proj
I0810 21:05:19.800083   463 net.cpp:151] Top shape: 10 64 80 80 (4096000)
I0810 21:05:19.800091   463 net.cpp:159] Memory required for data: 2709058080
I0810 21:05:19.800107   463 layer_factory.hpp:77] Creating layer inception_3b/relu_pool_proj
I0810 21:05:19.800123   463 net.cpp:94] Creating Layer inception_3b/relu_pool_proj
I0810 21:05:19.800135   463 net.cpp:435] inception_3b/relu_pool_proj <- inception_3b/pool_proj
I0810 21:05:19.800148   463 net.cpp:396] inception_3b/relu_pool_proj -> inception_3b/pool_proj (in-place)
I0810 21:05:19.800168   463 net.cpp:144] Setting up inception_3b/relu_pool_proj
I0810 21:05:19.800175   463 net.cpp:151] Top shape: 10 64 80 80 (4096000)
I0810 21:05:19.800181   463 net.cpp:159] Memory required for data: 2725442080
I0810 21:05:19.800187   463 layer_factory.hpp:77] Creating layer inception_3b/output
I0810 21:05:19.800199   463 net.cpp:94] Creating Layer inception_3b/output
I0810 21:05:19.800205   463 net.cpp:435] inception_3b/output <- inception_3b/1x1
I0810 21:05:19.800213   463 net.cpp:435] inception_3b/output <- inception_3b/3x3
I0810 21:05:19.800221   463 net.cpp:435] inception_3b/output <- inception_3b/5x5
I0810 21:05:19.800228   463 net.cpp:435] inception_3b/output <- inception_3b/pool_proj
I0810 21:05:19.800237   463 net.cpp:409] inception_3b/output -> inception_3b/output
I0810 21:05:19.800277   463 net.cpp:144] Setting up inception_3b/output
I0810 21:05:19.800287   463 net.cpp:151] Top shape: 10 480 80 80 (30720000)
I0810 21:05:19.800292   463 net.cpp:159] Memory required for data: 2848322080
I0810 21:05:19.800298   463 layer_factory.hpp:77] Creating layer pool3/3x3_s2
I0810 21:05:19.800308   463 net.cpp:94] Creating Layer pool3/3x3_s2
I0810 21:05:19.800315   463 net.cpp:435] pool3/3x3_s2 <- inception_3b/output
I0810 21:05:19.800326   463 net.cpp:409] pool3/3x3_s2 -> pool3/3x3_s2
I0810 21:05:19.800382   463 net.cpp:144] Setting up pool3/3x3_s2
I0810 21:05:19.800393   463 net.cpp:151] Top shape: 10 480 40 40 (7680000)
I0810 21:05:19.800400   463 net.cpp:159] Memory required for data: 2879042080
I0810 21:05:19.800405   463 layer_factory.hpp:77] Creating layer pool3/3x3_s2_pool3/3x3_s2_0_split
I0810 21:05:19.800416   463 net.cpp:94] Creating Layer pool3/3x3_s2_pool3/3x3_s2_0_split
I0810 21:05:19.800422   463 net.cpp:435] pool3/3x3_s2_pool3/3x3_s2_0_split <- pool3/3x3_s2
I0810 21:05:19.800432   463 net.cpp:409] pool3/3x3_s2_pool3/3x3_s2_0_split -> pool3/3x3_s2_pool3/3x3_s2_0_split_0
I0810 21:05:19.800443   463 net.cpp:409] pool3/3x3_s2_pool3/3x3_s2_0_split -> pool3/3x3_s2_pool3/3x3_s2_0_split_1
I0810 21:05:19.800453   463 net.cpp:409] pool3/3x3_s2_pool3/3x3_s2_0_split -> pool3/3x3_s2_pool3/3x3_s2_0_split_2
I0810 21:05:19.800464   463 net.cpp:409] pool3/3x3_s2_pool3/3x3_s2_0_split -> pool3/3x3_s2_pool3/3x3_s2_0_split_3
I0810 21:05:19.800523   463 net.cpp:144] Setting up pool3/3x3_s2_pool3/3x3_s2_0_split
I0810 21:05:19.800531   463 net.cpp:151] Top shape: 10 480 40 40 (7680000)
I0810 21:05:19.800539   463 net.cpp:151] Top shape: 10 480 40 40 (7680000)
I0810 21:05:19.800545   463 net.cpp:151] Top shape: 10 480 40 40 (7680000)
I0810 21:05:19.800552   463 net.cpp:151] Top shape: 10 480 40 40 (7680000)
I0810 21:05:19.800559   463 net.cpp:159] Memory required for data: 3001922080
I0810 21:05:19.800565   463 layer_factory.hpp:77] Creating layer inception_4a/1x1
I0810 21:05:19.800578   463 net.cpp:94] Creating Layer inception_4a/1x1
I0810 21:05:19.800585   463 net.cpp:435] inception_4a/1x1 <- pool3/3x3_s2_pool3/3x3_s2_0_split_0
I0810 21:05:19.800596   463 net.cpp:409] inception_4a/1x1 -> inception_4a/1x1
I0810 21:05:19.802556   463 net.cpp:144] Setting up inception_4a/1x1
I0810 21:05:19.802580   463 net.cpp:151] Top shape: 10 192 40 40 (3072000)
I0810 21:05:19.802624   463 net.cpp:159] Memory required for data: 3014210080
I0810 21:05:19.802636   463 layer_factory.hpp:77] Creating layer inception_4a/relu_1x1
I0810 21:05:19.802649   463 net.cpp:94] Creating Layer inception_4a/relu_1x1
I0810 21:05:19.802655   463 net.cpp:435] inception_4a/relu_1x1 <- inception_4a/1x1
I0810 21:05:19.802665   463 net.cpp:396] inception_4a/relu_1x1 -> inception_4a/1x1 (in-place)
I0810 21:05:19.802678   463 net.cpp:144] Setting up inception_4a/relu_1x1
I0810 21:05:19.802686   463 net.cpp:151] Top shape: 10 192 40 40 (3072000)
I0810 21:05:19.802692   463 net.cpp:159] Memory required for data: 3026498080
I0810 21:05:19.802698   463 layer_factory.hpp:77] Creating layer inception_4a/3x3_reduce
I0810 21:05:19.802712   463 net.cpp:94] Creating Layer inception_4a/3x3_reduce
I0810 21:05:19.802719   463 net.cpp:435] inception_4a/3x3_reduce <- pool3/3x3_s2_pool3/3x3_s2_0_split_1
I0810 21:05:19.802731   463 net.cpp:409] inception_4a/3x3_reduce -> inception_4a/3x3_reduce
I0810 21:05:19.803402   463 net.cpp:144] Setting up inception_4a/3x3_reduce
I0810 21:05:19.803422   463 net.cpp:151] Top shape: 10 96 40 40 (1536000)
I0810 21:05:19.803429   463 net.cpp:159] Memory required for data: 3032642080
I0810 21:05:19.803450   463 layer_factory.hpp:77] Creating layer inception_4a/relu_3x3_reduce
I0810 21:05:19.803462   463 net.cpp:94] Creating Layer inception_4a/relu_3x3_reduce
I0810 21:05:19.803469   463 net.cpp:435] inception_4a/relu_3x3_reduce <- inception_4a/3x3_reduce
I0810 21:05:19.803480   463 net.cpp:396] inception_4a/relu_3x3_reduce -> inception_4a/3x3_reduce (in-place)
I0810 21:05:19.803493   463 net.cpp:144] Setting up inception_4a/relu_3x3_reduce
I0810 21:05:19.803500   463 net.cpp:151] Top shape: 10 96 40 40 (1536000)
I0810 21:05:19.803506   463 net.cpp:159] Memory required for data: 3038786080
I0810 21:05:19.803512   463 layer_factory.hpp:77] Creating layer inception_4a/3x3
I0810 21:05:19.803526   463 net.cpp:94] Creating Layer inception_4a/3x3
I0810 21:05:19.803532   463 net.cpp:435] inception_4a/3x3 <- inception_4a/3x3_reduce
I0810 21:05:19.803544   463 net.cpp:409] inception_4a/3x3 -> inception_4a/3x3
I0810 21:05:19.805635   463 net.cpp:144] Setting up inception_4a/3x3
I0810 21:05:19.805655   463 net.cpp:151] Top shape: 10 208 40 40 (3328000)
I0810 21:05:19.805662   463 net.cpp:159] Memory required for data: 3052098080
I0810 21:05:19.805675   463 layer_factory.hpp:77] Creating layer inception_4a/relu_3x3
I0810 21:05:19.805686   463 net.cpp:94] Creating Layer inception_4a/relu_3x3
I0810 21:05:19.805693   463 net.cpp:435] inception_4a/relu_3x3 <- inception_4a/3x3
I0810 21:05:19.805704   463 net.cpp:396] inception_4a/relu_3x3 -> inception_4a/3x3 (in-place)
I0810 21:05:19.805716   463 net.cpp:144] Setting up inception_4a/relu_3x3
I0810 21:05:19.805724   463 net.cpp:151] Top shape: 10 208 40 40 (3328000)
I0810 21:05:19.805730   463 net.cpp:159] Memory required for data: 3065410080
I0810 21:05:19.805737   463 layer_factory.hpp:77] Creating layer inception_4a/5x5_reduce
I0810 21:05:19.805748   463 net.cpp:94] Creating Layer inception_4a/5x5_reduce
I0810 21:05:19.805755   463 net.cpp:435] inception_4a/5x5_reduce <- pool3/3x3_s2_pool3/3x3_s2_0_split_2
I0810 21:05:19.805768   463 net.cpp:409] inception_4a/5x5_reduce -> inception_4a/5x5_reduce
I0810 21:05:19.806052   463 net.cpp:144] Setting up inception_4a/5x5_reduce
I0810 21:05:19.806066   463 net.cpp:151] Top shape: 10 16 40 40 (256000)
I0810 21:05:19.806071   463 net.cpp:159] Memory required for data: 3066434080
I0810 21:05:19.806079   463 layer_factory.hpp:77] Creating layer inception_4a/relu_5x5_reduce
I0810 21:05:19.806089   463 net.cpp:94] Creating Layer inception_4a/relu_5x5_reduce
I0810 21:05:19.806097   463 net.cpp:435] inception_4a/relu_5x5_reduce <- inception_4a/5x5_reduce
I0810 21:05:19.806105   463 net.cpp:396] inception_4a/relu_5x5_reduce -> inception_4a/5x5_reduce (in-place)
I0810 21:05:19.806115   463 net.cpp:144] Setting up inception_4a/relu_5x5_reduce
I0810 21:05:19.806123   463 net.cpp:151] Top shape: 10 16 40 40 (256000)
I0810 21:05:19.806147   463 net.cpp:159] Memory required for data: 3067458080
I0810 21:05:19.806154   463 layer_factory.hpp:77] Creating layer inception_4a/5x5
I0810 21:05:19.806197   463 net.cpp:94] Creating Layer inception_4a/5x5
I0810 21:05:19.806205   463 net.cpp:435] inception_4a/5x5 <- inception_4a/5x5_reduce
I0810 21:05:19.806216   463 net.cpp:409] inception_4a/5x5 -> inception_4a/5x5
I0810 21:05:19.806557   463 net.cpp:144] Setting up inception_4a/5x5
I0810 21:05:19.806569   463 net.cpp:151] Top shape: 10 48 40 40 (768000)
I0810 21:05:19.806576   463 net.cpp:159] Memory required for data: 3070530080
I0810 21:05:19.806584   463 layer_factory.hpp:77] Creating layer inception_4a/relu_5x5
I0810 21:05:19.806593   463 net.cpp:94] Creating Layer inception_4a/relu_5x5
I0810 21:05:19.806601   463 net.cpp:435] inception_4a/relu_5x5 <- inception_4a/5x5
I0810 21:05:19.806610   463 net.cpp:396] inception_4a/relu_5x5 -> inception_4a/5x5 (in-place)
I0810 21:05:19.806620   463 net.cpp:144] Setting up inception_4a/relu_5x5
I0810 21:05:19.806627   463 net.cpp:151] Top shape: 10 48 40 40 (768000)
I0810 21:05:19.806633   463 net.cpp:159] Memory required for data: 3073602080
I0810 21:05:19.806639   463 layer_factory.hpp:77] Creating layer inception_4a/pool
I0810 21:05:19.806649   463 net.cpp:94] Creating Layer inception_4a/pool
I0810 21:05:19.806655   463 net.cpp:435] inception_4a/pool <- pool3/3x3_s2_pool3/3x3_s2_0_split_3
I0810 21:05:19.806665   463 net.cpp:409] inception_4a/pool -> inception_4a/pool
I0810 21:05:19.806713   463 net.cpp:144] Setting up inception_4a/pool
I0810 21:05:19.806723   463 net.cpp:151] Top shape: 10 480 40 40 (7680000)
I0810 21:05:19.806730   463 net.cpp:159] Memory required for data: 3104322080
I0810 21:05:19.806735   463 layer_factory.hpp:77] Creating layer inception_4a/pool_proj
I0810 21:05:19.806747   463 net.cpp:94] Creating Layer inception_4a/pool_proj
I0810 21:05:19.806753   463 net.cpp:435] inception_4a/pool_proj <- inception_4a/pool
I0810 21:05:19.806763   463 net.cpp:409] inception_4a/pool_proj -> inception_4a/pool_proj
I0810 21:05:19.824530   463 net.cpp:144] Setting up inception_4a/pool_proj
I0810 21:05:19.824578   463 net.cpp:151] Top shape: 10 64 40 40 (1024000)
I0810 21:05:19.824584   463 net.cpp:159] Memory required for data: 3108418080
I0810 21:05:19.824600   463 layer_factory.hpp:77] Creating layer inception_4a/relu_pool_proj
I0810 21:05:19.824618   463 net.cpp:94] Creating Layer inception_4a/relu_pool_proj
I0810 21:05:19.824628   463 net.cpp:435] inception_4a/relu_pool_proj <- inception_4a/pool_proj
I0810 21:05:19.824642   463 net.cpp:396] inception_4a/relu_pool_proj -> inception_4a/pool_proj (in-place)
I0810 21:05:19.824661   463 net.cpp:144] Setting up inception_4a/relu_pool_proj
I0810 21:05:19.824671   463 net.cpp:151] Top shape: 10 64 40 40 (1024000)
I0810 21:05:19.824677   463 net.cpp:159] Memory required for data: 3112514080
I0810 21:05:19.824684   463 layer_factory.hpp:77] Creating layer inception_4a/output
I0810 21:05:19.824694   463 net.cpp:94] Creating Layer inception_4a/output
I0810 21:05:19.824702   463 net.cpp:435] inception_4a/output <- inception_4a/1x1
I0810 21:05:19.824710   463 net.cpp:435] inception_4a/output <- inception_4a/3x3
I0810 21:05:19.824718   463 net.cpp:435] inception_4a/output <- inception_4a/5x5
I0810 21:05:19.824725   463 net.cpp:435] inception_4a/output <- inception_4a/pool_proj
I0810 21:05:19.824735   463 net.cpp:409] inception_4a/output -> inception_4a/output
I0810 21:05:19.824771   463 net.cpp:144] Setting up inception_4a/output
I0810 21:05:19.824781   463 net.cpp:151] Top shape: 10 512 40 40 (8192000)
I0810 21:05:19.824786   463 net.cpp:159] Memory required for data: 3145282080
I0810 21:05:19.824793   463 layer_factory.hpp:77] Creating layer inception_4a/output_inception_4a/output_0_split
I0810 21:05:19.824803   463 net.cpp:94] Creating Layer inception_4a/output_inception_4a/output_0_split
I0810 21:05:19.824810   463 net.cpp:435] inception_4a/output_inception_4a/output_0_split <- inception_4a/output
I0810 21:05:19.824821   463 net.cpp:409] inception_4a/output_inception_4a/output_0_split -> inception_4a/output_inception_4a/output_0_split_0
I0810 21:05:19.824867   463 net.cpp:409] inception_4a/output_inception_4a/output_0_split -> inception_4a/output_inception_4a/output_0_split_1
I0810 21:05:19.824878   463 net.cpp:409] inception_4a/output_inception_4a/output_0_split -> inception_4a/output_inception_4a/output_0_split_2
I0810 21:05:19.824913   463 net.cpp:409] inception_4a/output_inception_4a/output_0_split -> inception_4a/output_inception_4a/output_0_split_3
I0810 21:05:19.824978   463 net.cpp:144] Setting up inception_4a/output_inception_4a/output_0_split
I0810 21:05:19.824987   463 net.cpp:151] Top shape: 10 512 40 40 (8192000)
I0810 21:05:19.824995   463 net.cpp:151] Top shape: 10 512 40 40 (8192000)
I0810 21:05:19.825001   463 net.cpp:151] Top shape: 10 512 40 40 (8192000)
I0810 21:05:19.825008   463 net.cpp:151] Top shape: 10 512 40 40 (8192000)
I0810 21:05:19.825013   463 net.cpp:159] Memory required for data: 3276354080
I0810 21:05:19.825019   463 layer_factory.hpp:77] Creating layer inception_4b/1x1
I0810 21:05:19.825034   463 net.cpp:94] Creating Layer inception_4b/1x1
I0810 21:05:19.825042   463 net.cpp:435] inception_4b/1x1 <- inception_4a/output_inception_4a/output_0_split_0
I0810 21:05:19.825052   463 net.cpp:409] inception_4b/1x1 -> inception_4b/1x1
I0810 21:05:19.825789   463 net.cpp:144] Setting up inception_4b/1x1
I0810 21:05:19.825801   463 net.cpp:151] Top shape: 10 160 40 40 (2560000)
I0810 21:05:19.825808   463 net.cpp:159] Memory required for data: 3286594080
I0810 21:05:19.825817   463 layer_factory.hpp:77] Creating layer inception_4b/relu_1x1
I0810 21:05:19.825826   463 net.cpp:94] Creating Layer inception_4b/relu_1x1
I0810 21:05:19.825834   463 net.cpp:435] inception_4b/relu_1x1 <- inception_4b/1x1
I0810 21:05:19.825844   463 net.cpp:396] inception_4b/relu_1x1 -> inception_4b/1x1 (in-place)
I0810 21:05:19.825855   463 net.cpp:144] Setting up inception_4b/relu_1x1
I0810 21:05:19.825862   463 net.cpp:151] Top shape: 10 160 40 40 (2560000)
I0810 21:05:19.825867   463 net.cpp:159] Memory required for data: 3296834080
I0810 21:05:19.825873   463 layer_factory.hpp:77] Creating layer inception_4b/3x3_reduce
I0810 21:05:19.825886   463 net.cpp:94] Creating Layer inception_4b/3x3_reduce
I0810 21:05:19.825892   463 net.cpp:435] inception_4b/3x3_reduce <- inception_4a/output_inception_4a/output_0_split_1
I0810 21:05:19.825904   463 net.cpp:409] inception_4b/3x3_reduce -> inception_4b/3x3_reduce
I0810 21:05:19.827373   463 net.cpp:144] Setting up inception_4b/3x3_reduce
I0810 21:05:19.827389   463 net.cpp:151] Top shape: 10 112 40 40 (1792000)
I0810 21:05:19.827395   463 net.cpp:159] Memory required for data: 3304002080
I0810 21:05:19.827405   463 layer_factory.hpp:77] Creating layer inception_4b/relu_3x3_reduce
I0810 21:05:19.827416   463 net.cpp:94] Creating Layer inception_4b/relu_3x3_reduce
I0810 21:05:19.827425   463 net.cpp:435] inception_4b/relu_3x3_reduce <- inception_4b/3x3_reduce
I0810 21:05:19.827435   463 net.cpp:396] inception_4b/relu_3x3_reduce -> inception_4b/3x3_reduce (in-place)
I0810 21:05:19.827445   463 net.cpp:144] Setting up inception_4b/relu_3x3_reduce
I0810 21:05:19.827452   463 net.cpp:151] Top shape: 10 112 40 40 (1792000)
I0810 21:05:19.827458   463 net.cpp:159] Memory required for data: 3311170080
I0810 21:05:19.827464   463 layer_factory.hpp:77] Creating layer inception_4b/3x3
I0810 21:05:19.827478   463 net.cpp:94] Creating Layer inception_4b/3x3
I0810 21:05:19.827486   463 net.cpp:435] inception_4b/3x3 <- inception_4b/3x3_reduce
I0810 21:05:19.827495   463 net.cpp:409] inception_4b/3x3 -> inception_4b/3x3
I0810 21:05:19.829622   463 net.cpp:144] Setting up inception_4b/3x3
I0810 21:05:19.829640   463 net.cpp:151] Top shape: 10 224 40 40 (3584000)
I0810 21:05:19.829646   463 net.cpp:159] Memory required for data: 3325506080
I0810 21:05:19.829656   463 layer_factory.hpp:77] Creating layer inception_4b/relu_3x3
I0810 21:05:19.829726   463 net.cpp:94] Creating Layer inception_4b/relu_3x3
I0810 21:05:19.829741   463 net.cpp:435] inception_4b/relu_3x3 <- inception_4b/3x3
I0810 21:05:19.829778   463 net.cpp:396] inception_4b/relu_3x3 -> inception_4b/3x3 (in-place)
I0810 21:05:19.829793   463 net.cpp:144] Setting up inception_4b/relu_3x3
I0810 21:05:19.829802   463 net.cpp:151] Top shape: 10 224 40 40 (3584000)
I0810 21:05:19.829808   463 net.cpp:159] Memory required for data: 3339842080
I0810 21:05:19.829815   463 layer_factory.hpp:77] Creating layer inception_4b/5x5_reduce
I0810 21:05:19.829828   463 net.cpp:94] Creating Layer inception_4b/5x5_reduce
I0810 21:05:19.829836   463 net.cpp:435] inception_4b/5x5_reduce <- inception_4a/output_inception_4a/output_0_split_2
I0810 21:05:19.829847   463 net.cpp:409] inception_4b/5x5_reduce -> inception_4b/5x5_reduce
I0810 21:05:19.830194   463 net.cpp:144] Setting up inception_4b/5x5_reduce
I0810 21:05:19.830209   463 net.cpp:151] Top shape: 10 24 40 40 (384000)
I0810 21:05:19.830214   463 net.cpp:159] Memory required for data: 3341378080
I0810 21:05:19.830224   463 layer_factory.hpp:77] Creating layer inception_4b/relu_5x5_reduce
I0810 21:05:19.830233   463 net.cpp:94] Creating Layer inception_4b/relu_5x5_reduce
I0810 21:05:19.830240   463 net.cpp:435] inception_4b/relu_5x5_reduce <- inception_4b/5x5_reduce
I0810 21:05:19.830250   463 net.cpp:396] inception_4b/relu_5x5_reduce -> inception_4b/5x5_reduce (in-place)
I0810 21:05:19.830260   463 net.cpp:144] Setting up inception_4b/relu_5x5_reduce
I0810 21:05:19.830267   463 net.cpp:151] Top shape: 10 24 40 40 (384000)
I0810 21:05:19.830272   463 net.cpp:159] Memory required for data: 3342914080
I0810 21:05:19.830279   463 layer_factory.hpp:77] Creating layer inception_4b/5x5
I0810 21:05:19.830291   463 net.cpp:94] Creating Layer inception_4b/5x5
I0810 21:05:19.830296   463 net.cpp:435] inception_4b/5x5 <- inception_4b/5x5_reduce
I0810 21:05:19.830307   463 net.cpp:409] inception_4b/5x5 -> inception_4b/5x5
I0810 21:05:19.830775   463 net.cpp:144] Setting up inception_4b/5x5
I0810 21:05:19.830786   463 net.cpp:151] Top shape: 10 64 40 40 (1024000)
I0810 21:05:19.830792   463 net.cpp:159] Memory required for data: 3347010080
I0810 21:05:19.830801   463 layer_factory.hpp:77] Creating layer inception_4b/relu_5x5
I0810 21:05:19.830811   463 net.cpp:94] Creating Layer inception_4b/relu_5x5
I0810 21:05:19.830818   463 net.cpp:435] inception_4b/relu_5x5 <- inception_4b/5x5
I0810 21:05:19.830826   463 net.cpp:396] inception_4b/relu_5x5 -> inception_4b/5x5 (in-place)
I0810 21:05:19.830837   463 net.cpp:144] Setting up inception_4b/relu_5x5
I0810 21:05:19.830844   463 net.cpp:151] Top shape: 10 64 40 40 (1024000)
I0810 21:05:19.830849   463 net.cpp:159] Memory required for data: 3351106080
I0810 21:05:19.830855   463 layer_factory.hpp:77] Creating layer inception_4b/pool
I0810 21:05:19.830865   463 net.cpp:94] Creating Layer inception_4b/pool
I0810 21:05:19.830873   463 net.cpp:435] inception_4b/pool <- inception_4a/output_inception_4a/output_0_split_3
I0810 21:05:19.830881   463 net.cpp:409] inception_4b/pool -> inception_4b/pool
I0810 21:05:19.830930   463 net.cpp:144] Setting up inception_4b/pool
I0810 21:05:19.830940   463 net.cpp:151] Top shape: 10 512 40 40 (8192000)
I0810 21:05:19.830945   463 net.cpp:159] Memory required for data: 3383874080
I0810 21:05:19.830951   463 layer_factory.hpp:77] Creating layer inception_4b/pool_proj
I0810 21:05:19.830965   463 net.cpp:94] Creating Layer inception_4b/pool_proj
I0810 21:05:19.830971   463 net.cpp:435] inception_4b/pool_proj <- inception_4b/pool
I0810 21:05:19.830981   463 net.cpp:409] inception_4b/pool_proj -> inception_4b/pool_proj
I0810 21:05:19.831404   463 net.cpp:144] Setting up inception_4b/pool_proj
I0810 21:05:19.831416   463 net.cpp:151] Top shape: 10 64 40 40 (1024000)
I0810 21:05:19.831423   463 net.cpp:159] Memory required for data: 3387970080
I0810 21:05:19.831432   463 layer_factory.hpp:77] Creating layer inception_4b/relu_pool_proj
I0810 21:05:19.831444   463 net.cpp:94] Creating Layer inception_4b/relu_pool_proj
I0810 21:05:19.831450   463 net.cpp:435] inception_4b/relu_pool_proj <- inception_4b/pool_proj
I0810 21:05:19.831475   463 net.cpp:396] inception_4b/relu_pool_proj -> inception_4b/pool_proj (in-place)
I0810 21:05:19.831486   463 net.cpp:144] Setting up inception_4b/relu_pool_proj
I0810 21:05:19.831495   463 net.cpp:151] Top shape: 10 64 40 40 (1024000)
I0810 21:05:19.831499   463 net.cpp:159] Memory required for data: 3392066080
I0810 21:05:19.831506   463 layer_factory.hpp:77] Creating layer inception_4b/output
I0810 21:05:19.831516   463 net.cpp:94] Creating Layer inception_4b/output
I0810 21:05:19.831522   463 net.cpp:435] inception_4b/output <- inception_4b/1x1
I0810 21:05:19.831529   463 net.cpp:435] inception_4b/output <- inception_4b/3x3
I0810 21:05:19.831549   463 net.cpp:435] inception_4b/output <- inception_4b/5x5
I0810 21:05:19.831557   463 net.cpp:435] inception_4b/output <- inception_4b/pool_proj
I0810 21:05:19.831567   463 net.cpp:409] inception_4b/output -> inception_4b/output
I0810 21:05:19.831600   463 net.cpp:144] Setting up inception_4b/output
I0810 21:05:19.831610   463 net.cpp:151] Top shape: 10 512 40 40 (8192000)
I0810 21:05:19.831615   463 net.cpp:159] Memory required for data: 3424834080
I0810 21:05:19.831621   463 layer_factory.hpp:77] Creating layer inception_4b/output_inception_4b/output_0_split
I0810 21:05:19.831631   463 net.cpp:94] Creating Layer inception_4b/output_inception_4b/output_0_split
I0810 21:05:19.831638   463 net.cpp:435] inception_4b/output_inception_4b/output_0_split <- inception_4b/output
I0810 21:05:19.831656   463 net.cpp:409] inception_4b/output_inception_4b/output_0_split -> inception_4b/output_inception_4b/output_0_split_0
I0810 21:05:19.831668   463 net.cpp:409] inception_4b/output_inception_4b/output_0_split -> inception_4b/output_inception_4b/output_0_split_1
I0810 21:05:19.831678   463 net.cpp:409] inception_4b/output_inception_4b/output_0_split -> inception_4b/output_inception_4b/output_0_split_2
I0810 21:05:19.831688   463 net.cpp:409] inception_4b/output_inception_4b/output_0_split -> inception_4b/output_inception_4b/output_0_split_3
I0810 21:05:19.831750   463 net.cpp:144] Setting up inception_4b/output_inception_4b/output_0_split
I0810 21:05:19.831759   463 net.cpp:151] Top shape: 10 512 40 40 (8192000)
I0810 21:05:19.831766   463 net.cpp:151] Top shape: 10 512 40 40 (8192000)
I0810 21:05:19.831773   463 net.cpp:151] Top shape: 10 512 40 40 (8192000)
I0810 21:05:19.831779   463 net.cpp:151] Top shape: 10 512 40 40 (8192000)
I0810 21:05:19.831785   463 net.cpp:159] Memory required for data: 3555906080
I0810 21:05:19.831791   463 layer_factory.hpp:77] Creating layer inception_4c/1x1
I0810 21:05:19.831802   463 net.cpp:94] Creating Layer inception_4c/1x1
I0810 21:05:19.831818   463 net.cpp:435] inception_4c/1x1 <- inception_4b/output_inception_4b/output_0_split_0
I0810 21:05:19.831831   463 net.cpp:409] inception_4c/1x1 -> inception_4c/1x1
I0810 21:05:19.832427   463 net.cpp:144] Setting up inception_4c/1x1
I0810 21:05:19.832439   463 net.cpp:151] Top shape: 10 128 40 40 (2048000)
I0810 21:05:19.832445   463 net.cpp:159] Memory required for data: 3564098080
I0810 21:05:19.832454   463 layer_factory.hpp:77] Creating layer inception_4c/relu_1x1
I0810 21:05:19.832463   463 net.cpp:94] Creating Layer inception_4c/relu_1x1
I0810 21:05:19.832470   463 net.cpp:435] inception_4c/relu_1x1 <- inception_4c/1x1
I0810 21:05:19.832480   463 net.cpp:396] inception_4c/relu_1x1 -> inception_4c/1x1 (in-place)
I0810 21:05:19.832492   463 net.cpp:144] Setting up inception_4c/relu_1x1
I0810 21:05:19.832500   463 net.cpp:151] Top shape: 10 128 40 40 (2048000)
I0810 21:05:19.832506   463 net.cpp:159] Memory required for data: 3572290080
I0810 21:05:19.832512   463 layer_factory.hpp:77] Creating layer inception_4c/3x3_reduce
I0810 21:05:19.832525   463 net.cpp:94] Creating Layer inception_4c/3x3_reduce
I0810 21:05:19.832531   463 net.cpp:435] inception_4c/3x3_reduce <- inception_4b/output_inception_4b/output_0_split_1
I0810 21:05:19.832545   463 net.cpp:409] inception_4c/3x3_reduce -> inception_4c/3x3_reduce
I0810 21:05:19.833180   463 net.cpp:144] Setting up inception_4c/3x3_reduce
I0810 21:05:19.833210   463 net.cpp:151] Top shape: 10 128 40 40 (2048000)
I0810 21:05:19.833216   463 net.cpp:159] Memory required for data: 3580482080
I0810 21:05:19.833226   463 layer_factory.hpp:77] Creating layer inception_4c/relu_3x3_reduce
I0810 21:05:19.833236   463 net.cpp:94] Creating Layer inception_4c/relu_3x3_reduce
I0810 21:05:19.833243   463 net.cpp:435] inception_4c/relu_3x3_reduce <- inception_4c/3x3_reduce
I0810 21:05:19.833253   463 net.cpp:396] inception_4c/relu_3x3_reduce -> inception_4c/3x3_reduce (in-place)
I0810 21:05:19.833263   463 net.cpp:144] Setting up inception_4c/relu_3x3_reduce
I0810 21:05:19.833271   463 net.cpp:151] Top shape: 10 128 40 40 (2048000)
I0810 21:05:19.833277   463 net.cpp:159] Memory required for data: 3588674080
I0810 21:05:19.833283   463 layer_factory.hpp:77] Creating layer inception_4c/3x3
I0810 21:05:19.833294   463 net.cpp:94] Creating Layer inception_4c/3x3
I0810 21:05:19.833302   463 net.cpp:435] inception_4c/3x3 <- inception_4c/3x3_reduce
I0810 21:05:19.833312   463 net.cpp:409] inception_4c/3x3 -> inception_4c/3x3
I0810 21:05:19.836010   463 net.cpp:144] Setting up inception_4c/3x3
I0810 21:05:19.836030   463 net.cpp:151] Top shape: 10 256 40 40 (4096000)
I0810 21:05:19.836036   463 net.cpp:159] Memory required for data: 3605058080
I0810 21:05:19.836046   463 layer_factory.hpp:77] Creating layer inception_4c/relu_3x3
I0810 21:05:19.836057   463 net.cpp:94] Creating Layer inception_4c/relu_3x3
I0810 21:05:19.836066   463 net.cpp:435] inception_4c/relu_3x3 <- inception_4c/3x3
I0810 21:05:19.836076   463 net.cpp:396] inception_4c/relu_3x3 -> inception_4c/3x3 (in-place)
I0810 21:05:19.836087   463 net.cpp:144] Setting up inception_4c/relu_3x3
I0810 21:05:19.836096   463 net.cpp:151] Top shape: 10 256 40 40 (4096000)
I0810 21:05:19.836102   463 net.cpp:159] Memory required for data: 3621442080
I0810 21:05:19.836107   463 layer_factory.hpp:77] Creating layer inception_4c/5x5_reduce
I0810 21:05:19.836119   463 net.cpp:94] Creating Layer inception_4c/5x5_reduce
I0810 21:05:19.836127   463 net.cpp:435] inception_4c/5x5_reduce <- inception_4b/output_inception_4b/output_0_split_2
I0810 21:05:19.836138   463 net.cpp:409] inception_4c/5x5_reduce -> inception_4c/5x5_reduce
I0810 21:05:19.836452   463 net.cpp:144] Setting up inception_4c/5x5_reduce
I0810 21:05:19.836463   463 net.cpp:151] Top shape: 10 24 40 40 (384000)
I0810 21:05:19.836469   463 net.cpp:159] Memory required for data: 3622978080
I0810 21:05:19.836479   463 layer_factory.hpp:77] Creating layer inception_4c/relu_5x5_reduce
I0810 21:05:19.836488   463 net.cpp:94] Creating Layer inception_4c/relu_5x5_reduce
I0810 21:05:19.836495   463 net.cpp:435] inception_4c/relu_5x5_reduce <- inception_4c/5x5_reduce
I0810 21:05:19.836504   463 net.cpp:396] inception_4c/relu_5x5_reduce -> inception_4c/5x5_reduce (in-place)
I0810 21:05:19.836514   463 net.cpp:144] Setting up inception_4c/relu_5x5_reduce
I0810 21:05:19.836521   463 net.cpp:151] Top shape: 10 24 40 40 (384000)
I0810 21:05:19.836527   463 net.cpp:159] Memory required for data: 3624514080
I0810 21:05:19.836534   463 layer_factory.hpp:77] Creating layer inception_4c/5x5
I0810 21:05:19.836545   463 net.cpp:94] Creating Layer inception_4c/5x5
I0810 21:05:19.836725   463 net.cpp:435] inception_4c/5x5 <- inception_4c/5x5_reduce
I0810 21:05:19.836745   463 net.cpp:409] inception_4c/5x5 -> inception_4c/5x5
I0810 21:05:19.838001   463 net.cpp:144] Setting up inception_4c/5x5
I0810 21:05:19.838021   463 net.cpp:151] Top shape: 10 64 40 40 (1024000)
I0810 21:05:19.838027   463 net.cpp:159] Memory required for data: 3628610080
I0810 21:05:19.838037   463 layer_factory.hpp:77] Creating layer inception_4c/relu_5x5
I0810 21:05:19.838047   463 net.cpp:94] Creating Layer inception_4c/relu_5x5
I0810 21:05:19.838055   463 net.cpp:435] inception_4c/relu_5x5 <- inception_4c/5x5
I0810 21:05:19.838065   463 net.cpp:396] inception_4c/relu_5x5 -> inception_4c/5x5 (in-place)
I0810 21:05:19.838076   463 net.cpp:144] Setting up inception_4c/relu_5x5
I0810 21:05:19.838084   463 net.cpp:151] Top shape: 10 64 40 40 (1024000)
I0810 21:05:19.838111   463 net.cpp:159] Memory required for data: 3632706080
I0810 21:05:19.838119   463 layer_factory.hpp:77] Creating layer inception_4c/pool
I0810 21:05:19.838129   463 net.cpp:94] Creating Layer inception_4c/pool
I0810 21:05:19.838135   463 net.cpp:435] inception_4c/pool <- inception_4b/output_inception_4b/output_0_split_3
I0810 21:05:19.838145   463 net.cpp:409] inception_4c/pool -> inception_4c/pool
I0810 21:05:19.838197   463 net.cpp:144] Setting up inception_4c/pool
I0810 21:05:19.838207   463 net.cpp:151] Top shape: 10 512 40 40 (8192000)
I0810 21:05:19.838213   463 net.cpp:159] Memory required for data: 3665474080
I0810 21:05:19.838219   463 layer_factory.hpp:77] Creating layer inception_4c/pool_proj
I0810 21:05:19.838232   463 net.cpp:94] Creating Layer inception_4c/pool_proj
I0810 21:05:19.838239   463 net.cpp:435] inception_4c/pool_proj <- inception_4c/pool
I0810 21:05:19.838249   463 net.cpp:409] inception_4c/pool_proj -> inception_4c/pool_proj
I0810 21:05:19.838697   463 net.cpp:144] Setting up inception_4c/pool_proj
I0810 21:05:19.838711   463 net.cpp:151] Top shape: 10 64 40 40 (1024000)
I0810 21:05:19.838717   463 net.cpp:159] Memory required for data: 3669570080
I0810 21:05:19.838740   463 layer_factory.hpp:77] Creating layer inception_4c/relu_pool_proj
I0810 21:05:19.838752   463 net.cpp:94] Creating Layer inception_4c/relu_pool_proj
I0810 21:05:19.838758   463 net.cpp:435] inception_4c/relu_pool_proj <- inception_4c/pool_proj
I0810 21:05:19.838768   463 net.cpp:396] inception_4c/relu_pool_proj -> inception_4c/pool_proj (in-place)
I0810 21:05:19.838778   463 net.cpp:144] Setting up inception_4c/relu_pool_proj
I0810 21:05:19.838786   463 net.cpp:151] Top shape: 10 64 40 40 (1024000)
I0810 21:05:19.838791   463 net.cpp:159] Memory required for data: 3673666080
I0810 21:05:19.838798   463 layer_factory.hpp:77] Creating layer inception_4c/output
I0810 21:05:19.838806   463 net.cpp:94] Creating Layer inception_4c/output
I0810 21:05:19.838814   463 net.cpp:435] inception_4c/output <- inception_4c/1x1
I0810 21:05:19.838820   463 net.cpp:435] inception_4c/output <- inception_4c/3x3
I0810 21:05:19.838827   463 net.cpp:435] inception_4c/output <- inception_4c/5x5
I0810 21:05:19.838835   463 net.cpp:435] inception_4c/output <- inception_4c/pool_proj
I0810 21:05:19.838845   463 net.cpp:409] inception_4c/output -> inception_4c/output
I0810 21:05:19.838877   463 net.cpp:144] Setting up inception_4c/output
I0810 21:05:19.838886   463 net.cpp:151] Top shape: 10 512 40 40 (8192000)
I0810 21:05:19.838892   463 net.cpp:159] Memory required for data: 3706434080
I0810 21:05:19.838898   463 layer_factory.hpp:77] Creating layer inception_4c/output_inception_4c/output_0_split
I0810 21:05:19.838908   463 net.cpp:94] Creating Layer inception_4c/output_inception_4c/output_0_split
I0810 21:05:19.838914   463 net.cpp:435] inception_4c/output_inception_4c/output_0_split <- inception_4c/output
I0810 21:05:19.838924   463 net.cpp:409] inception_4c/output_inception_4c/output_0_split -> inception_4c/output_inception_4c/output_0_split_0
I0810 21:05:19.838934   463 net.cpp:409] inception_4c/output_inception_4c/output_0_split -> inception_4c/output_inception_4c/output_0_split_1
I0810 21:05:19.838944   463 net.cpp:409] inception_4c/output_inception_4c/output_0_split -> inception_4c/output_inception_4c/output_0_split_2
I0810 21:05:19.838953   463 net.cpp:409] inception_4c/output_inception_4c/output_0_split -> inception_4c/output_inception_4c/output_0_split_3
I0810 21:05:19.839015   463 net.cpp:144] Setting up inception_4c/output_inception_4c/output_0_split
I0810 21:05:19.839025   463 net.cpp:151] Top shape: 10 512 40 40 (8192000)
I0810 21:05:19.839031   463 net.cpp:151] Top shape: 10 512 40 40 (8192000)
I0810 21:05:19.839038   463 net.cpp:151] Top shape: 10 512 40 40 (8192000)
I0810 21:05:19.839047   463 net.cpp:151] Top shape: 10 512 40 40 (8192000)
I0810 21:05:19.839052   463 net.cpp:159] Memory required for data: 3837506080
I0810 21:05:19.839058   463 layer_factory.hpp:77] Creating layer inception_4d/1x1
I0810 21:05:19.839083   463 net.cpp:94] Creating Layer inception_4d/1x1
I0810 21:05:19.839092   463 net.cpp:435] inception_4d/1x1 <- inception_4c/output_inception_4c/output_0_split_0
I0810 21:05:19.839102   463 net.cpp:409] inception_4d/1x1 -> inception_4d/1x1
I0810 21:05:19.839643   463 net.cpp:144] Setting up inception_4d/1x1
I0810 21:05:19.839665   463 net.cpp:151] Top shape: 10 112 40 40 (1792000)
I0810 21:05:19.839671   463 net.cpp:159] Memory required for data: 3844674080
I0810 21:05:19.839681   463 layer_factory.hpp:77] Creating layer inception_4d/relu_1x1
I0810 21:05:19.839690   463 net.cpp:94] Creating Layer inception_4d/relu_1x1
I0810 21:05:19.839697   463 net.cpp:435] inception_4d/relu_1x1 <- inception_4d/1x1
I0810 21:05:19.839706   463 net.cpp:396] inception_4d/relu_1x1 -> inception_4d/1x1 (in-place)
I0810 21:05:19.839716   463 net.cpp:144] Setting up inception_4d/relu_1x1
I0810 21:05:19.839725   463 net.cpp:151] Top shape: 10 112 40 40 (1792000)
I0810 21:05:19.839730   463 net.cpp:159] Memory required for data: 3851842080
I0810 21:05:19.839736   463 layer_factory.hpp:77] Creating layer inception_4d/3x3_reduce
I0810 21:05:19.839747   463 net.cpp:94] Creating Layer inception_4d/3x3_reduce
I0810 21:05:19.839753   463 net.cpp:435] inception_4d/3x3_reduce <- inception_4c/output_inception_4c/output_0_split_1
I0810 21:05:19.839764   463 net.cpp:409] inception_4d/3x3_reduce -> inception_4d/3x3_reduce
I0810 21:05:19.840426   463 net.cpp:144] Setting up inception_4d/3x3_reduce
I0810 21:05:19.840438   463 net.cpp:151] Top shape: 10 144 40 40 (2304000)
I0810 21:05:19.840445   463 net.cpp:159] Memory required for data: 3861058080
I0810 21:05:19.840453   463 layer_factory.hpp:77] Creating layer inception_4d/relu_3x3_reduce
I0810 21:05:19.840462   463 net.cpp:94] Creating Layer inception_4d/relu_3x3_reduce
I0810 21:05:19.840469   463 net.cpp:435] inception_4d/relu_3x3_reduce <- inception_4d/3x3_reduce
I0810 21:05:19.840477   463 net.cpp:396] inception_4d/relu_3x3_reduce -> inception_4d/3x3_reduce (in-place)
I0810 21:05:19.840487   463 net.cpp:144] Setting up inception_4d/relu_3x3_reduce
I0810 21:05:19.840494   463 net.cpp:151] Top shape: 10 144 40 40 (2304000)
I0810 21:05:19.840500   463 net.cpp:159] Memory required for data: 3870274080
I0810 21:05:19.840507   463 layer_factory.hpp:77] Creating layer inception_4d/3x3
I0810 21:05:19.840517   463 net.cpp:94] Creating Layer inception_4d/3x3
I0810 21:05:19.840523   463 net.cpp:435] inception_4d/3x3 <- inception_4d/3x3_reduce
I0810 21:05:19.840533   463 net.cpp:409] inception_4d/3x3 -> inception_4d/3x3
I0810 21:05:19.844781   463 net.cpp:144] Setting up inception_4d/3x3
I0810 21:05:19.844805   463 net.cpp:151] Top shape: 10 288 40 40 (4608000)
I0810 21:05:19.844811   463 net.cpp:159] Memory required for data: 3888706080
I0810 21:05:19.844822   463 layer_factory.hpp:77] Creating layer inception_4d/relu_3x3
I0810 21:05:19.844833   463 net.cpp:94] Creating Layer inception_4d/relu_3x3
I0810 21:05:19.844841   463 net.cpp:435] inception_4d/relu_3x3 <- inception_4d/3x3
I0810 21:05:19.844851   463 net.cpp:396] inception_4d/relu_3x3 -> inception_4d/3x3 (in-place)
I0810 21:05:19.844864   463 net.cpp:144] Setting up inception_4d/relu_3x3
I0810 21:05:19.844871   463 net.cpp:151] Top shape: 10 288 40 40 (4608000)
I0810 21:05:19.844877   463 net.cpp:159] Memory required for data: 3907138080
I0810 21:05:19.844915   463 layer_factory.hpp:77] Creating layer inception_4d/5x5_reduce
I0810 21:05:19.844929   463 net.cpp:94] Creating Layer inception_4d/5x5_reduce
I0810 21:05:19.844938   463 net.cpp:435] inception_4d/5x5_reduce <- inception_4c/output_inception_4c/output_0_split_2
I0810 21:05:19.844947   463 net.cpp:409] inception_4d/5x5_reduce -> inception_4d/5x5_reduce
I0810 21:05:19.845305   463 net.cpp:144] Setting up inception_4d/5x5_reduce
I0810 21:05:19.845319   463 net.cpp:151] Top shape: 10 32 40 40 (512000)
I0810 21:05:19.845325   463 net.cpp:159] Memory required for data: 3909186080
I0810 21:05:19.845335   463 layer_factory.hpp:77] Creating layer inception_4d/relu_5x5_reduce
I0810 21:05:19.845368   463 net.cpp:94] Creating Layer inception_4d/relu_5x5_reduce
I0810 21:05:19.845376   463 net.cpp:435] inception_4d/relu_5x5_reduce <- inception_4d/5x5_reduce
I0810 21:05:19.845386   463 net.cpp:396] inception_4d/relu_5x5_reduce -> inception_4d/5x5_reduce (in-place)
I0810 21:05:19.845396   463 net.cpp:144] Setting up inception_4d/relu_5x5_reduce
I0810 21:05:19.845403   463 net.cpp:151] Top shape: 10 32 40 40 (512000)
I0810 21:05:19.845409   463 net.cpp:159] Memory required for data: 3911234080
I0810 21:05:19.845415   463 layer_factory.hpp:77] Creating layer inception_4d/5x5
I0810 21:05:19.845427   463 net.cpp:94] Creating Layer inception_4d/5x5
I0810 21:05:19.845432   463 net.cpp:435] inception_4d/5x5 <- inception_4d/5x5_reduce
I0810 21:05:19.845443   463 net.cpp:409] inception_4d/5x5 -> inception_4d/5x5
I0810 21:05:19.846007   463 net.cpp:144] Setting up inception_4d/5x5
I0810 21:05:19.846021   463 net.cpp:151] Top shape: 10 64 40 40 (1024000)
I0810 21:05:19.846027   463 net.cpp:159] Memory required for data: 3915330080
I0810 21:05:19.846036   463 layer_factory.hpp:77] Creating layer inception_4d/relu_5x5
I0810 21:05:19.846046   463 net.cpp:94] Creating Layer inception_4d/relu_5x5
I0810 21:05:19.846053   463 net.cpp:435] inception_4d/relu_5x5 <- inception_4d/5x5
I0810 21:05:19.846062   463 net.cpp:396] inception_4d/relu_5x5 -> inception_4d/5x5 (in-place)
I0810 21:05:19.846073   463 net.cpp:144] Setting up inception_4d/relu_5x5
I0810 21:05:19.846081   463 net.cpp:151] Top shape: 10 64 40 40 (1024000)
I0810 21:05:19.846086   463 net.cpp:159] Memory required for data: 3919426080
I0810 21:05:19.846092   463 layer_factory.hpp:77] Creating layer inception_4d/pool
I0810 21:05:19.846102   463 net.cpp:94] Creating Layer inception_4d/pool
I0810 21:05:19.846109   463 net.cpp:435] inception_4d/pool <- inception_4c/output_inception_4c/output_0_split_3
I0810 21:05:19.846118   463 net.cpp:409] inception_4d/pool -> inception_4d/pool
I0810 21:05:19.846168   463 net.cpp:144] Setting up inception_4d/pool
I0810 21:05:19.846179   463 net.cpp:151] Top shape: 10 512 40 40 (8192000)
I0810 21:05:19.846184   463 net.cpp:159] Memory required for data: 3952194080
I0810 21:05:19.846190   463 layer_factory.hpp:77] Creating layer inception_4d/pool_proj
I0810 21:05:19.846202   463 net.cpp:94] Creating Layer inception_4d/pool_proj
I0810 21:05:19.846210   463 net.cpp:435] inception_4d/pool_proj <- inception_4d/pool
I0810 21:05:19.846220   463 net.cpp:409] inception_4d/pool_proj -> inception_4d/pool_proj
I0810 21:05:19.846637   463 net.cpp:144] Setting up inception_4d/pool_proj
I0810 21:05:19.846698   463 net.cpp:151] Top shape: 10 64 40 40 (1024000)
I0810 21:05:19.846706   463 net.cpp:159] Memory required for data: 3956290080
I0810 21:05:19.846715   463 layer_factory.hpp:77] Creating layer inception_4d/relu_pool_proj
I0810 21:05:19.846725   463 net.cpp:94] Creating Layer inception_4d/relu_pool_proj
I0810 21:05:19.846732   463 net.cpp:435] inception_4d/relu_pool_proj <- inception_4d/pool_proj
I0810 21:05:19.846742   463 net.cpp:396] inception_4d/relu_pool_proj -> inception_4d/pool_proj (in-place)
I0810 21:05:19.846753   463 net.cpp:144] Setting up inception_4d/relu_pool_proj
I0810 21:05:19.846760   463 net.cpp:151] Top shape: 10 64 40 40 (1024000)
I0810 21:05:19.846766   463 net.cpp:159] Memory required for data: 3960386080
I0810 21:05:19.846772   463 layer_factory.hpp:77] Creating layer inception_4d/output
I0810 21:05:19.846781   463 net.cpp:94] Creating Layer inception_4d/output
I0810 21:05:19.846788   463 net.cpp:435] inception_4d/output <- inception_4d/1x1
I0810 21:05:19.846796   463 net.cpp:435] inception_4d/output <- inception_4d/3x3
I0810 21:05:19.846803   463 net.cpp:435] inception_4d/output <- inception_4d/5x5
I0810 21:05:19.846812   463 net.cpp:435] inception_4d/output <- inception_4d/pool_proj
I0810 21:05:19.846822   463 net.cpp:409] inception_4d/output -> inception_4d/output
I0810 21:05:19.846856   463 net.cpp:144] Setting up inception_4d/output
I0810 21:05:19.846866   463 net.cpp:151] Top shape: 10 528 40 40 (8448000)
I0810 21:05:19.846886   463 net.cpp:159] Memory required for data: 3994178080
I0810 21:05:19.846894   463 layer_factory.hpp:77] Creating layer inception_4d/output_inception_4d/output_0_split
I0810 21:05:19.846904   463 net.cpp:94] Creating Layer inception_4d/output_inception_4d/output_0_split
I0810 21:05:19.846910   463 net.cpp:435] inception_4d/output_inception_4d/output_0_split <- inception_4d/output
I0810 21:05:19.846920   463 net.cpp:409] inception_4d/output_inception_4d/output_0_split -> inception_4d/output_inception_4d/output_0_split_0
I0810 21:05:19.846931   463 net.cpp:409] inception_4d/output_inception_4d/output_0_split -> inception_4d/output_inception_4d/output_0_split_1
I0810 21:05:19.846942   463 net.cpp:409] inception_4d/output_inception_4d/output_0_split -> inception_4d/output_inception_4d/output_0_split_2
I0810 21:05:19.846951   463 net.cpp:409] inception_4d/output_inception_4d/output_0_split -> inception_4d/output_inception_4d/output_0_split_3
I0810 21:05:19.847014   463 net.cpp:144] Setting up inception_4d/output_inception_4d/output_0_split
I0810 21:05:19.847024   463 net.cpp:151] Top shape: 10 528 40 40 (8448000)
I0810 21:05:19.847031   463 net.cpp:151] Top shape: 10 528 40 40 (8448000)
I0810 21:05:19.847038   463 net.cpp:151] Top shape: 10 528 40 40 (8448000)
I0810 21:05:19.847044   463 net.cpp:151] Top shape: 10 528 40 40 (8448000)
I0810 21:05:19.847050   463 net.cpp:159] Memory required for data: 4129346080
I0810 21:05:19.847056   463 layer_factory.hpp:77] Creating layer inception_4e/1x1
I0810 21:05:19.847067   463 net.cpp:94] Creating Layer inception_4e/1x1
I0810 21:05:19.847074   463 net.cpp:435] inception_4e/1x1 <- inception_4d/output_inception_4d/output_0_split_0
I0810 21:05:19.847085   463 net.cpp:409] inception_4e/1x1 -> inception_4e/1x1
I0810 21:05:19.848984   463 net.cpp:144] Setting up inception_4e/1x1
I0810 21:05:19.849002   463 net.cpp:151] Top shape: 10 256 40 40 (4096000)
I0810 21:05:19.849009   463 net.cpp:159] Memory required for data: 4145730080
I0810 21:05:19.849020   463 layer_factory.hpp:77] Creating layer inception_4e/relu_1x1
I0810 21:05:19.849030   463 net.cpp:94] Creating Layer inception_4e/relu_1x1
I0810 21:05:19.849037   463 net.cpp:435] inception_4e/relu_1x1 <- inception_4e/1x1
I0810 21:05:19.849047   463 net.cpp:396] inception_4e/relu_1x1 -> inception_4e/1x1 (in-place)
I0810 21:05:19.849059   463 net.cpp:144] Setting up inception_4e/relu_1x1
I0810 21:05:19.849067   463 net.cpp:151] Top shape: 10 256 40 40 (4096000)
I0810 21:05:19.849072   463 net.cpp:159] Memory required for data: 4162114080
I0810 21:05:19.849078   463 layer_factory.hpp:77] Creating layer inception_4e/3x3_reduce
I0810 21:05:19.849090   463 net.cpp:94] Creating Layer inception_4e/3x3_reduce
I0810 21:05:19.849097   463 net.cpp:435] inception_4e/3x3_reduce <- inception_4d/output_inception_4d/output_0_split_1
I0810 21:05:19.849109   463 net.cpp:409] inception_4e/3x3_reduce -> inception_4e/3x3_reduce
I0810 21:05:19.850162   463 net.cpp:144] Setting up inception_4e/3x3_reduce
I0810 21:05:19.850179   463 net.cpp:151] Top shape: 10 160 40 40 (2560000)
I0810 21:05:19.850185   463 net.cpp:159] Memory required for data: 4172354080
I0810 21:05:19.850194   463 layer_factory.hpp:77] Creating layer inception_4e/relu_3x3_reduce
I0810 21:05:19.850204   463 net.cpp:94] Creating Layer inception_4e/relu_3x3_reduce
I0810 21:05:19.850212   463 net.cpp:435] inception_4e/relu_3x3_reduce <- inception_4e/3x3_reduce
I0810 21:05:19.850222   463 net.cpp:396] inception_4e/relu_3x3_reduce -> inception_4e/3x3_reduce (in-place)
I0810 21:05:19.850234   463 net.cpp:144] Setting up inception_4e/relu_3x3_reduce
I0810 21:05:19.850240   463 net.cpp:151] Top shape: 10 160 40 40 (2560000)
I0810 21:05:19.850246   463 net.cpp:159] Memory required for data: 4182594080
I0810 21:05:19.850252   463 layer_factory.hpp:77] Creating layer inception_4e/3x3
I0810 21:05:19.850265   463 net.cpp:94] Creating Layer inception_4e/3x3
I0810 21:05:19.850272   463 net.cpp:435] inception_4e/3x3 <- inception_4e/3x3_reduce
I0810 21:05:19.850283   463 net.cpp:409] inception_4e/3x3 -> inception_4e/3x3
I0810 21:05:19.863759   463 net.cpp:144] Setting up inception_4e/3x3
I0810 21:05:19.863790   463 net.cpp:151] Top shape: 10 320 40 40 (5120000)
I0810 21:05:19.863797   463 net.cpp:159] Memory required for data: 4203074080
I0810 21:05:19.863811   463 layer_factory.hpp:77] Creating layer inception_4e/relu_3x3
I0810 21:05:19.863823   463 net.cpp:94] Creating Layer inception_4e/relu_3x3
I0810 21:05:19.863832   463 net.cpp:435] inception_4e/relu_3x3 <- inception_4e/3x3
I0810 21:05:19.863843   463 net.cpp:396] inception_4e/relu_3x3 -> inception_4e/3x3 (in-place)
I0810 21:05:19.863860   463 net.cpp:144] Setting up inception_4e/relu_3x3
I0810 21:05:19.863867   463 net.cpp:151] Top shape: 10 320 40 40 (5120000)
I0810 21:05:19.863873   463 net.cpp:159] Memory required for data: 4223554080
I0810 21:05:19.863879   463 layer_factory.hpp:77] Creating layer inception_4e/5x5_reduce
I0810 21:05:19.863893   463 net.cpp:94] Creating Layer inception_4e/5x5_reduce
I0810 21:05:19.863900   463 net.cpp:435] inception_4e/5x5_reduce <- inception_4d/output_inception_4d/output_0_split_2
I0810 21:05:19.863911   463 net.cpp:409] inception_4e/5x5_reduce -> inception_4e/5x5_reduce
I0810 21:05:19.864269   463 net.cpp:144] Setting up inception_4e/5x5_reduce
I0810 21:05:19.864281   463 net.cpp:151] Top shape: 10 32 40 40 (512000)
I0810 21:05:19.864287   463 net.cpp:159] Memory required for data: 4225602080
I0810 21:05:19.864296   463 layer_factory.hpp:77] Creating layer inception_4e/relu_5x5_reduce
I0810 21:05:19.864305   463 net.cpp:94] Creating Layer inception_4e/relu_5x5_reduce
I0810 21:05:19.864312   463 net.cpp:435] inception_4e/relu_5x5_reduce <- inception_4e/5x5_reduce
I0810 21:05:19.864321   463 net.cpp:396] inception_4e/relu_5x5_reduce -> inception_4e/5x5_reduce (in-place)
I0810 21:05:19.864332   463 net.cpp:144] Setting up inception_4e/relu_5x5_reduce
I0810 21:05:19.864339   463 net.cpp:151] Top shape: 10 32 40 40 (512000)
I0810 21:05:19.864346   463 net.cpp:159] Memory required for data: 4227650080
I0810 21:05:19.864351   463 layer_factory.hpp:77] Creating layer inception_4e/5x5
I0810 21:05:19.864362   463 net.cpp:94] Creating Layer inception_4e/5x5
I0810 21:05:19.864369   463 net.cpp:435] inception_4e/5x5 <- inception_4e/5x5_reduce
I0810 21:05:19.864379   463 net.cpp:409] inception_4e/5x5 -> inception_4e/5x5
I0810 21:05:19.869689   463 net.cpp:144] Setting up inception_4e/5x5
I0810 21:05:19.869732   463 net.cpp:151] Top shape: 10 128 40 40 (2048000)
I0810 21:05:19.869740   463 net.cpp:159] Memory required for data: 4235842080
I0810 21:05:19.869752   463 layer_factory.hpp:77] Creating layer inception_4e/relu_5x5
I0810 21:05:19.869766   463 net.cpp:94] Creating Layer inception_4e/relu_5x5
I0810 21:05:19.869776   463 net.cpp:435] inception_4e/relu_5x5 <- inception_4e/5x5
I0810 21:05:19.869789   463 net.cpp:396] inception_4e/relu_5x5 -> inception_4e/5x5 (in-place)
I0810 21:05:19.869805   463 net.cpp:144] Setting up inception_4e/relu_5x5
I0810 21:05:19.869813   463 net.cpp:151] Top shape: 10 128 40 40 (2048000)
I0810 21:05:19.869819   463 net.cpp:159] Memory required for data: 4244034080
I0810 21:05:19.869825   463 layer_factory.hpp:77] Creating layer inception_4e/pool
I0810 21:05:19.869837   463 net.cpp:94] Creating Layer inception_4e/pool
I0810 21:05:19.869844   463 net.cpp:435] inception_4e/pool <- inception_4d/output_inception_4d/output_0_split_3
I0810 21:05:19.869854   463 net.cpp:409] inception_4e/pool -> inception_4e/pool
I0810 21:05:19.869963   463 net.cpp:144] Setting up inception_4e/pool
I0810 21:05:19.869976   463 net.cpp:151] Top shape: 10 528 40 40 (8448000)
I0810 21:05:19.869982   463 net.cpp:159] Memory required for data: 4277826080
I0810 21:05:19.869989   463 layer_factory.hpp:77] Creating layer inception_4e/pool_proj
I0810 21:05:19.870005   463 net.cpp:94] Creating Layer inception_4e/pool_proj
I0810 21:05:19.870012   463 net.cpp:435] inception_4e/pool_proj <- inception_4e/pool
I0810 21:05:19.870023   463 net.cpp:409] inception_4e/pool_proj -> inception_4e/pool_proj
I0810 21:05:19.870775   463 net.cpp:144] Setting up inception_4e/pool_proj
I0810 21:05:19.870790   463 net.cpp:151] Top shape: 10 128 40 40 (2048000)
I0810 21:05:19.870796   463 net.cpp:159] Memory required for data: 4286018080
I0810 21:05:19.870806   463 layer_factory.hpp:77] Creating layer inception_4e/relu_pool_proj
I0810 21:05:19.870856   463 net.cpp:94] Creating Layer inception_4e/relu_pool_proj
I0810 21:05:19.870863   463 net.cpp:435] inception_4e/relu_pool_proj <- inception_4e/pool_proj
I0810 21:05:19.870872   463 net.cpp:396] inception_4e/relu_pool_proj -> inception_4e/pool_proj (in-place)
I0810 21:05:19.870883   463 net.cpp:144] Setting up inception_4e/relu_pool_proj
I0810 21:05:19.870890   463 net.cpp:151] Top shape: 10 128 40 40 (2048000)
I0810 21:05:19.870896   463 net.cpp:159] Memory required for data: 4294210080
I0810 21:05:19.870903   463 layer_factory.hpp:77] Creating layer inception_4e/output
I0810 21:05:19.870913   463 net.cpp:94] Creating Layer inception_4e/output
I0810 21:05:19.870918   463 net.cpp:435] inception_4e/output <- inception_4e/1x1
I0810 21:05:19.870926   463 net.cpp:435] inception_4e/output <- inception_4e/3x3
I0810 21:05:19.870934   463 net.cpp:435] inception_4e/output <- inception_4e/5x5
I0810 21:05:19.870941   463 net.cpp:435] inception_4e/output <- inception_4e/pool_proj
I0810 21:05:19.870949   463 net.cpp:409] inception_4e/output -> inception_4e/output
I0810 21:05:19.870983   463 net.cpp:144] Setting up inception_4e/output
I0810 21:05:19.870993   463 net.cpp:151] Top shape: 10 832 40 40 (13312000)
I0810 21:05:19.870998   463 net.cpp:159] Memory required for data: 4347458080
I0810 21:05:19.871004   463 layer_factory.hpp:77] Creating layer inception_4e/output_inception_4e/output_0_split
I0810 21:05:19.871014   463 net.cpp:94] Creating Layer inception_4e/output_inception_4e/output_0_split
I0810 21:05:19.871021   463 net.cpp:435] inception_4e/output_inception_4e/output_0_split <- inception_4e/output
I0810 21:05:19.871029   463 net.cpp:409] inception_4e/output_inception_4e/output_0_split -> inception_4e/output_inception_4e/output_0_split_0
I0810 21:05:19.871040   463 net.cpp:409] inception_4e/output_inception_4e/output_0_split -> inception_4e/output_inception_4e/output_0_split_1
I0810 21:05:19.871050   463 net.cpp:409] inception_4e/output_inception_4e/output_0_split -> inception_4e/output_inception_4e/output_0_split_2
I0810 21:05:19.871060   463 net.cpp:409] inception_4e/output_inception_4e/output_0_split -> inception_4e/output_inception_4e/output_0_split_3
I0810 21:05:19.871125   463 net.cpp:144] Setting up inception_4e/output_inception_4e/output_0_split
I0810 21:05:19.871134   463 net.cpp:151] Top shape: 10 832 40 40 (13312000)
I0810 21:05:19.871140   463 net.cpp:151] Top shape: 10 832 40 40 (13312000)
I0810 21:05:19.871148   463 net.cpp:151] Top shape: 10 832 40 40 (13312000)
I0810 21:05:19.871157   463 net.cpp:151] Top shape: 10 832 40 40 (13312000)
I0810 21:05:19.871163   463 net.cpp:159] Memory required for data: 4560450080
I0810 21:05:19.871170   463 layer_factory.hpp:77] Creating layer inception_5a/1x1
I0810 21:05:19.871182   463 net.cpp:94] Creating Layer inception_5a/1x1
I0810 21:05:19.871188   463 net.cpp:435] inception_5a/1x1 <- inception_4e/output_inception_4e/output_0_split_0
I0810 21:05:19.871199   463 net.cpp:409] inception_5a/1x1 -> inception_5a/1x1
I0810 21:05:19.891589   463 net.cpp:144] Setting up inception_5a/1x1
I0810 21:05:19.891633   463 net.cpp:151] Top shape: 10 256 40 40 (4096000)
I0810 21:05:19.891639   463 net.cpp:159] Memory required for data: 4576834080
I0810 21:05:19.891662   463 layer_factory.hpp:77] Creating layer inception_5a/relu_1x1
I0810 21:05:19.891680   463 net.cpp:94] Creating Layer inception_5a/relu_1x1
I0810 21:05:19.891690   463 net.cpp:435] inception_5a/relu_1x1 <- inception_5a/1x1
I0810 21:05:19.891703   463 net.cpp:396] inception_5a/relu_1x1 -> inception_5a/1x1 (in-place)
I0810 21:05:19.891721   463 net.cpp:144] Setting up inception_5a/relu_1x1
I0810 21:05:19.891729   463 net.cpp:151] Top shape: 10 256 40 40 (4096000)
I0810 21:05:19.891736   463 net.cpp:159] Memory required for data: 4593218080
I0810 21:05:19.891778   463 layer_factory.hpp:77] Creating layer inception_5a/3x3_reduce
I0810 21:05:19.891795   463 net.cpp:94] Creating Layer inception_5a/3x3_reduce
I0810 21:05:19.891803   463 net.cpp:435] inception_5a/3x3_reduce <- inception_4e/output_inception_4e/output_0_split_1
I0810 21:05:19.891815   463 net.cpp:409] inception_5a/3x3_reduce -> inception_5a/3x3_reduce
I0810 21:05:19.893712   463 net.cpp:144] Setting up inception_5a/3x3_reduce
I0810 21:05:19.893733   463 net.cpp:151] Top shape: 10 160 40 40 (2560000)
I0810 21:05:19.893738   463 net.cpp:159] Memory required for data: 4603458080
I0810 21:05:19.893749   463 layer_factory.hpp:77] Creating layer inception_5a/relu_3x3_reduce
I0810 21:05:19.893760   463 net.cpp:94] Creating Layer inception_5a/relu_3x3_reduce
I0810 21:05:19.893769   463 net.cpp:435] inception_5a/relu_3x3_reduce <- inception_5a/3x3_reduce
I0810 21:05:19.893779   463 net.cpp:396] inception_5a/relu_3x3_reduce -> inception_5a/3x3_reduce (in-place)
I0810 21:05:19.893791   463 net.cpp:144] Setting up inception_5a/relu_3x3_reduce
I0810 21:05:19.893798   463 net.cpp:151] Top shape: 10 160 40 40 (2560000)
I0810 21:05:19.893805   463 net.cpp:159] Memory required for data: 4613698080
I0810 21:05:19.893810   463 layer_factory.hpp:77] Creating layer inception_5a/3x3
I0810 21:05:19.893824   463 net.cpp:94] Creating Layer inception_5a/3x3
I0810 21:05:19.893831   463 net.cpp:435] inception_5a/3x3 <- inception_5a/3x3_reduce
I0810 21:05:19.893842   463 net.cpp:409] inception_5a/3x3 -> inception_5a/3x3
I0810 21:05:19.907948   463 net.cpp:144] Setting up inception_5a/3x3
I0810 21:05:19.907997   463 net.cpp:151] Top shape: 10 320 40 40 (5120000)
I0810 21:05:19.908004   463 net.cpp:159] Memory required for data: 4634178080
I0810 21:05:19.908018   463 layer_factory.hpp:77] Creating layer inception_5a/relu_3x3
I0810 21:05:19.908035   463 net.cpp:94] Creating Layer inception_5a/relu_3x3
I0810 21:05:19.908044   463 net.cpp:435] inception_5a/relu_3x3 <- inception_5a/3x3
I0810 21:05:19.908057   463 net.cpp:396] inception_5a/relu_3x3 -> inception_5a/3x3 (in-place)
I0810 21:05:19.908076   463 net.cpp:144] Setting up inception_5a/relu_3x3
I0810 21:05:19.908083   463 net.cpp:151] Top shape: 10 320 40 40 (5120000)
I0810 21:05:19.908088   463 net.cpp:159] Memory required for data: 4654658080
I0810 21:05:19.908095   463 layer_factory.hpp:77] Creating layer inception_5a/5x5_reduce
I0810 21:05:19.908110   463 net.cpp:94] Creating Layer inception_5a/5x5_reduce
I0810 21:05:19.908118   463 net.cpp:435] inception_5a/5x5_reduce <- inception_4e/output_inception_4e/output_0_split_2
I0810 21:05:19.908129   463 net.cpp:409] inception_5a/5x5_reduce -> inception_5a/5x5_reduce
I0810 21:05:19.908658   463 net.cpp:144] Setting up inception_5a/5x5_reduce
I0810 21:05:19.908674   463 net.cpp:151] Top shape: 10 32 40 40 (512000)
I0810 21:05:19.908679   463 net.cpp:159] Memory required for data: 4656706080
I0810 21:05:19.908689   463 layer_factory.hpp:77] Creating layer inception_5a/relu_5x5_reduce
I0810 21:05:19.908699   463 net.cpp:94] Creating Layer inception_5a/relu_5x5_reduce
I0810 21:05:19.908707   463 net.cpp:435] inception_5a/relu_5x5_reduce <- inception_5a/5x5_reduce
I0810 21:05:19.908716   463 net.cpp:396] inception_5a/relu_5x5_reduce -> inception_5a/5x5_reduce (in-place)
I0810 21:05:19.908728   463 net.cpp:144] Setting up inception_5a/relu_5x5_reduce
I0810 21:05:19.908735   463 net.cpp:151] Top shape: 10 32 40 40 (512000)
I0810 21:05:19.908741   463 net.cpp:159] Memory required for data: 4658754080
I0810 21:05:19.908748   463 layer_factory.hpp:77] Creating layer inception_5a/5x5
I0810 21:05:19.908761   463 net.cpp:94] Creating Layer inception_5a/5x5
I0810 21:05:19.908767   463 net.cpp:435] inception_5a/5x5 <- inception_5a/5x5_reduce
I0810 21:05:19.908778   463 net.cpp:409] inception_5a/5x5 -> inception_5a/5x5
I0810 21:05:19.909979   463 net.cpp:144] Setting up inception_5a/5x5
I0810 21:05:19.909998   463 net.cpp:151] Top shape: 10 128 40 40 (2048000)
I0810 21:05:19.910006   463 net.cpp:159] Memory required for data: 4666946080
I0810 21:05:19.910056   463 layer_factory.hpp:77] Creating layer inception_5a/relu_5x5
I0810 21:05:19.910068   463 net.cpp:94] Creating Layer inception_5a/relu_5x5
I0810 21:05:19.910075   463 net.cpp:435] inception_5a/relu_5x5 <- inception_5a/5x5
I0810 21:05:19.910084   463 net.cpp:396] inception_5a/relu_5x5 -> inception_5a/5x5 (in-place)
I0810 21:05:19.910096   463 net.cpp:144] Setting up inception_5a/relu_5x5
I0810 21:05:19.910104   463 net.cpp:151] Top shape: 10 128 40 40 (2048000)
I0810 21:05:19.910109   463 net.cpp:159] Memory required for data: 4675138080
I0810 21:05:19.910116   463 layer_factory.hpp:77] Creating layer inception_5a/pool
I0810 21:05:19.910127   463 net.cpp:94] Creating Layer inception_5a/pool
I0810 21:05:19.910135   463 net.cpp:435] inception_5a/pool <- inception_4e/output_inception_4e/output_0_split_3
I0810 21:05:19.910143   463 net.cpp:409] inception_5a/pool -> inception_5a/pool
I0810 21:05:19.910200   463 net.cpp:144] Setting up inception_5a/pool
I0810 21:05:19.910212   463 net.cpp:151] Top shape: 10 832 40 40 (13312000)
I0810 21:05:19.910218   463 net.cpp:159] Memory required for data: 4728386080
I0810 21:05:19.910223   463 layer_factory.hpp:77] Creating layer inception_5a/pool_proj
I0810 21:05:19.910236   463 net.cpp:94] Creating Layer inception_5a/pool_proj
I0810 21:05:19.910243   463 net.cpp:435] inception_5a/pool_proj <- inception_5a/pool
I0810 21:05:19.910254   463 net.cpp:409] inception_5a/pool_proj -> inception_5a/pool_proj
I0810 21:05:19.912039   463 net.cpp:144] Setting up inception_5a/pool_proj
I0810 21:05:19.912060   463 net.cpp:151] Top shape: 10 128 40 40 (2048000)
I0810 21:05:19.912065   463 net.cpp:159] Memory required for data: 4736578080
I0810 21:05:19.912075   463 layer_factory.hpp:77] Creating layer inception_5a/relu_pool_proj
I0810 21:05:19.912086   463 net.cpp:94] Creating Layer inception_5a/relu_pool_proj
I0810 21:05:19.912093   463 net.cpp:435] inception_5a/relu_pool_proj <- inception_5a/pool_proj
I0810 21:05:19.912104   463 net.cpp:396] inception_5a/relu_pool_proj -> inception_5a/pool_proj (in-place)
I0810 21:05:19.912115   463 net.cpp:144] Setting up inception_5a/relu_pool_proj
I0810 21:05:19.912123   463 net.cpp:151] Top shape: 10 128 40 40 (2048000)
I0810 21:05:19.912128   463 net.cpp:159] Memory required for data: 4744770080
I0810 21:05:19.912134   463 layer_factory.hpp:77] Creating layer inception_5a/output
I0810 21:05:19.912144   463 net.cpp:94] Creating Layer inception_5a/output
I0810 21:05:19.912153   463 net.cpp:435] inception_5a/output <- inception_5a/1x1
I0810 21:05:19.912160   463 net.cpp:435] inception_5a/output <- inception_5a/3x3
I0810 21:05:19.912168   463 net.cpp:435] inception_5a/output <- inception_5a/5x5
I0810 21:05:19.912175   463 net.cpp:435] inception_5a/output <- inception_5a/pool_proj
I0810 21:05:19.912185   463 net.cpp:409] inception_5a/output -> inception_5a/output
I0810 21:05:19.912220   463 net.cpp:144] Setting up inception_5a/output
I0810 21:05:19.912230   463 net.cpp:151] Top shape: 10 832 40 40 (13312000)
I0810 21:05:19.912235   463 net.cpp:159] Memory required for data: 4798018080
I0810 21:05:19.912241   463 layer_factory.hpp:77] Creating layer inception_5a/output_inception_5a/output_0_split
I0810 21:05:19.912252   463 net.cpp:94] Creating Layer inception_5a/output_inception_5a/output_0_split
I0810 21:05:19.912259   463 net.cpp:435] inception_5a/output_inception_5a/output_0_split <- inception_5a/output
I0810 21:05:19.912269   463 net.cpp:409] inception_5a/output_inception_5a/output_0_split -> inception_5a/output_inception_5a/output_0_split_0
I0810 21:05:19.912281   463 net.cpp:409] inception_5a/output_inception_5a/output_0_split -> inception_5a/output_inception_5a/output_0_split_1
I0810 21:05:19.912292   463 net.cpp:409] inception_5a/output_inception_5a/output_0_split -> inception_5a/output_inception_5a/output_0_split_2
I0810 21:05:19.912302   463 net.cpp:409] inception_5a/output_inception_5a/output_0_split -> inception_5a/output_inception_5a/output_0_split_3
I0810 21:05:19.912364   463 net.cpp:144] Setting up inception_5a/output_inception_5a/output_0_split
I0810 21:05:19.912394   463 net.cpp:151] Top shape: 10 832 40 40 (13312000)
I0810 21:05:19.912400   463 net.cpp:151] Top shape: 10 832 40 40 (13312000)
I0810 21:05:19.912407   463 net.cpp:151] Top shape: 10 832 40 40 (13312000)
I0810 21:05:19.912415   463 net.cpp:151] Top shape: 10 832 40 40 (13312000)
I0810 21:05:19.912420   463 net.cpp:159] Memory required for data: 5011010080
I0810 21:05:19.912426   463 layer_factory.hpp:77] Creating layer inception_5b/1x1
I0810 21:05:19.912438   463 net.cpp:94] Creating Layer inception_5b/1x1
I0810 21:05:19.912446   463 net.cpp:435] inception_5b/1x1 <- inception_5a/output_inception_5a/output_0_split_0
I0810 21:05:19.912456   463 net.cpp:409] inception_5b/1x1 -> inception_5b/1x1
I0810 21:05:19.915249   463 net.cpp:144] Setting up inception_5b/1x1
I0810 21:05:19.915268   463 net.cpp:151] Top shape: 10 384 40 40 (6144000)
I0810 21:05:19.915274   463 net.cpp:159] Memory required for data: 5035586080
I0810 21:05:19.915284   463 layer_factory.hpp:77] Creating layer inception_5b/relu_1x1
I0810 21:05:19.915295   463 net.cpp:94] Creating Layer inception_5b/relu_1x1
I0810 21:05:19.915303   463 net.cpp:435] inception_5b/relu_1x1 <- inception_5b/1x1
I0810 21:05:19.915313   463 net.cpp:396] inception_5b/relu_1x1 -> inception_5b/1x1 (in-place)
I0810 21:05:19.915324   463 net.cpp:144] Setting up inception_5b/relu_1x1
I0810 21:05:19.915333   463 net.cpp:151] Top shape: 10 384 40 40 (6144000)
I0810 21:05:19.915338   463 net.cpp:159] Memory required for data: 5060162080
I0810 21:05:19.915345   463 layer_factory.hpp:77] Creating layer inception_5b/3x3_reduce
I0810 21:05:19.915359   463 net.cpp:94] Creating Layer inception_5b/3x3_reduce
I0810 21:05:19.915365   463 net.cpp:435] inception_5b/3x3_reduce <- inception_5a/output_inception_5a/output_0_split_1
I0810 21:05:19.915377   463 net.cpp:409] inception_5b/3x3_reduce -> inception_5b/3x3_reduce
I0810 21:05:19.926470   463 net.cpp:144] Setting up inception_5b/3x3_reduce
I0810 21:05:19.926519   463 net.cpp:151] Top shape: 10 192 40 40 (3072000)
I0810 21:05:19.926525   463 net.cpp:159] Memory required for data: 5072450080
I0810 21:05:19.926539   463 layer_factory.hpp:77] Creating layer inception_5b/relu_3x3_reduce
I0810 21:05:19.926555   463 net.cpp:94] Creating Layer inception_5b/relu_3x3_reduce
I0810 21:05:19.926565   463 net.cpp:435] inception_5b/relu_3x3_reduce <- inception_5b/3x3_reduce
I0810 21:05:19.926578   463 net.cpp:396] inception_5b/relu_3x3_reduce -> inception_5b/3x3_reduce (in-place)
I0810 21:05:19.926597   463 net.cpp:144] Setting up inception_5b/relu_3x3_reduce
I0810 21:05:19.926605   463 net.cpp:151] Top shape: 10 192 40 40 (3072000)
I0810 21:05:19.926610   463 net.cpp:159] Memory required for data: 5084738080
I0810 21:05:19.926617   463 layer_factory.hpp:77] Creating layer inception_5b/3x3
I0810 21:05:19.926632   463 net.cpp:94] Creating Layer inception_5b/3x3
I0810 21:05:19.926638   463 net.cpp:435] inception_5b/3x3 <- inception_5b/3x3_reduce
I0810 21:05:19.926658   463 net.cpp:409] inception_5b/3x3 -> inception_5b/3x3
I0810 21:05:19.932440   463 net.cpp:144] Setting up inception_5b/3x3
I0810 21:05:19.932476   463 net.cpp:151] Top shape: 10 384 40 40 (6144000)
I0810 21:05:19.932482   463 net.cpp:159] Memory required for data: 5109314080
I0810 21:05:19.932494   463 layer_factory.hpp:77] Creating layer inception_5b/relu_3x3
I0810 21:05:19.932509   463 net.cpp:94] Creating Layer inception_5b/relu_3x3
I0810 21:05:19.932544   463 net.cpp:435] inception_5b/relu_3x3 <- inception_5b/3x3
I0810 21:05:19.932559   463 net.cpp:396] inception_5b/relu_3x3 -> inception_5b/3x3 (in-place)
I0810 21:05:19.932574   463 net.cpp:144] Setting up inception_5b/relu_3x3
I0810 21:05:19.932584   463 net.cpp:151] Top shape: 10 384 40 40 (6144000)
I0810 21:05:19.932588   463 net.cpp:159] Memory required for data: 5133890080
I0810 21:05:19.932595   463 layer_factory.hpp:77] Creating layer inception_5b/5x5_reduce
I0810 21:05:19.932610   463 net.cpp:94] Creating Layer inception_5b/5x5_reduce
I0810 21:05:19.932618   463 net.cpp:435] inception_5b/5x5_reduce <- inception_5a/output_inception_5a/output_0_split_2
I0810 21:05:19.932677   463 net.cpp:409] inception_5b/5x5_reduce -> inception_5b/5x5_reduce
I0810 21:05:19.934098   463 net.cpp:144] Setting up inception_5b/5x5_reduce
I0810 21:05:19.934115   463 net.cpp:151] Top shape: 10 48 40 40 (768000)
I0810 21:05:19.934123   463 net.cpp:159] Memory required for data: 5136962080
I0810 21:05:19.934132   463 layer_factory.hpp:77] Creating layer inception_5b/relu_5x5_reduce
I0810 21:05:19.934144   463 net.cpp:94] Creating Layer inception_5b/relu_5x5_reduce
I0810 21:05:19.934151   463 net.cpp:435] inception_5b/relu_5x5_reduce <- inception_5b/5x5_reduce
I0810 21:05:19.934162   463 net.cpp:396] inception_5b/relu_5x5_reduce -> inception_5b/5x5_reduce (in-place)
I0810 21:05:19.934175   463 net.cpp:144] Setting up inception_5b/relu_5x5_reduce
I0810 21:05:19.934182   463 net.cpp:151] Top shape: 10 48 40 40 (768000)
I0810 21:05:19.934187   463 net.cpp:159] Memory required for data: 5140034080
I0810 21:05:19.934195   463 layer_factory.hpp:77] Creating layer inception_5b/5x5
I0810 21:05:19.934207   463 net.cpp:94] Creating Layer inception_5b/5x5
I0810 21:05:19.934214   463 net.cpp:435] inception_5b/5x5 <- inception_5b/5x5_reduce
I0810 21:05:19.934226   463 net.cpp:409] inception_5b/5x5 -> inception_5b/5x5
I0810 21:05:19.935366   463 net.cpp:144] Setting up inception_5b/5x5
I0810 21:05:19.935380   463 net.cpp:151] Top shape: 10 128 40 40 (2048000)
I0810 21:05:19.935386   463 net.cpp:159] Memory required for data: 5148226080
I0810 21:05:19.935397   463 layer_factory.hpp:77] Creating layer inception_5b/relu_5x5
I0810 21:05:19.935407   463 net.cpp:94] Creating Layer inception_5b/relu_5x5
I0810 21:05:19.935415   463 net.cpp:435] inception_5b/relu_5x5 <- inception_5b/5x5
I0810 21:05:19.935423   463 net.cpp:396] inception_5b/relu_5x5 -> inception_5b/5x5 (in-place)
I0810 21:05:19.935434   463 net.cpp:144] Setting up inception_5b/relu_5x5
I0810 21:05:19.935441   463 net.cpp:151] Top shape: 10 128 40 40 (2048000)
I0810 21:05:19.935447   463 net.cpp:159] Memory required for data: 5156418080
I0810 21:05:19.935453   463 layer_factory.hpp:77] Creating layer inception_5b/pool
I0810 21:05:19.935464   463 net.cpp:94] Creating Layer inception_5b/pool
I0810 21:05:19.935472   463 net.cpp:435] inception_5b/pool <- inception_5a/output_inception_5a/output_0_split_3
I0810 21:05:19.935482   463 net.cpp:409] inception_5b/pool -> inception_5b/pool
I0810 21:05:19.935534   463 net.cpp:144] Setting up inception_5b/pool
I0810 21:05:19.935544   463 net.cpp:151] Top shape: 10 832 40 40 (13312000)
I0810 21:05:19.935549   463 net.cpp:159] Memory required for data: 5209666080
I0810 21:05:19.935555   463 layer_factory.hpp:77] Creating layer inception_5b/pool_proj
I0810 21:05:19.935570   463 net.cpp:94] Creating Layer inception_5b/pool_proj
I0810 21:05:19.935576   463 net.cpp:435] inception_5b/pool_proj <- inception_5b/pool
I0810 21:05:19.935587   463 net.cpp:409] inception_5b/pool_proj -> inception_5b/pool_proj
I0810 21:05:19.937185   463 net.cpp:144] Setting up inception_5b/pool_proj
I0810 21:05:19.937202   463 net.cpp:151] Top shape: 10 128 40 40 (2048000)
I0810 21:05:19.937208   463 net.cpp:159] Memory required for data: 5217858080
I0810 21:05:19.937218   463 layer_factory.hpp:77] Creating layer inception_5b/relu_pool_proj
I0810 21:05:19.937229   463 net.cpp:94] Creating Layer inception_5b/relu_pool_proj
I0810 21:05:19.937237   463 net.cpp:435] inception_5b/relu_pool_proj <- inception_5b/pool_proj
I0810 21:05:19.937247   463 net.cpp:396] inception_5b/relu_pool_proj -> inception_5b/pool_proj (in-place)
I0810 21:05:19.937259   463 net.cpp:144] Setting up inception_5b/relu_pool_proj
I0810 21:05:19.937266   463 net.cpp:151] Top shape: 10 128 40 40 (2048000)
I0810 21:05:19.937273   463 net.cpp:159] Memory required for data: 5226050080
I0810 21:05:19.937279   463 layer_factory.hpp:77] Creating layer inception_5b/output
I0810 21:05:19.937290   463 net.cpp:94] Creating Layer inception_5b/output
I0810 21:05:19.937297   463 net.cpp:435] inception_5b/output <- inception_5b/1x1
I0810 21:05:19.937337   463 net.cpp:435] inception_5b/output <- inception_5b/3x3
I0810 21:05:19.937346   463 net.cpp:435] inception_5b/output <- inception_5b/5x5
I0810 21:05:19.937353   463 net.cpp:435] inception_5b/output <- inception_5b/pool_proj
I0810 21:05:19.937363   463 net.cpp:409] inception_5b/output -> inception_5b/output
I0810 21:05:19.937402   463 net.cpp:144] Setting up inception_5b/output
I0810 21:05:19.937412   463 net.cpp:151] Top shape: 10 1024 40 40 (16384000)
I0810 21:05:19.937418   463 net.cpp:159] Memory required for data: 5291586080
I0810 21:05:19.937424   463 layer_factory.hpp:77] Creating layer pool5/drop_s1
I0810 21:05:19.937438   463 net.cpp:94] Creating Layer pool5/drop_s1
I0810 21:05:19.937444   463 net.cpp:435] pool5/drop_s1 <- inception_5b/output
I0810 21:05:19.937455   463 net.cpp:409] pool5/drop_s1 -> pool5/drop_s1
I0810 21:05:19.937505   463 net.cpp:144] Setting up pool5/drop_s1
I0810 21:05:19.937513   463 net.cpp:151] Top shape: 10 1024 40 40 (16384000)
I0810 21:05:19.937520   463 net.cpp:159] Memory required for data: 5357122080
I0810 21:05:19.937525   463 layer_factory.hpp:77] Creating layer pool5/drop_s1_pool5/drop_s1_0_split
I0810 21:05:19.937536   463 net.cpp:94] Creating Layer pool5/drop_s1_pool5/drop_s1_0_split
I0810 21:05:19.937542   463 net.cpp:435] pool5/drop_s1_pool5/drop_s1_0_split <- pool5/drop_s1
I0810 21:05:19.937552   463 net.cpp:409] pool5/drop_s1_pool5/drop_s1_0_split -> pool5/drop_s1_pool5/drop_s1_0_split_0
I0810 21:05:19.937563   463 net.cpp:409] pool5/drop_s1_pool5/drop_s1_0_split -> pool5/drop_s1_pool5/drop_s1_0_split_1
I0810 21:05:19.937608   463 net.cpp:144] Setting up pool5/drop_s1_pool5/drop_s1_0_split
I0810 21:05:19.937618   463 net.cpp:151] Top shape: 10 1024 40 40 (16384000)
I0810 21:05:19.937624   463 net.cpp:151] Top shape: 10 1024 40 40 (16384000)
I0810 21:05:19.937629   463 net.cpp:159] Memory required for data: 5488194080
I0810 21:05:19.937635   463 layer_factory.hpp:77] Creating layer cvg/classifier
I0810 21:05:19.937657   463 net.cpp:94] Creating Layer cvg/classifier
I0810 21:05:19.937666   463 net.cpp:435] cvg/classifier <- pool5/drop_s1_pool5/drop_s1_0_split_0
I0810 21:05:19.937677   463 net.cpp:409] cvg/classifier -> cvg/classifier
I0810 21:05:19.937934   463 net.cpp:144] Setting up cvg/classifier
I0810 21:05:19.937947   463 net.cpp:151] Top shape: 10 1 40 40 (16000)
I0810 21:05:19.937952   463 net.cpp:159] Memory required for data: 5488258080
I0810 21:05:19.937961   463 layer_factory.hpp:77] Creating layer coverage/sig
I0810 21:05:19.937970   463 net.cpp:94] Creating Layer coverage/sig
I0810 21:05:19.937978   463 net.cpp:435] coverage/sig <- cvg/classifier
I0810 21:05:19.937986   463 net.cpp:409] coverage/sig -> coverage
I0810 21:05:19.938024   463 net.cpp:144] Setting up coverage/sig
I0810 21:05:19.938032   463 net.cpp:151] Top shape: 10 1 40 40 (16000)
I0810 21:05:19.938038   463 net.cpp:159] Memory required for data: 5488322080
I0810 21:05:19.938045   463 layer_factory.hpp:77] Creating layer bbox/regressor
I0810 21:05:19.938056   463 net.cpp:94] Creating Layer bbox/regressor
I0810 21:05:19.938062   463 net.cpp:435] bbox/regressor <- pool5/drop_s1_pool5/drop_s1_0_split_1
I0810 21:05:19.938073   463 net.cpp:409] bbox/regressor -> bboxes
I0810 21:05:19.938344   463 net.cpp:144] Setting up bbox/regressor
I0810 21:05:19.938356   463 net.cpp:151] Top shape: 10 4 40 40 (64000)
I0810 21:05:19.938362   463 net.cpp:159] Memory required for data: 5488578080
I0810 21:05:19.938370   463 layer_factory.hpp:77] Creating layer bbox_mask
I0810 21:05:19.938380   463 net.cpp:94] Creating Layer bbox_mask
I0810 21:05:19.938387   463 net.cpp:435] bbox_mask <- bboxes
I0810 21:05:19.938395   463 net.cpp:435] bbox_mask <- coverage-block
I0810 21:05:19.938405   463 net.cpp:409] bbox_mask -> bboxes-masked
I0810 21:05:19.938439   463 net.cpp:144] Setting up bbox_mask
I0810 21:05:19.938448   463 net.cpp:151] Top shape: 10 4 40 40 (64000)
I0810 21:05:19.938454   463 net.cpp:159] Memory required for data: 5488834080
I0810 21:05:19.938460   463 layer_factory.hpp:77] Creating layer bbox-norm
I0810 21:05:19.938484   463 net.cpp:94] Creating Layer bbox-norm
I0810 21:05:19.938491   463 net.cpp:435] bbox-norm <- bboxes-masked
I0810 21:05:19.938499   463 net.cpp:435] bbox-norm <- size-block_size-block_0_split_1
I0810 21:05:19.938509   463 net.cpp:409] bbox-norm -> bboxes-masked-norm
I0810 21:05:19.938542   463 net.cpp:144] Setting up bbox-norm
I0810 21:05:19.938551   463 net.cpp:151] Top shape: 10 4 40 40 (64000)
I0810 21:05:19.938557   463 net.cpp:159] Memory required for data: 5489090080
I0810 21:05:19.938563   463 layer_factory.hpp:77] Creating layer bbox-obj-norm
I0810 21:05:19.938573   463 net.cpp:94] Creating Layer bbox-obj-norm
I0810 21:05:19.938580   463 net.cpp:435] bbox-obj-norm <- bboxes-masked-norm
I0810 21:05:19.938588   463 net.cpp:435] bbox-obj-norm <- obj-block_obj-block_0_split_1
I0810 21:05:19.938597   463 net.cpp:409] bbox-obj-norm -> bboxes-obj-masked-norm
I0810 21:05:19.938627   463 net.cpp:144] Setting up bbox-obj-norm
I0810 21:05:19.938635   463 net.cpp:151] Top shape: 10 4 40 40 (64000)
I0810 21:05:19.938642   463 net.cpp:159] Memory required for data: 5489346080
I0810 21:05:19.938657   463 layer_factory.hpp:77] Creating layer bbox_loss
I0810 21:05:19.938668   463 net.cpp:94] Creating Layer bbox_loss
I0810 21:05:19.938674   463 net.cpp:435] bbox_loss <- bboxes-obj-masked-norm
I0810 21:05:19.938683   463 net.cpp:435] bbox_loss <- bbox-obj-label-norm
I0810 21:05:19.938694   463 net.cpp:409] bbox_loss -> loss_bbox
I0810 21:05:19.938758   463 net.cpp:144] Setting up bbox_loss
I0810 21:05:19.938767   463 net.cpp:151] Top shape: (1)
I0810 21:05:19.938773   463 net.cpp:154]     with loss weight 2
I0810 21:05:19.938813   463 net.cpp:159] Memory required for data: 5489346084
I0810 21:05:19.938820   463 layer_factory.hpp:77] Creating layer coverage_loss
I0810 21:05:19.938829   463 net.cpp:94] Creating Layer coverage_loss
I0810 21:05:19.938836   463 net.cpp:435] coverage_loss <- coverage
I0810 21:05:19.938843   463 net.cpp:435] coverage_loss <- coverage-label
I0810 21:05:19.938853   463 net.cpp:409] coverage_loss -> loss_coverage
I0810 21:05:19.938901   463 net.cpp:144] Setting up coverage_loss
I0810 21:05:19.938910   463 net.cpp:151] Top shape: (1)
I0810 21:05:19.938916   463 net.cpp:154]     with loss weight 1
I0810 21:05:19.938925   463 net.cpp:159] Memory required for data: 5489346088
I0810 21:05:19.938930   463 net.cpp:220] coverage_loss needs backward computation.
I0810 21:05:19.938942   463 net.cpp:220] bbox_loss needs backward computation.
I0810 21:05:19.938951   463 net.cpp:220] bbox-obj-norm needs backward computation.
I0810 21:05:19.938958   463 net.cpp:220] bbox-norm needs backward computation.
I0810 21:05:19.938966   463 net.cpp:220] bbox_mask needs backward computation.
I0810 21:05:19.938973   463 net.cpp:220] bbox/regressor needs backward computation.
I0810 21:05:19.938979   463 net.cpp:220] coverage/sig needs backward computation.
I0810 21:05:19.938987   463 net.cpp:220] cvg/classifier needs backward computation.
I0810 21:05:19.938992   463 net.cpp:220] pool5/drop_s1_pool5/drop_s1_0_split needs backward computation.
I0810 21:05:19.938999   463 net.cpp:220] pool5/drop_s1 needs backward computation.
I0810 21:05:19.939005   463 net.cpp:220] inception_5b/output needs backward computation.
I0810 21:05:19.939014   463 net.cpp:220] inception_5b/relu_pool_proj needs backward computation.
I0810 21:05:19.939020   463 net.cpp:220] inception_5b/pool_proj needs backward computation.
I0810 21:05:19.939026   463 net.cpp:220] inception_5b/pool needs backward computation.
I0810 21:05:19.939033   463 net.cpp:220] inception_5b/relu_5x5 needs backward computation.
I0810 21:05:19.939039   463 net.cpp:220] inception_5b/5x5 needs backward computation.
I0810 21:05:19.939046   463 net.cpp:220] inception_5b/relu_5x5_reduce needs backward computation.
I0810 21:05:19.939052   463 net.cpp:220] inception_5b/5x5_reduce needs backward computation.
I0810 21:05:19.939059   463 net.cpp:220] inception_5b/relu_3x3 needs backward computation.
I0810 21:05:19.939065   463 net.cpp:220] inception_5b/3x3 needs backward computation.
I0810 21:05:19.939085   463 net.cpp:220] inception_5b/relu_3x3_reduce needs backward computation.
I0810 21:05:19.939092   463 net.cpp:220] inception_5b/3x3_reduce needs backward computation.
I0810 21:05:19.939100   463 net.cpp:220] inception_5b/relu_1x1 needs backward computation.
I0810 21:05:19.939106   463 net.cpp:220] inception_5b/1x1 needs backward computation.
I0810 21:05:19.939113   463 net.cpp:220] inception_5a/output_inception_5a/output_0_split needs backward computation.
I0810 21:05:19.939121   463 net.cpp:220] inception_5a/output needs backward computation.
I0810 21:05:19.939129   463 net.cpp:220] inception_5a/relu_pool_proj needs backward computation.
I0810 21:05:19.939136   463 net.cpp:220] inception_5a/pool_proj needs backward computation.
I0810 21:05:19.939142   463 net.cpp:220] inception_5a/pool needs backward computation.
I0810 21:05:19.939151   463 net.cpp:220] inception_5a/relu_5x5 needs backward computation.
I0810 21:05:19.939158   463 net.cpp:220] inception_5a/5x5 needs backward computation.
I0810 21:05:19.939165   463 net.cpp:220] inception_5a/relu_5x5_reduce needs backward computation.
I0810 21:05:19.939172   463 net.cpp:220] inception_5a/5x5_reduce needs backward computation.
I0810 21:05:19.939179   463 net.cpp:220] inception_5a/relu_3x3 needs backward computation.
I0810 21:05:19.939186   463 net.cpp:220] inception_5a/3x3 needs backward computation.
I0810 21:05:19.939194   463 net.cpp:220] inception_5a/relu_3x3_reduce needs backward computation.
I0810 21:05:19.939200   463 net.cpp:220] inception_5a/3x3_reduce needs backward computation.
I0810 21:05:19.939208   463 net.cpp:220] inception_5a/relu_1x1 needs backward computation.
I0810 21:05:19.939214   463 net.cpp:220] inception_5a/1x1 needs backward computation.
I0810 21:05:19.939221   463 net.cpp:220] inception_4e/output_inception_4e/output_0_split needs backward computation.
I0810 21:05:19.939229   463 net.cpp:220] inception_4e/output needs backward computation.
I0810 21:05:19.939237   463 net.cpp:220] inception_4e/relu_pool_proj needs backward computation.
I0810 21:05:19.939244   463 net.cpp:220] inception_4e/pool_proj needs backward computation.
I0810 21:05:19.939250   463 net.cpp:220] inception_4e/pool needs backward computation.
I0810 21:05:19.939257   463 net.cpp:220] inception_4e/relu_5x5 needs backward computation.
I0810 21:05:19.939265   463 net.cpp:220] inception_4e/5x5 needs backward computation.
I0810 21:05:19.939271   463 net.cpp:220] inception_4e/relu_5x5_reduce needs backward computation.
I0810 21:05:19.939278   463 net.cpp:220] inception_4e/5x5_reduce needs backward computation.
I0810 21:05:19.939285   463 net.cpp:220] inception_4e/relu_3x3 needs backward computation.
I0810 21:05:19.939292   463 net.cpp:220] inception_4e/3x3 needs backward computation.
I0810 21:05:19.939298   463 net.cpp:220] inception_4e/relu_3x3_reduce needs backward computation.
I0810 21:05:19.939306   463 net.cpp:220] inception_4e/3x3_reduce needs backward computation.
I0810 21:05:19.939311   463 net.cpp:220] inception_4e/relu_1x1 needs backward computation.
I0810 21:05:19.939318   463 net.cpp:220] inception_4e/1x1 needs backward computation.
I0810 21:05:19.939326   463 net.cpp:220] inception_4d/output_inception_4d/output_0_split needs backward computation.
I0810 21:05:19.939332   463 net.cpp:220] inception_4d/output needs backward computation.
I0810 21:05:19.939340   463 net.cpp:220] inception_4d/relu_pool_proj needs backward computation.
I0810 21:05:19.939347   463 net.cpp:220] inception_4d/pool_proj needs backward computation.
I0810 21:05:19.939353   463 net.cpp:220] inception_4d/pool needs backward computation.
I0810 21:05:19.939359   463 net.cpp:220] inception_4d/relu_5x5 needs backward computation.
I0810 21:05:19.939365   463 net.cpp:220] inception_4d/5x5 needs backward computation.
I0810 21:05:19.939373   463 net.cpp:220] inception_4d/relu_5x5_reduce needs backward computation.
I0810 21:05:19.939378   463 net.cpp:220] inception_4d/5x5_reduce needs backward computation.
I0810 21:05:19.939386   463 net.cpp:220] inception_4d/relu_3x3 needs backward computation.
I0810 21:05:19.939400   463 net.cpp:220] inception_4d/3x3 needs backward computation.
I0810 21:05:19.939407   463 net.cpp:220] inception_4d/relu_3x3_reduce needs backward computation.
I0810 21:05:19.939414   463 net.cpp:220] inception_4d/3x3_reduce needs backward computation.
I0810 21:05:19.939420   463 net.cpp:220] inception_4d/relu_1x1 needs backward computation.
I0810 21:05:19.939426   463 net.cpp:220] inception_4d/1x1 needs backward computation.
I0810 21:05:19.939433   463 net.cpp:220] inception_4c/output_inception_4c/output_0_split needs backward computation.
I0810 21:05:19.939440   463 net.cpp:220] inception_4c/output needs backward computation.
I0810 21:05:19.939448   463 net.cpp:220] inception_4c/relu_pool_proj needs backward computation.
I0810 21:05:19.939455   463 net.cpp:220] inception_4c/pool_proj needs backward computation.
I0810 21:05:19.939461   463 net.cpp:220] inception_4c/pool needs backward computation.
I0810 21:05:19.939468   463 net.cpp:220] inception_4c/relu_5x5 needs backward computation.
I0810 21:05:19.939474   463 net.cpp:220] inception_4c/5x5 needs backward computation.
I0810 21:05:19.939481   463 net.cpp:220] inception_4c/relu_5x5_reduce needs backward computation.
I0810 21:05:19.939487   463 net.cpp:220] inception_4c/5x5_reduce needs backward computation.
I0810 21:05:19.939494   463 net.cpp:220] inception_4c/relu_3x3 needs backward computation.
I0810 21:05:19.939502   463 net.cpp:220] inception_4c/3x3 needs backward computation.
I0810 21:05:19.939508   463 net.cpp:220] inception_4c/relu_3x3_reduce needs backward computation.
I0810 21:05:19.939514   463 net.cpp:220] inception_4c/3x3_reduce needs backward computation.
I0810 21:05:19.939522   463 net.cpp:220] inception_4c/relu_1x1 needs backward computation.
I0810 21:05:19.939527   463 net.cpp:220] inception_4c/1x1 needs backward computation.
I0810 21:05:19.939534   463 net.cpp:220] inception_4b/output_inception_4b/output_0_split needs backward computation.
I0810 21:05:19.939541   463 net.cpp:220] inception_4b/output needs backward computation.
I0810 21:05:19.939549   463 net.cpp:220] inception_4b/relu_pool_proj needs backward computation.
I0810 21:05:19.939555   463 net.cpp:220] inception_4b/pool_proj needs backward computation.
I0810 21:05:19.939563   463 net.cpp:220] inception_4b/pool needs backward computation.
I0810 21:05:19.939569   463 net.cpp:220] inception_4b/relu_5x5 needs backward computation.
I0810 21:05:19.939575   463 net.cpp:220] inception_4b/5x5 needs backward computation.
I0810 21:05:19.939582   463 net.cpp:220] inception_4b/relu_5x5_reduce needs backward computation.
I0810 21:05:19.939589   463 net.cpp:220] inception_4b/5x5_reduce needs backward computation.
I0810 21:05:19.939595   463 net.cpp:220] inception_4b/relu_3x3 needs backward computation.
I0810 21:05:19.939601   463 net.cpp:220] inception_4b/3x3 needs backward computation.
I0810 21:05:19.939608   463 net.cpp:220] inception_4b/relu_3x3_reduce needs backward computation.
I0810 21:05:19.939615   463 net.cpp:220] inception_4b/3x3_reduce needs backward computation.
I0810 21:05:19.939621   463 net.cpp:220] inception_4b/relu_1x1 needs backward computation.
I0810 21:05:19.939628   463 net.cpp:220] inception_4b/1x1 needs backward computation.
I0810 21:05:19.939635   463 net.cpp:220] inception_4a/output_inception_4a/output_0_split needs backward computation.
I0810 21:05:19.939641   463 net.cpp:220] inception_4a/output needs backward computation.
I0810 21:05:19.939657   463 net.cpp:220] inception_4a/relu_pool_proj needs backward computation.
I0810 21:05:19.939664   463 net.cpp:220] inception_4a/pool_proj needs backward computation.
I0810 21:05:19.939671   463 net.cpp:220] inception_4a/pool needs backward computation.
I0810 21:05:19.939678   463 net.cpp:220] inception_4a/relu_5x5 needs backward computation.
I0810 21:05:19.939684   463 net.cpp:220] inception_4a/5x5 needs backward computation.
I0810 21:05:19.939692   463 net.cpp:220] inception_4a/relu_5x5_reduce needs backward computation.
I0810 21:05:19.939698   463 net.cpp:220] inception_4a/5x5_reduce needs backward computation.
I0810 21:05:19.939714   463 net.cpp:220] inception_4a/relu_3x3 needs backward computation.
I0810 21:05:19.939721   463 net.cpp:220] inception_4a/3x3 needs backward computation.
I0810 21:05:19.939728   463 net.cpp:220] inception_4a/relu_3x3_reduce needs backward computation.
I0810 21:05:19.939734   463 net.cpp:220] inception_4a/3x3_reduce needs backward computation.
I0810 21:05:19.939741   463 net.cpp:220] inception_4a/relu_1x1 needs backward computation.
I0810 21:05:19.939748   463 net.cpp:220] inception_4a/1x1 needs backward computation.
I0810 21:05:19.939755   463 net.cpp:220] pool3/3x3_s2_pool3/3x3_s2_0_split needs backward computation.
I0810 21:05:19.939762   463 net.cpp:220] pool3/3x3_s2 needs backward computation.
I0810 21:05:19.939769   463 net.cpp:220] inception_3b/output needs backward computation.
I0810 21:05:19.939779   463 net.cpp:220] inception_3b/relu_pool_proj needs backward computation.
I0810 21:05:19.939785   463 net.cpp:220] inception_3b/pool_proj needs backward computation.
I0810 21:05:19.939791   463 net.cpp:220] inception_3b/pool needs backward computation.
I0810 21:05:19.939798   463 net.cpp:220] inception_3b/relu_5x5 needs backward computation.
I0810 21:05:19.939805   463 net.cpp:220] inception_3b/5x5 needs backward computation.
I0810 21:05:19.939812   463 net.cpp:220] inception_3b/relu_5x5_reduce needs backward computation.
I0810 21:05:19.939821   463 net.cpp:220] inception_3b/5x5_reduce needs backward computation.
I0810 21:05:19.939826   463 net.cpp:220] inception_3b/relu_3x3 needs backward computation.
I0810 21:05:19.939832   463 net.cpp:220] inception_3b/3x3 needs backward computation.
I0810 21:05:19.939839   463 net.cpp:220] inception_3b/relu_3x3_reduce needs backward computation.
I0810 21:05:19.939846   463 net.cpp:220] inception_3b/3x3_reduce needs backward computation.
I0810 21:05:19.939852   463 net.cpp:220] inception_3b/relu_1x1 needs backward computation.
I0810 21:05:19.939859   463 net.cpp:220] inception_3b/1x1 needs backward computation.
I0810 21:05:19.939867   463 net.cpp:220] inception_3a/output_inception_3a/output_0_split needs backward computation.
I0810 21:05:19.939873   463 net.cpp:220] inception_3a/output needs backward computation.
I0810 21:05:19.939882   463 net.cpp:220] inception_3a/relu_pool_proj needs backward computation.
I0810 21:05:19.939889   463 net.cpp:220] inception_3a/pool_proj needs backward computation.
I0810 21:05:19.939896   463 net.cpp:220] inception_3a/pool needs backward computation.
I0810 21:05:19.939904   463 net.cpp:220] inception_3a/relu_5x5 needs backward computation.
I0810 21:05:19.939910   463 net.cpp:220] inception_3a/5x5 needs backward computation.
I0810 21:05:19.939918   463 net.cpp:220] inception_3a/relu_5x5_reduce needs backward computation.
I0810 21:05:19.939924   463 net.cpp:220] inception_3a/5x5_reduce needs backward computation.
I0810 21:05:19.939930   463 net.cpp:220] inception_3a/relu_3x3 needs backward computation.
I0810 21:05:19.939937   463 net.cpp:220] inception_3a/3x3 needs backward computation.
I0810 21:05:19.939944   463 net.cpp:220] inception_3a/relu_3x3_reduce needs backward computation.
I0810 21:05:19.939951   463 net.cpp:220] inception_3a/3x3_reduce needs backward computation.
I0810 21:05:19.939959   463 net.cpp:220] inception_3a/relu_1x1 needs backward computation.
I0810 21:05:19.939965   463 net.cpp:220] inception_3a/1x1 needs backward computation.
I0810 21:05:19.939972   463 net.cpp:220] pool2/3x3_s2_pool2/3x3_s2_0_split needs backward computation.
I0810 21:05:19.939980   463 net.cpp:220] pool2/3x3_s2 needs backward computation.
I0810 21:05:19.939985   463 net.cpp:220] conv2/norm2 needs backward computation.
I0810 21:05:19.939992   463 net.cpp:220] conv2/relu_3x3 needs backward computation.
I0810 21:05:19.939999   463 net.cpp:220] conv2/3x3 needs backward computation.
I0810 21:05:19.940006   463 net.cpp:220] conv2/relu_3x3_reduce needs backward computation.
I0810 21:05:19.940013   463 net.cpp:220] conv2/3x3_reduce needs backward computation.
I0810 21:05:19.940021   463 net.cpp:220] pool1/norm1 needs backward computation.
I0810 21:05:19.940035   463 net.cpp:220] pool1/3x3_s2 needs backward computation.
I0810 21:05:19.940043   463 net.cpp:220] conv1/relu_7x7 needs backward computation.
I0810 21:05:19.940050   463 net.cpp:220] conv1/7x7_s2 needs backward computation.
I0810 21:05:19.940057   463 net.cpp:222] bb-obj-norm does not need backward computation.
I0810 21:05:19.940066   463 net.cpp:222] bb-label-norm does not need backward computation.
I0810 21:05:19.940075   463 net.cpp:222] obj-block_obj-block_0_split does not need backward computation.
I0810 21:05:19.940083   463 net.cpp:222] obj-block does not need backward computation.
I0810 21:05:19.940093   463 net.cpp:222] size-block_size-block_0_split does not need backward computation.
I0810 21:05:19.940100   463 net.cpp:222] size-block does not need backward computation.
I0810 21:05:19.940109   463 net.cpp:222] coverage-block does not need backward computation.
I0810 21:05:19.940119   463 net.cpp:222] obj-label_slice-label_3_split does not need backward computation.
I0810 21:05:19.940126   463 net.cpp:222] size-label_slice-label_2_split does not need backward computation.
I0810 21:05:19.940135   463 net.cpp:222] foreground-label_slice-label_0_split does not need backward computation.
I0810 21:05:19.940145   463 net.cpp:222] slice-label does not need backward computation.
I0810 21:05:19.940155   463 net.cpp:222] train_transform does not need backward computation.
I0810 21:05:19.940162   463 net.cpp:222] train_label does not need backward computation.
I0810 21:05:19.940170   463 net.cpp:222] train_data does not need backward computation.
I0810 21:05:19.940176   463 net.cpp:264] This network produces output loss_bbox
I0810 21:05:19.940182   463 net.cpp:264] This network produces output loss_coverage
I0810 21:05:19.940326   463 net.cpp:284] Network initialization done.
I0810 21:05:19.942234   463 solver.cpp:181] Creating test net (#0) specified by net file: train_val.prototxt
I0810 21:05:19.942395   463 net.cpp:323] The NetState phase (1) differed from the phase (0) specified by a rule in layer train_data
I0810 21:05:19.942406   463 net.cpp:323] The NetState phase (1) differed from the phase (0) specified by a rule in layer train_label
I0810 21:05:19.942415   463 net.cpp:323] The NetState phase (1) differed from the phase (0) specified by a rule in layer train_transform
I0810 21:05:19.943166   463 net.cpp:52] Initializing net from parameters:
state {
phase: TEST
}
layer {
name: "val_data"
type: "Data"
top: "data"
include {
phase: TEST
}
transform_param {
mean_file: "/opt/DIGITS/digits/jobs/20180810-202617-c692/train_db/mean.binaryproto"
}
data_param {
source: "/opt/DIGITS/digits/jobs/20180810-202617-c692/val_db/features"
batch_size: 6
backend: LMDB
}
}
layer {
name: "val_label"
type: "Data"
top: "label"
include {
phase: TEST
}
data_param {
source: "/opt/DIGITS/digits/jobs/20180810-202617-c692/val_db/labels"
batch_size: 6
backend: LMDB
}
}
layer {
name: "val_transform"
type: "DetectNetTransformation"
bottom: "data"
bottom: "label"
top: "transformed_data"
top: "transformed_label"
include {
phase: TEST
}
transform_param {
mean_value: 127
}
detectnet_groundtruth_param {
stride: 16
scale_cvg: 0.4
gridbox_type: GRIDBOX_MIN
min_cvg_len: 20
coverage_type: RECTANGULAR
image_size_x: 640
image_size_y: 640
obj_norm: true
crop_bboxes: false
object_class {
src: 1
dst: 0
}
}
}
layer {
name: "slice-label"
type: "Slice"
bottom: "transformed_label"
top: "foreground-label"
top: "bbox-label"
top: "size-label"
top: "obj-label"
top: "coverage-label"
slice_param {
slice_dim: 1
slice_point: 1
slice_point: 5
slice_point: 7
slice_point: 8
}
}
layer {
name: "coverage-block"
type: "Concat"
bottom: "foreground-label"
bottom: "foreground-label"
bottom: "foreground-label"
bottom: "foreground-label"
top: "coverage-block"
concat_param {
concat_dim: 1
}
}
layer {
name: "size-block"
type: "Concat"
bottom: "size-label"
bottom: "size-label"
top: "size-block"
concat_param {
concat_dim: 1
}
}
layer {
name: "obj-block"
type: "Concat"
bottom: "obj-label"
bottom: "obj-label"
bottom: "obj-label"
bottom: "obj-label"
top: "obj-block"
concat_param {
concat_dim: 1
}
}
layer {
name: "bb-label-norm"
type: "Eltwise"
bottom: "bbox-label"
bottom: "size-block"
top: "bbox-label-norm"
eltwise_param {
operation: PROD
}
}
layer {
name: "bb-obj-norm"
type: "Eltwise"
bottom: "bbox-label-norm"
bottom: "obj-block"
top: "bbox-obj-label-norm"
eltwise_param {
operation: PROD
}
}
layer {
name: "conv1/7x7_s2"
type: "Convolution"
bottom: "transformed_data"
top: "conv1/7x7_s2"
param {
lr_mult: 1
decay_mult: 1
}
param {
lr_mult: 2
decay_mult: 0
}
convolution_param {
num_output: 64
pad: 3
kernel_size: 7
stride: 2
weight_filler {
type: "xavier"
std: 0.1
}
bias_filler {
type: "constant"
value: 0.2
}
}
}
layer {
name: "conv1/relu_7x7"
type: "ReLU"
bottom: "conv1/7x7_s2"
top: "conv1/7x7_s2"
}
layer {
name: "pool1/3x3_s2"
type: "Pooling"
bottom: "conv1/7x7_s2"
top: "pool1/3x3_s2"
pooling_param {
pool: MAX
kernel_size: 3
stride: 2
}
}
layer {
name: "pool1/norm1"
type: "LRN"
bottom: "pool1/3x3_s2"
top: "pool1/norm1"
lrn_param {
local_size: 5
alpha: 0.0001
beta: 0.75
}
}
layer {
name: "conv2/3x3_reduce"
type: "Convolution"
bottom: "pool1/norm1"
top: "conv2/3x3_reduce"
param {
lr_mult: 1
decay_mult: 1
}
param {
lr_mult: 2
decay_mult: 0
}
convolution_param {
num_output: 64
kernel_size: 1
weight_filler {
type: "xavier"
std: 0.1
}
bias_filler {
type: "constant"
value: 0.2
}
}
}
layer {
name: "conv2/relu_3x3_reduce"
type: "ReLU"
bottom: "conv2/3x3_reduce"
top: "conv2/3x3_reduce"
}
layer {
name: "conv2/3x3"
type: "Convolution"
bottom: "conv2/3x3_reduce"
top: "conv2/3x3"
param {
lr_mult: 1
decay_mult: 1
}
param {
lr_mult: 2
decay_mult: 0
}
convolution_param {
num_output: 192
pad: 1
kernel_size: 3
weight_filler {
type: "xavier"
std: 0.03
}
bias_filler {
type: "constant"
value: 0.2
}
}
}
layer {
name: "conv2/relu_3x3"
type: "ReLU"
bottom: "conv2/3x3"
top: "conv2/3x3"
}
layer {
name: "conv2/norm2"
type: "LRN"
bottom: "conv2/3x3"
top: "conv2/norm2"
lrn_param {
local_size: 5
alpha: 0.0001
beta: 0.75
}
}
layer {
name: "pool2/3x3_s2"
type: "Pooling"
bottom: "conv2/norm2"
top: "pool2/3x3_s2"
pooling_param {
pool: MAX
kernel_size: 3
stride: 2
}
}
layer {
name: "inception_3a/1x1"
type: "Convolution"
bottom: "pool2/3x3_s2"
top: "inception_3a/1x1"
param {
lr_mult: 1
decay_mult: 1
}
param {
lr_mult: 2
decay_mult: 0
}
convolution_param {
num_output: 64
kernel_size: 1
weight_filler {
type: "xavier"
std: 0.03
}
bias_filler {
type: "constant"
value: 0.2
}
}
}
layer {
name: "inception_3a/relu_1x1"
type: "ReLU"
bottom: "inception_3a/1x1"
top: "inception_3a/1x1"
}
layer {
name: "inception_3a/3x3_reduce"
type: "Convolution"
bottom: "pool2/3x3_s2"
top: "inception_3a/3x3_reduce"
param {
lr_mult: 1
decay_mult: 1
}
param {
lr_mult: 2
decay_mult: 0
}
convolution_param {
num_output: 96
kernel_size: 1
weight_filler {
type: "xavier"
std: 0.09
}
bias_filler {
type: "constant"
value: 0.2
}
}
}
layer {
name: "inception_3a/relu_3x3_reduce"
type: "ReLU"
bottom: "inception_3a/3x3_reduce"
top: "inception_3a/3x3_reduce"
}
layer {
name: "inception_3a/3x3"
type: "Convolution"
bottom: "inception_3a/3x3_reduce"
top: "inception_3a/3x3"
param {
lr_mult: 1
decay_mult: 1
}
param {
lr_mult: 2
decay_mult: 0
}
convolution_param {
num_output: 128
pad: 1
kernel_size: 3
weight_filler {
type: "xavier"
std: 0.03
}
bias_filler {
type: "constant"
value: 0.2
}
}
}
layer {
name: "inception_3a/relu_3x3"
type: "ReLU"
bottom: "inception_3a/3x3"
top: "inception_3a/3x3"
}
layer {
name: "inception_3a/5x5_reduce"
type: "Convolution"
bottom: "pool2/3x3_s2"
top: "inception_3a/5x5_reduce"
param {
lr_mult: 1
decay_mult: 1
}
param {
lr_mult: 2
decay_mult: 0
}
convolution_param {
num_output: 16
kernel_size: 1
weight_filler {
type: "xavier"
std: 0.2
}
bias_filler {
type: "constant"
value: 0.2
}
}
}
layer {
name: "inception_3a/relu_5x5_reduce"
type: "ReLU"
bottom: "inception_3a/5x5_reduce"
top: "inception_3a/5x5_reduce"
}
layer {
name: "inception_3a/5x5"
type: "Convolution"
bottom: "inception_3a/5x5_reduce"
top: "inception_3a/5x5"
param {
lr_mult: 1
decay_mult: 1
}
param {
lr_mult: 2
decay_mult: 0
}
convolution_param {
num_output: 32
pad: 2
kernel_size: 5
weight_filler {
type: "xavier"
std: 0.03
}
bias_filler {
type: "constant"
value: 0.2
}
}
}
layer {
name: "inception_3a/relu_5x5"
type: "ReLU"
bottom: "inception_3a/5x5"
top: "inception_3a/5x5"
}
layer {
name: "inception_3a/pool"
type: "Pooling"
bottom: "pool2/3x3_s2"
top: "inception_3a/pool"
pooling_param {
pool: MAX
kernel_size: 3
stride: 1
pad: 1
}
}
layer {
name: "inception_3a/pool_proj"
type: "Convolution"
bottom: "inception_3a/pool"
top: "inception_3a/pool_proj"
param {
lr_mult: 1
decay_mult: 1
}
param {
lr_mult: 2
decay_mult: 0
}
convolution_param {
num_output: 32
kernel_size: 1
weight_filler {
type: "xavier"
std: 0.1
}
bias_filler {
type: "constant"
value: 0.2
}
}
}
layer {
name: "inception_3a/relu_pool_proj"
type: "ReLU"
bottom: "inception_3a/pool_proj"
top: "inception_3a/pool_proj"
}
layer {
name: "inception_3a/output"
type: "Concat"
bottom: "inception_3a/1x1"
bottom: "inception_3a/3x3"
bottom: "inception_3a/5x5"
bottom: "inception_3a/pool_proj"
top: "inception_3a/output"
}
layer {
name: "inception_3b/1x1"
type: "Convolution"
bottom: "inception_3a/output"
top: "inception_3b/1x1"
param {
lr_mult: 1
decay_mult: 1
}
param {
lr_mult: 2
decay_mult: 0
}
convolution_param {
num_output: 128
kernel_size: 1
weight_filler {
type: "xavier"
std: 0.03
}
bias_filler {
type: "constant"
value: 0.2
}
}
}
layer {
name: "inception_3b/relu_1x1"
type: "ReLU"
bottom: "inception_3b/1x1"
top: "inception_3b/1x1"
}
layer {
name: "inception_3b/3x3_reduce"
type: "Convolution"
bottom: "inception_3a/output"
top: "inception_3b/3x3_reduce"
param {
lr_mult: 1
decay_mult: 1
}
param {
lr_mult: 2
decay_mult: 0
}
convolution_param {
num_output: 128
kernel_size: 1
weight_filler {
type: "xavier"
std: 0.09
}
bias_filler {
type: "constant"
value: 0.2
}
}
}
layer {
name: "inception_3b/relu_3x3_reduce"
type: "ReLU"
bottom: "inception_3b/3x3_reduce"
top: "inception_3b/3x3_reduce"
}
layer {
name: "inception_3b/3x3"
type: "Convolution"
bottom: "inception_3b/3x3_reduce"
top: "inception_3b/3x3"
param {
lr_mult: 1
decay_mult: 1
}
param {
lr_mult: 2
decay_mult: 0
}
convolution_param {
num_output: 192
pad: 1
kernel_size: 3
weight_filler {
type: "xavier"
std: 0.03
}
bias_filler {
type: "constant"
value: 0.2
}
}
}
layer {
name: "inception_3b/relu_3x3"
type: "ReLU"
bottom: "inception_3b/3x3"
top: "inception_3b/3x3"
}
layer {
name: "inception_3b/5x5_reduce"
type: "Convolution"
bottom: "inception_3a/output"
top: "inception_3b/5x5_reduce"
param {
lr_mult: 1
decay_mult: 1
}
param {
lr_mult: 2
decay_mult: 0
}
convolution_param {
num_output: 32
kernel_size: 1
weight_filler {
type: "xavier"
std: 0.2
}
bias_filler {
type: "constant"
value: 0.2
}
}
}
layer {
name: "inception_3b/relu_5x5_reduce"
type: "ReLU"
bottom: "inception_3b/5x5_reduce"
top: "inception_3b/5x5_reduce"
}
layer {
name: "inception_3b/5x5"
type: "Convolution"
bottom: "inception_3b/5x5_reduce"
top: "inception_3b/5x5"
param {
lr_mult: 1
decay_mult: 1
}
param {
lr_mult: 2
decay_mult: 0
}
convolution_param {
num_output: 96
pad: 2
kernel_size: 5
weight_filler {
type: "xavier"
std: 0.03
}
bias_filler {
type: "constant"
value: 0.2
}
}
}
layer {
name: "inception_3b/relu_5x5"
type: "ReLU"
bottom: "inception_3b/5x5"
top: "inception_3b/5x5"
}
layer {
name: "inception_3b/pool"
type: "Pooling"
bottom: "inception_3a/output"
top: "inception_3b/pool"
pooling_param {
pool: MAX
kernel_size: 3
stride: 1
pad: 1
}
}
layer {
name: "inception_3b/pool_proj"
type: "Convolution"
bottom: "inception_3b/pool"
top: "inception_3b/pool_proj"
param {
lr_mult: 1
decay_mult: 1
}
param {
lr_mult: 2
decay_mult: 0
}
convolution_param {
num_output: 64
kernel_size: 1
weight_filler {
type: "xavier"
std: 0.1
}
bias_filler {
type: "constant"
value: 0.2
}
}
}
layer {
name: "inception_3b/relu_pool_proj"
type: "ReLU"
bottom: "inception_3b/pool_proj"
top: "inception_3b/pool_proj"
}
layer {
name: "inception_3b/output"
type: "Concat"
bottom: "inception_3b/1x1"
bottom: "inception_3b/3x3"
bottom: "inception_3b/5x5"
bottom: "inception_3b/pool_proj"
top: "inception_3b/output"
}
layer {
name: "pool3/3x3_s2"
type: "Pooling"
bottom: "inception_3b/output"
top: "pool3/3x3_s2"
pooling_param {
pool: MAX
kernel_size: 3
stride: 2
}
}
layer {
name: "inception_4a/1x1"
type: "Convolution"
bottom: "pool3/3x3_s2"
top: "inception_4a/1x1"
param {
lr_mult: 1
decay_mult: 1
}
param {
lr_mult: 2
decay_mult: 0
}
convolution_param {
num_output: 192
kernel_size: 1
weight_filler {
type: "xavier"
std: 0.03
}
bias_filler {
type: "constant"
value: 0.2
}
}
}
layer {
name: "inception_4a/relu_1x1"
type: "ReLU"
bottom: "inception_4a/1x1"
top: "inception_4a/1x1"
}
layer {
name: "inception_4a/3x3_reduce"
type: "Convolution"
bottom: "pool3/3x3_s2"
top: "inception_4a/3x3_reduce"
param {
lr_mult: 1
decay_mult: 1
}
param {
lr_mult: 2
decay_mult: 0
}
convolution_param {
num_output: 96
kernel_size: 1
weight_filler {
type: "xavier"
std: 0.09
}
bias_filler {
type: "constant"
value: 0.2
}
}
}
layer {
name: "inception_4a/relu_3x3_reduce"
type: "ReLU"
bottom: "inception_4a/3x3_reduce"
top: "inception_4a/3x3_reduce"
}
layer {
name: "inception_4a/3x3"
type: "Convolution"
bottom: "inception_4a/3x3_reduce"
top: "inception_4a/3x3"
param {
lr_mult: 1
decay_mult: 1
}
param {
lr_mult: 2
decay_mult: 0
}
convolution_param {
num_output: 208
pad: 1
kernel_size: 3
weight_filler {
type: "xavier"
std: 0.03
}
bias_filler {
type: "constant"
value: 0.2
}
}
}
layer {
name: "inception_4a/relu_3x3"
type: "ReLU"
bottom: "inception_4a/3x3"
top: "inception_4a/3x3"
}
layer {
name: "inception_4a/5x5_reduce"
type: "Convolution"
bottom: "pool3/3x3_s2"
top: "inception_4a/5x5_reduce"
param {
lr_mult: 1
decay_mult: 1
}
param {
lr_mult: 2
decay_mult: 0
}
convolution_param {
num_output: 16
kernel_size: 1
weight_filler {
type: "xavier"
std: 0.2
}
bias_filler {
type: "constant"
value: 0.2
}
}
}
layer {
name: "inception_4a/relu_5x5_reduce"
type: "ReLU"
bottom: "inception_4a/5x5_reduce"
top: "inception_4a/5x5_reduce"
}
layer {
name: "inception_4a/5x5"
type: "Convolution"
bottom: "inception_4a/5x5_reduce"
top: "inception_4a/5x5"
param {
lr_mult: 1
decay_mult: 1
}
param {
lr_mult: 2
decay_mult: 0
}
convolution_param {
num_output: 48
pad: 2
kernel_size: 5
weight_filler {
type: "xavier"
std: 0.03
}
bias_filler {
type: "constant"
value: 0.2
}
}
}
layer {
name: "inception_4a/relu_5x5"
type: "ReLU"
bottom: "inception_4a/5x5"
top: "inception_4a/5x5"
}
layer {
name: "inception_4a/pool"
type: "Pooling"
bottom: "pool3/3x3_s2"
top: "inception_4a/pool"
pooling_param {
pool: MAX
kernel_size: 3
stride: 1
pad: 1
}
}
layer {
name: "inception_4a/pool_proj"
type: "Convolution"
bottom: "inception_4a/pool"
top: "inception_4a/pool_proj"
param {
lr_mult: 1
decay_mult: 1
}
param {
lr_mult: 2
decay_mult: 0
}
convolution_param {
num_output: 64
kernel_size: 1
weight_filler {
type: "xavier"
std: 0.1
}
bias_filler {
type: "constant"
value: 0.2
}
}
}
layer {
name: "inception_4a/relu_pool_proj"
type: "ReLU"
bottom: "inception_4a/pool_proj"
top: "inception_4a/pool_proj"
}
layer {
name: "inception_4a/output"
type: "Concat"
bottom: "inception_4a/1x1"
bottom: "inception_4a/3x3"
bottom: "inception_4a/5x5"
bottom: "inception_4a/pool_proj"
top: "inception_4a/output"
}
layer {
name: "inception_4b/1x1"
type: "Convolution"
bottom: "inception_4a/output"
top: "inception_4b/1x1"
param {
lr_mult: 1
decay_mult: 1
}
param {
lr_mult: 2
decay_mult: 0
}
convolution_param {
num_output: 160
kernel_size: 1
weight_filler {
type: "xavier"
std: 0.03
}
bias_filler {
type: "constant"
value: 0.2
}
}
}
layer {
name: "inception_4b/relu_1x1"
type: "ReLU"
bottom: "inception_4b/1x1"
top: "inception_4b/1x1"
}
layer {
name: "inception_4b/3x3_reduce"
type: "Convolution"
bottom: "inception_4a/output"
top: "inception_4b/3x3_reduce"
param {
lr_mult: 1
decay_mult: 1
}
param {
lr_mult: 2
decay_mult: 0
}
convolution_param {
num_output: 112
kernel_size: 1
weight_filler {
type: "xavier"
std: 0.09
}
bias_filler {
type: "constant"
value: 0.2
}
}
}
layer {
name: "inception_4b/relu_3x3_reduce"
type: "ReLU"
bottom: "inception_4b/3x3_reduce"
top: "inception_4b/3x3_reduce"
}
layer {
name: "inception_4b/3x3"
type: "Convolution"
bottom: "inception_4b/3x3_reduce"
top: "inception_4b/3x3"
param {
lr_mult: 1
decay_mult: 1
}
param {
lr_mult: 2
decay_mult: 0
}
convolution_param {
num_output: 224
pad: 1
kernel_size: 3
weight_filler {
type: "xavier"
std: 0.03
}
bias_filler {
type: "constant"
value: 0.2
}
}
}
layer {
name: "inception_4b/relu_3x3"
type: "ReLU"
bottom: "inception_4b/3x3"
top: "inception_4b/3x3"
}
layer {
name: "inception_4b/5x5_reduce"
type: "Convolution"
bottom: "inception_4a/output"
top: "inception_4b/5x5_reduce"
param {
lr_mult: 1
decay_mult: 1
}
param {
lr_mult: 2
decay_mult: 0
}
convolution_param {
num_output: 24
kernel_size: 1
weight_filler {
type: "xavier"
std: 0.2
}
bias_filler {
type: "constant"
value: 0.2
}
}
}
layer {
name: "inception_4b/relu_5x5_reduce"
type: "ReLU"
bottom: "inception_4b/5x5_reduce"
top: "inception_4b/5x5_reduce"
}
layer {
name: "inception_4b/5x5"
type: "Convolution"
bottom: "inception_4b/5x5_reduce"
top: "inception_4b/5x5"
param {
lr_mult: 1
decay_mult: 1
}
param {
lr_mult: 2
decay_mult: 0
}
convolution_param {
num_output: 64
pad: 2
kernel_size: 5
weight_filler {
type: "xavier"
std: 0.03
}
bias_filler {
type: "constant"
value: 0.2
}
}
}
layer {
name: "inception_4b/relu_5x5"
type: "ReLU"
bottom: "inception_4b/5x5"
top: "inception_4b/5x5"
}
layer {
name: "inception_4b/pool"
type: "Pooling"
bottom: "inception_4a/output"
top: "inception_4b/pool"
pooling_param {
pool: MAX
kernel_size: 3
stride: 1
pad: 1
}
}
layer {
name: "inception_4b/pool_proj"
type: "Convolution"
bottom: "inception_4b/pool"
top: "inception_4b/pool_proj"
param {
lr_mult: 1
decay_mult: 1
}
param {
lr_mult: 2
decay_mult: 0
}
convolution_param {
num_output: 64
kernel_size: 1
weight_filler {
type: "xavier"
std: 0.1
}
bias_filler {
type: "constant"
value: 0.2
}
}
}
layer {
name: "inception_4b/relu_pool_proj"
type: "ReLU"
bottom: "inception_4b/pool_proj"
top: "inception_4b/pool_proj"
}
layer {
name: "inception_4b/output"
type: "Concat"
bottom: "inception_4b/1x1"
bottom: "inception_4b/3x3"
bottom: "inception_4b/5x5"
bottom: "inception_4b/pool_proj"
top: "inception_4b/output"
}
layer {
name: "inception_4c/1x1"
type: "Convolution"
bottom: "inception_4b/output"
top: "inception_4c/1x1"
param {
lr_mult: 1
decay_mult: 1
}
param {
lr_mult: 2
decay_mult: 0
}
convolution_param {
num_output: 128
kernel_size: 1
weight_filler {
type: "xavier"
std: 0.03
}
bias_filler {
type: "constant"
value: 0.2
}
}
}
layer {
name: "inception_4c/relu_1x1"
type: "ReLU"
bottom: "inception_4c/1x1"
top: "inception_4c/1x1"
}
layer {
name: "inception_4c/3x3_reduce"
type: "Convolution"
bottom: "inception_4b/output"
top: "inception_4c/3x3_reduce"
param {
lr_mult: 1
decay_mult: 1
}
param {
lr_mult: 2
decay_mult: 0
}
convolution_param {
num_output: 128
kernel_size: 1
weight_filler {
type: "xavier"
std: 0.09
}
bias_filler {
type: "constant"
value: 0.2
}
}
}
layer {
name: "inception_4c/relu_3x3_reduce"
type: "ReLU"
bottom: "inception_4c/3x3_reduce"
top: "inception_4c/3x3_reduce"
}
layer {
name: "inception_4c/3x3"
type: "Convolution"
bottom: "inception_4c/3x3_reduce"
top: "inception_4c/3x3"
param {
lr_mult: 1
decay_mult: 1
}
param {
lr_mult: 2
decay_mult: 0
}
convolution_param {
num_output: 256
pad: 1
kernel_size: 3
weight_filler {
type: "xavier"
std: 0.03
}
bias_filler {
type: "constant"
value: 0.2
}
}
}
layer {
name: "inception_4c/relu_3x3"
type: "ReLU"
bottom: "inception_4c/3x3"
top: "inception_4c/3x3"
}
layer {
name: "inception_4c/5x5_reduce"
type: "Convolution"
bottom: "inception_4b/output"
top: "inception_4c/5x5_reduce"
param {
lr_mult: 1
decay_mult: 1
}
param {
lr_mult: 2
decay_mult: 0
}
convolution_param {
num_output: 24
kernel_size: 1
weight_filler {
type: "xavier"
std: 0.2
}
bias_filler {
type: "constant"
value: 0.2
}
}
}
layer {
name: "inception_4c/relu_5x5_reduce"
type: "ReLU"
bottom: "inception_4c/5x5_reduce"
top: "inception_4c/5x5_reduce"
}
layer {
name: "inception_4c/5x5"
type: "Convolution"
bottom: "inception_4c/5x5_reduce"
top: "inception_4c/5x5"
param {
lr_mult: 1
decay_mult: 1
}
param {
lr_mult: 2
decay_mult: 0
}
convolution_param {
num_output: 64
pad: 2
kernel_size: 5
weight_filler {
type: "xavier"
std: 0.03
}
bias_filler {
type: "constant"
value: 0.2
}
}
}
layer {
name: "inception_4c/relu_5x5"
type: "ReLU"
bottom: "inception_4c/5x5"
top: "inception_4c/5x5"
}
layer {
name: "inception_4c/pool"
type: "Pooling"
bottom: "inception_4b/output"
top: "inception_4c/pool"
pooling_param {
pool: MAX
kernel_size: 3
stride: 1
pad: 1
}
}
layer {
name: "inception_4c/pool_proj"
type: "Convolution"
bottom: "inception_4c/pool"
top: "inception_4c/pool_proj"
param {
lr_mult: 1
decay_mult: 1
}
param {
lr_mult: 2
decay_mult: 0
}
convolution_param {
num_output: 64
kernel_size: 1
weight_filler {
type: "xavier"
std: 0.1
}
bias_filler {
type: "constant"
value: 0.2
}
}
}
layer {
name: "inception_4c/relu_pool_proj"
type: "ReLU"
bottom: "inception_4c/pool_proj"
top: "inception_4c/pool_proj"
}
layer {
name: "inception_4c/output"
type: "Concat"
bottom: "inception_4c/1x1"
bottom: "inception_4c/3x3"
bottom: "inception_4c/5x5"
bottom: "inception_4c/pool_proj"
top: "inception_4c/output"
}
layer {
name: "inception_4d/1x1"
type: "Convolution"
bottom: "inception_4c/output"
top: "inception_4d/1x1"
param {
lr_mult: 1
decay_mult: 1
}
param {
lr_mult: 2
decay_mult: 0
}
convolution_param {
num_output: 112
kernel_size: 1
weight_filler {
type: "xavier"
std: 0.1
}
bias_filler {
type: "constant"
value: 0.2
}
}
}
layer {
name: "inception_4d/relu_1x1"
type: "ReLU"
bottom: "inception_4d/1x1"
top: "inception_4d/1x1"
}
layer {
name: "inception_4d/3x3_reduce"
type: "Convolution"
bottom: "inception_4c/output"
top: "inception_4d/3x3_reduce"
param {
lr_mult: 1
decay_mult: 1
}
param {
lr_mult: 2
decay_mult: 0
}
convolution_param {
num_output: 144
kernel_size: 1
weight_filler {
type: "xavier"
std: 0.1
}
bias_filler {
type: "constant"
value: 0.2
}
}
}
layer {
name: "inception_4d/relu_3x3_reduce"
type: "ReLU"
bottom: "inception_4d/3x3_reduce"
top: "inception_4d/3x3_reduce"
}
layer {
name: "inception_4d/3x3"
type: "Convolution"
bottom: "inception_4d/3x3_reduce"
top: "inception_4d/3x3"
param {
lr_mult: 1
decay_mult: 1
}
param {
lr_mult: 2
decay_mult: 0
}
convolution_param {
num_output: 288
pad: 1
kernel_size: 3
weight_filler {
type: "xavier"
std: 0.1
}
bias_filler {
type: "constant"
value: 0.2
}
}
}
layer {
name: "inception_4d/relu_3x3"
type: "ReLU"
bottom: "inception_4d/3x3"
top: "inception_4d/3x3"
}
layer {
name: "inception_4d/5x5_reduce"
type: "Convolution"
bottom: "inception_4c/output"
top: "inception_4d/5x5_reduce"
param {
lr_mult: 1
decay_mult: 1
}
param {
lr_mult: 2
decay_mult: 0
}
convolution_param {
num_output: 32
kernel_size: 1
weight_filler {
type: "xavier"
std: 0.1
}
bias_filler {
type: "constant"
value: 0.2
}
}
}
layer {
name: "inception_4d/relu_5x5_reduce"
type: "ReLU"
bottom: "inception_4d/5x5_reduce"
top: "inception_4d/5x5_reduce"
}
layer {
name: "inception_4d/5x5"
type: "Convolution"
bottom: "inception_4d/5x5_reduce"
top: "inception_4d/5x5"
param {
lr_mult: 1
decay_mult: 1
}
param {
lr_mult: 2
decay_mult: 0
}
convolution_param {
num_output: 64
pad: 2
kernel_size: 5
weight_filler {
type: "xavier"
std: 0.1
}
bias_filler {
type: "constant"
value: 0.2
}
}
}
layer {
name: "inception_4d/relu_5x5"
type: "ReLU"
bottom: "inception_4d/5x5"
top: "inception_4d/5x5"
}
layer {
name: "inception_4d/pool"
type: "Pooling"
bottom: "inception_4c/output"
top: "inception_4d/pool"
pooling_param {
pool: MAX
kernel_size: 3
stride: 1
pad: 1
}
}
layer {
name: "inception_4d/pool_proj"
type: "Convolution"
bottom: "inception_4d/pool"
top: "inception_4d/pool_proj"
param {
lr_mult: 1
decay_mult: 1
}
param {
lr_mult: 2
decay_mult: 0
}
convolution_param {
num_output: 64
kernel_size: 1
weight_filler {
type: "xavier"
std: 0.1
}
bias_filler {
type: "constant"
value: 0.2
}
}
}
layer {
name: "inception_4d/relu_pool_proj"
type: "ReLU"
bottom: "inception_4d/pool_proj"
top: "inception_4d/pool_proj"
}
layer {
name: "inception_4d/output"
type: "Concat"
bottom: "inception_4d/1x1"
bottom: "inception_4d/3x3"
bottom: "inception_4d/5x5"
bottom: "inception_4d/pool_proj"
top: "inception_4d/output"
}
layer {
name: "inception_4e/1x1"
type: "Convolution"
bottom: "inception_4d/output"
top: "inception_4e/1x1"
param {
lr_mult: 1
decay_mult: 1
}
param {
lr_mult: 2
decay_mult: 0
}
convolution_param {
num_output: 256
kernel_size: 1
weight_filler {
type: "xavier"
std: 0.03
}
bias_filler {
type: "constant"
value: 0.2
}
}
}
layer {
name: "inception_4e/relu_1x1"
type: "ReLU"
bottom: "inception_4e/1x1"
top: "inception_4e/1x1"
}
layer {
name: "inception_4e/3x3_reduce"
type: "Convolution"
bottom: "inception_4d/output"
top: "inception_4e/3x3_reduce"
param {
lr_mult: 1
decay_mult: 1
}
param {
lr_mult: 2
decay_mult: 0
}
convolution_param {
num_output: 160
kernel_size: 1
weight_filler {
type: "xavier"
std: 0.09
}
bias_filler {
type: "constant"
value: 0.2
}
}
}
layer {
name: "inception_4e/relu_3x3_reduce"
type: "ReLU"
bottom: "inception_4e/3x3_reduce"
top: "inception_4e/3x3_reduce"
}
layer {
name: "inception_4e/3x3"
type: "Convolution"
bottom: "inception_4e/3x3_reduce"
top: "inception_4e/3x3"
param {
lr_mult: 1
decay_mult: 1
}
param {
lr_mult: 2
decay_mult: 0
}
convolution_param {
num_output: 320
pad: 1
kernel_size: 3
weight_filler {
type: "xavier"
std: 0.03
}
bias_filler {
type: "constant"
value: 0.2
}
}
}
layer {
name: "inception_4e/relu_3x3"
type: "ReLU"
bottom: "inception_4e/3x3"
top: "inception_4e/3x3"
}
layer {
name: "inception_4e/5x5_reduce"
type: "Convolution"
bottom: "inception_4d/output"
top: "inception_4e/5x5_reduce"
param {
lr_mult: 1
decay_mult: 1
}
param {
lr_mult: 2
decay_mult: 0
}
convolution_param {
num_output: 32
kernel_size: 1
weight_filler {
type: "xavier"
std: 0.2
}
bias_filler {
type: "constant"
value: 0.2
}
}
}
layer {
name: "inception_4e/relu_5x5_reduce"
type: "ReLU"
bottom: "inception_4e/5x5_reduce"
top: "inception_4e/5x5_reduce"
}
layer {
name: "inception_4e/5x5"
type: "Convolution"
bottom: "inception_4e/5x5_reduce"
top: "inception_4e/5x5"
param {
lr_mult: 1
decay_mult: 1
}
param {
lr_mult: 2
decay_mult: 0
}
convolution_param {
num_output: 128
pad: 2
kernel_size: 5
weight_filler {
type: "xavier"
std: 0.03
}
bias_filler {
type: "constant"
value: 0.2
}
}
}
layer {
name: "inception_4e/relu_5x5"
type: "ReLU"
bottom: "inception_4e/5x5"
top: "inception_4e/5x5"
}
layer {
name: "inception_4e/pool"
type: "Pooling"
bottom: "inception_4d/output"
top: "inception_4e/pool"
pooling_param {
pool: MAX
kernel_size: 3
stride: 1
pad: 1
}
}
layer {
name: "inception_4e/pool_proj"
type: "Convolution"
bottom: "inception_4e/pool"
top: "inception_4e/pool_proj"
param {
lr_mult: 1
decay_mult: 1
}
param {
lr_mult: 2
decay_mult: 0
}
convolution_param {
num_output: 128
kernel_size: 1
weight_filler {
type: "xavier"
std: 0.1
}
bias_filler {
type: "constant"
value: 0.2
}
}
}
layer {
name: "inception_4e/relu_pool_proj"
type: "ReLU"
bottom: "inception_4e/pool_proj"
top: "inception_4e/pool_proj"
}
layer {
name: "inception_4e/output"
type: "Concat"
bottom: "inception_4e/1x1"
bottom: "inception_4e/3x3"
bottom: "inception_4e/5x5"
bottom: "inception_4e/pool_proj"
top: "inception_4e/output"
}
layer {
name: "inception_5a/1x
I0810 21:05:19.952553   463 layer_factory.hpp:77] Creating layer val_data
I0810 21:05:19.953140   463 net.cpp:94] Creating Layer val_data
I0810 21:05:19.953161   463 net.cpp:409] val_data -> data
I0810 21:05:19.953182   463 data_transformer.cpp:25] Loading mean file from: /opt/DIGITS/digits/jobs/20180810-202617-c692/train_db/mean.binaryproto
I0810 21:05:19.955932   478 db_lmdb.cpp:35] Opened lmdb /opt/DIGITS/digits/jobs/20180810-202617-c692/val_db/features
I0810 21:05:20.053767   463 data_layer.cpp:78] ReshapePrefetch 6, 3, 679, 1124
I0810 21:05:20.053865   463 data_layer.cpp:83] output data size: 6,3,679,1124
I0810 21:05:20.190224   463 net.cpp:144] Setting up val_data
I0810 21:05:20.190279   463 net.cpp:151] Top shape: 6 3 679 1124 (13737528)
I0810 21:05:20.190287   463 net.cpp:159] Memory required for data: 54950112
I0810 21:05:20.190299   463 layer_factory.hpp:77] Creating layer val_label
I0810 21:05:20.190927   463 net.cpp:94] Creating Layer val_label
I0810 21:05:20.190949   463 net.cpp:409] val_label -> label
I0810 21:05:20.214820   484 db_lmdb.cpp:35] Opened lmdb /opt/DIGITS/digits/jobs/20180810-202617-c692/val_db/labels
I0810 21:05:20.217054   463 data_layer.cpp:78] ReshapePrefetch 6, 1, 4, 16
I0810 21:05:20.217134   463 data_layer.cpp:83] output data size: 6,1,4,16
I0810 21:05:20.217464   463 net.cpp:144] Setting up val_label
I0810 21:05:20.217484   463 net.cpp:151] Top shape: 6 1 4 16 (384)
I0810 21:05:20.217490   463 net.cpp:159] Memory required for data: 54951648
I0810 21:05:20.217500   463 layer_factory.hpp:77] Creating layer val_transform
I0810 21:05:20.217533   463 net.cpp:94] Creating Layer val_transform
I0810 21:05:20.217542   463 net.cpp:435] val_transform <- data
I0810 21:05:20.217552   463 net.cpp:435] val_transform <- label
I0810 21:05:20.217563   463 net.cpp:409] val_transform -> transformed_data
I0810 21:05:20.217581   463 net.cpp:409] val_transform -> transformed_label
I0810 21:05:20.218041   463 net.cpp:144] Setting up val_transform
I0810 21:05:20.218061   463 net.cpp:151] Top shape: 6 3 640 640 (7372800)
I0810 21:05:20.218070   463 net.cpp:151] Top shape: 6 9 40 40 (86400)
I0810 21:05:20.218075   463 net.cpp:159] Memory required for data: 84788448
I0810 21:05:20.218081   463 layer_factory.hpp:77] Creating layer slice-label
I0810 21:05:20.218094   463 net.cpp:94] Creating Layer slice-label
I0810 21:05:20.218101   463 net.cpp:435] slice-label <- transformed_label
I0810 21:05:20.218111   463 net.cpp:409] slice-label -> foreground-label
I0810 21:05:20.218129   463 net.cpp:409] slice-label -> bbox-label
I0810 21:05:20.218150   463 net.cpp:409] slice-label -> size-label
I0810 21:05:20.218161   463 net.cpp:409] slice-label -> obj-label
I0810 21:05:20.218171   463 net.cpp:409] slice-label -> coverage-label
I0810 21:05:20.218261   463 net.cpp:144] Setting up slice-label
I0810 21:05:20.218271   463 net.cpp:151] Top shape: 6 1 40 40 (9600)
I0810 21:05:20.218278   463 net.cpp:151] Top shape: 6 4 40 40 (38400)
I0810 21:05:20.218286   463 net.cpp:151] Top shape: 6 2 40 40 (19200)
I0810 21:05:20.218292   463 net.cpp:151] Top shape: 6 1 40 40 (9600)
I0810 21:05:20.218299   463 net.cpp:151] Top shape: 6 1 40 40 (9600)
I0810 21:05:20.218305   463 net.cpp:159] Memory required for data: 85134048
I0810 21:05:20.218312   463 layer_factory.hpp:77] Creating layer foreground-label_slice-label_0_split
I0810 21:05:20.218323   463 net.cpp:94] Creating Layer foreground-label_slice-label_0_split
I0810 21:05:20.218330   463 net.cpp:435] foreground-label_slice-label_0_split <- foreground-label
I0810 21:05:20.218341   463 net.cpp:409] foreground-label_slice-label_0_split -> foreground-label_slice-label_0_split_0
I0810 21:05:20.218350   463 net.cpp:409] foreground-label_slice-label_0_split -> foreground-label_slice-label_0_split_1
I0810 21:05:20.218360   463 net.cpp:409] foreground-label_slice-label_0_split -> foreground-label_slice-label_0_split_2
I0810 21:05:20.218370   463 net.cpp:409] foreground-label_slice-label_0_split -> foreground-label_slice-label_0_split_3
I0810 21:05:20.218436   463 net.cpp:144] Setting up foreground-label_slice-label_0_split
I0810 21:05:20.218446   463 net.cpp:151] Top shape: 6 1 40 40 (9600)
I0810 21:05:20.218452   463 net.cpp:151] Top shape: 6 1 40 40 (9600)
I0810 21:05:20.218459   463 net.cpp:151] Top shape: 6 1 40 40 (9600)
I0810 21:05:20.218466   463 net.cpp:151] Top shape: 6 1 40 40 (9600)
I0810 21:05:20.218472   463 net.cpp:159] Memory required for data: 85287648
I0810 21:05:20.218510   463 layer_factory.hpp:77] Creating layer bbox-label_slice-label_1_split
I0810 21:05:20.218520   463 net.cpp:94] Creating Layer bbox-label_slice-label_1_split
I0810 21:05:20.218528   463 net.cpp:435] bbox-label_slice-label_1_split <- bbox-label
I0810 21:05:20.218536   463 net.cpp:409] bbox-label_slice-label_1_split -> bbox-label_slice-label_1_split_0
I0810 21:05:20.218546   463 net.cpp:409] bbox-label_slice-label_1_split -> bbox-label_slice-label_1_split_1
I0810 21:05:20.218591   463 net.cpp:144] Setting up bbox-label_slice-label_1_split
I0810 21:05:20.218601   463 net.cpp:151] Top shape: 6 4 40 40 (38400)
I0810 21:05:20.218607   463 net.cpp:151] Top shape: 6 4 40 40 (38400)
I0810 21:05:20.218616   463 net.cpp:159] Memory required for data: 85594848
I0810 21:05:20.218621   463 layer_factory.hpp:77] Creating layer size-label_slice-label_2_split
I0810 21:05:20.218629   463 net.cpp:94] Creating Layer size-label_slice-label_2_split
I0810 21:05:20.218636   463 net.cpp:435] size-label_slice-label_2_split <- size-label
I0810 21:05:20.218647   463 net.cpp:409] size-label_slice-label_2_split -> size-label_slice-label_2_split_0
I0810 21:05:20.218657   463 net.cpp:409] size-label_slice-label_2_split -> size-label_slice-label_2_split_1
I0810 21:05:20.218703   463 net.cpp:144] Setting up size-label_slice-label_2_split
I0810 21:05:20.218713   463 net.cpp:151] Top shape: 6 2 40 40 (19200)
I0810 21:05:20.218720   463 net.cpp:151] Top shape: 6 2 40 40 (19200)
I0810 21:05:20.218725   463 net.cpp:159] Memory required for data: 85748448
I0810 21:05:20.218732   463 layer_factory.hpp:77] Creating layer obj-label_slice-label_3_split
I0810 21:05:20.218746   463 net.cpp:94] Creating Layer obj-label_slice-label_3_split
I0810 21:05:20.218752   463 net.cpp:435] obj-label_slice-label_3_split <- obj-label
I0810 21:05:20.218762   463 net.cpp:409] obj-label_slice-label_3_split -> obj-label_slice-label_3_split_0
I0810 21:05:20.218771   463 net.cpp:409] obj-label_slice-label_3_split -> obj-label_slice-label_3_split_1
I0810 21:05:20.218781   463 net.cpp:409] obj-label_slice-label_3_split -> obj-label_slice-label_3_split_2
I0810 21:05:20.218791   463 net.cpp:409] obj-label_slice-label_3_split -> obj-label_slice-label_3_split_3
I0810 21:05:20.218853   463 net.cpp:144] Setting up obj-label_slice-label_3_split
I0810 21:05:20.218868   463 net.cpp:151] Top shape: 6 1 40 40 (9600)
I0810 21:05:20.218875   463 net.cpp:151] Top shape: 6 1 40 40 (9600)
I0810 21:05:20.218883   463 net.cpp:151] Top shape: 6 1 40 40 (9600)
I0810 21:05:20.218888   463 net.cpp:151] Top shape: 6 1 40 40 (9600)
I0810 21:05:20.218894   463 net.cpp:159] Memory required for data: 85902048
I0810 21:05:20.218900   463 layer_factory.hpp:77] Creating layer coverage-label_slice-label_4_split
I0810 21:05:20.218910   463 net.cpp:94] Creating Layer coverage-label_slice-label_4_split
I0810 21:05:20.218917   463 net.cpp:435] coverage-label_slice-label_4_split <- coverage-label
I0810 21:05:20.218927   463 net.cpp:409] coverage-label_slice-label_4_split -> coverage-label_slice-label_4_split_0
I0810 21:05:20.218936   463 net.cpp:409] coverage-label_slice-label_4_split -> coverage-label_slice-label_4_split_1
I0810 21:05:20.218981   463 net.cpp:144] Setting up coverage-label_slice-label_4_split
I0810 21:05:20.218991   463 net.cpp:151] Top shape: 6 1 40 40 (9600)
I0810 21:05:20.218997   463 net.cpp:151] Top shape: 6 1 40 40 (9600)
I0810 21:05:20.219003   463 net.cpp:159] Memory required for data: 85978848
I0810 21:05:20.219009   463 layer_factory.hpp:77] Creating layer coverage-block
I0810 21:05:20.219019   463 net.cpp:94] Creating Layer coverage-block
I0810 21:05:20.219027   463 net.cpp:435] coverage-block <- foreground-label_slice-label_0_split_0
I0810 21:05:20.219034   463 net.cpp:435] coverage-block <- foreground-label_slice-label_0_split_1
I0810 21:05:20.219041   463 net.cpp:435] coverage-block <- foreground-label_slice-label_0_split_2
I0810 21:05:20.219048   463 net.cpp:435] coverage-block <- foreground-label_slice-label_0_split_3
I0810 21:05:20.219056   463 net.cpp:409] coverage-block -> coverage-block
I0810 21:05:20.219115   463 net.cpp:144] Setting up coverage-block
I0810 21:05:20.219125   463 net.cpp:151] Top shape: 6 4 40 40 (38400)
I0810 21:05:20.219130   463 net.cpp:159] Memory required for data: 86132448
I0810 21:05:20.219146   463 layer_factory.hpp:77] Creating layer size-block
I0810 21:05:20.219156   463 net.cpp:94] Creating Layer size-block
I0810 21:05:20.219162   463 net.cpp:435] size-block <- size-label_slice-label_2_split_0
I0810 21:05:20.219169   463 net.cpp:435] size-block <- size-label_slice-label_2_split_1
I0810 21:05:20.219178   463 net.cpp:409] size-block -> size-block
I0810 21:05:20.219210   463 net.cpp:144] Setting up size-block
I0810 21:05:20.219220   463 net.cpp:151] Top shape: 6 4 40 40 (38400)
I0810 21:05:20.219226   463 net.cpp:159] Memory required for data: 86286048
I0810 21:05:20.219233   463 layer_factory.hpp:77] Creating layer size-block_size-block_0_split
I0810 21:05:20.219241   463 net.cpp:94] Creating Layer size-block_size-block_0_split
I0810 21:05:20.219256   463 net.cpp:435] size-block_size-block_0_split <- size-block
I0810 21:05:20.219265   463 net.cpp:409] size-block_size-block_0_split -> size-block_size-block_0_split_0
I0810 21:05:20.219274   463 net.cpp:409] size-block_size-block_0_split -> size-block_size-block_0_split_1
I0810 21:05:20.219317   463 net.cpp:144] Setting up size-block_size-block_0_split
I0810 21:05:20.219327   463 net.cpp:151] Top shape: 6 4 40 40 (38400)
I0810 21:05:20.219334   463 net.cpp:151] Top shape: 6 4 40 40 (38400)
I0810 21:05:20.219339   463 net.cpp:159] Memory required for data: 86593248
I0810 21:05:20.219346   463 layer_factory.hpp:77] Creating layer obj-block
I0810 21:05:20.219355   463 net.cpp:94] Creating Layer obj-block
I0810 21:05:20.219362   463 net.cpp:435] obj-block <- obj-label_slice-label_3_split_0
I0810 21:05:20.219369   463 net.cpp:435] obj-block <- obj-label_slice-label_3_split_1
I0810 21:05:20.219377   463 net.cpp:435] obj-block <- obj-label_slice-label_3_split_2
I0810 21:05:20.219383   463 net.cpp:435] obj-block <- obj-label_slice-label_3_split_3
I0810 21:05:20.219393   463 net.cpp:409] obj-block -> obj-block
I0810 21:05:20.219421   463 net.cpp:144] Setting up obj-block
I0810 21:05:20.219430   463 net.cpp:151] Top shape: 6 4 40 40 (38400)
I0810 21:05:20.219435   463 net.cpp:159] Memory required for data: 86746848
I0810 21:05:20.219442   463 layer_factory.hpp:77] Creating layer obj-block_obj-block_0_split
I0810 21:05:20.219450   463 net.cpp:94] Creating Layer obj-block_obj-block_0_split
I0810 21:05:20.219456   463 net.cpp:435] obj-block_obj-block_0_split <- obj-block
I0810 21:05:20.219466   463 net.cpp:409] obj-block_obj-block_0_split -> obj-block_obj-block_0_split_0
I0810 21:05:20.219475   463 net.cpp:409] obj-block_obj-block_0_split -> obj-block_obj-block_0_split_1
I0810 21:05:20.219518   463 net.cpp:144] Setting up obj-block_obj-block_0_split
I0810 21:05:20.219532   463 net.cpp:151] Top shape: 6 4 40 40 (38400)
I0810 21:05:20.219539   463 net.cpp:151] Top shape: 6 4 40 40 (38400)
I0810 21:05:20.219545   463 net.cpp:159] Memory required for data: 87054048
I0810 21:05:20.219552   463 layer_factory.hpp:77] Creating layer bb-label-norm
I0810 21:05:20.219561   463 net.cpp:94] Creating Layer bb-label-norm
I0810 21:05:20.219568   463 net.cpp:435] bb-label-norm <- bbox-label_slice-label_1_split_0
I0810 21:05:20.219575   463 net.cpp:435] bb-label-norm <- size-block_size-block_0_split_0
I0810 21:05:20.219584   463 net.cpp:409] bb-label-norm -> bbox-label-norm
I0810 21:05:20.219621   463 net.cpp:144] Setting up bb-label-norm
I0810 21:05:20.219630   463 net.cpp:151] Top shape: 6 4 40 40 (38400)
I0810 21:05:20.219636   463 net.cpp:159] Memory required for data: 87207648
I0810 21:05:20.219645   463 layer_factory.hpp:77] Creating layer bb-obj-norm
I0810 21:05:20.219653   463 net.cpp:94] Creating Layer bb-obj-norm
I0810 21:05:20.219660   463 net.cpp:435] bb-obj-norm <- bbox-label-norm
I0810 21:05:20.219667   463 net.cpp:435] bb-obj-norm <- obj-block_obj-block_0_split_0
I0810 21:05:20.219676   463 net.cpp:409] bb-obj-norm -> bbox-obj-label-norm
I0810 21:05:20.219732   463 net.cpp:144] Setting up bb-obj-norm
I0810 21:05:20.219743   463 net.cpp:151] Top shape: 6 4 40 40 (38400)
I0810 21:05:20.219748   463 net.cpp:159] Memory required for data: 87361248
I0810 21:05:20.219754   463 layer_factory.hpp:77] Creating layer conv1/7x7_s2
I0810 21:05:20.219772   463 net.cpp:94] Creating Layer conv1/7x7_s2
I0810 21:05:20.219779   463 net.cpp:435] conv1/7x7_s2 <- transformed_data
I0810 21:05:20.219789   463 net.cpp:409] conv1/7x7_s2 -> conv1/7x7_s2
I0810 21:05:20.220274   463 net.cpp:144] Setting up conv1/7x7_s2
I0810 21:05:20.220289   463 net.cpp:151] Top shape: 6 64 320 320 (39321600)
I0810 21:05:20.220297   463 net.cpp:159] Memory required for data: 244647648
I0810 21:05:20.220311   463 layer_factory.hpp:77] Creating layer conv1/relu_7x7
I0810 21:05:20.220321   463 net.cpp:94] Creating Layer conv1/relu_7x7
I0810 21:05:20.220329   463 net.cpp:435] conv1/relu_7x7 <- conv1/7x7_s2
I0810 21:05:20.220337   463 net.cpp:396] conv1/relu_7x7 -> conv1/7x7_s2 (in-place)
I0810 21:05:20.220350   463 net.cpp:144] Setting up conv1/relu_7x7
I0810 21:05:20.220357   463 net.cpp:151] Top shape: 6 64 320 320 (39321600)
I0810 21:05:20.220363   463 net.cpp:159] Memory required for data: 401934048
I0810 21:05:20.220369   463 layer_factory.hpp:77] Creating layer pool1/3x3_s2
I0810 21:05:20.220379   463 net.cpp:94] Creating Layer pool1/3x3_s2
I0810 21:05:20.220386   463 net.cpp:435] pool1/3x3_s2 <- conv1/7x7_s2
I0810 21:05:20.220394   463 net.cpp:409] pool1/3x3_s2 -> pool1/3x3_s2
I0810 21:05:20.220454   463 net.cpp:144] Setting up pool1/3x3_s2
I0810 21:05:20.220463   463 net.cpp:151] Top shape: 6 64 160 160 (9830400)
I0810 21:05:20.220469   463 net.cpp:159] Memory required for data: 441255648
I0810 21:05:20.220475   463 layer_factory.hpp:77] Creating layer pool1/norm1
I0810 21:05:20.220487   463 net.cpp:94] Creating Layer pool1/norm1
I0810 21:05:20.220494   463 net.cpp:435] pool1/norm1 <- pool1/3x3_s2
I0810 21:05:20.220502   463 net.cpp:409] pool1/norm1 -> pool1/norm1
I0810 21:05:20.220551   463 net.cpp:144] Setting up pool1/norm1
I0810 21:05:20.220561   463 net.cpp:151] Top shape: 6 64 160 160 (9830400)
I0810 21:05:20.220566   463 net.cpp:159] Memory required for data: 480577248
I0810 21:05:20.220572   463 layer_factory.hpp:77] Creating layer conv2/3x3_reduce
I0810 21:05:20.220585   463 net.cpp:94] Creating Layer conv2/3x3_reduce
I0810 21:05:20.220592   463 net.cpp:435] conv2/3x3_reduce <- pool1/norm1
I0810 21:05:20.220602   463 net.cpp:409] conv2/3x3_reduce -> conv2/3x3_reduce
I0810 21:05:20.220968   463 net.cpp:144] Setting up conv2/3x3_reduce
I0810 21:05:20.220993   463 net.cpp:151] Top shape: 6 64 160 160 (9830400)
I0810 21:05:20.220999   463 net.cpp:159] Memory required for data: 519898848
I0810 21:05:20.221011   463 layer_factory.hpp:77] Creating layer conv2/relu_3x3_reduce
I0810 21:05:20.221022   463 net.cpp:94] Creating Layer conv2/relu_3x3_reduce
I0810 21:05:20.221033   463 net.cpp:435] conv2/relu_3x3_reduce <- conv2/3x3_reduce
I0810 21:05:20.221043   463 net.cpp:396] conv2/relu_3x3_reduce -> conv2/3x3_reduce (in-place)
I0810 21:05:20.221055   463 net.cpp:144] Setting up conv2/relu_3x3_reduce
I0810 21:05:20.221061   463 net.cpp:151] Top shape: 6 64 160 160 (9830400)
I0810 21:05:20.221066   463 net.cpp:159] Memory required for data: 559220448
I0810 21:05:20.221072   463 layer_factory.hpp:77] Creating layer conv2/3x3
I0810 21:05:20.221084   463 net.cpp:94] Creating Layer conv2/3x3
I0810 21:05:20.221091   463 net.cpp:435] conv2/3x3 <- conv2/3x3_reduce
I0810 21:05:20.221101   463 net.cpp:409] conv2/3x3 -> conv2/3x3
I0810 21:05:20.234923   463 net.cpp:144] Setting up conv2/3x3
I0810 21:05:20.234961   463 net.cpp:151] Top shape: 6 192 160 160 (29491200)
I0810 21:05:20.234968   463 net.cpp:159] Memory required for data: 677185248
I0810 21:05:20.234987   463 layer_factory.hpp:77] Creating layer conv2/relu_3x3
I0810 21:05:20.235003   463 net.cpp:94] Creating Layer conv2/relu_3x3
I0810 21:05:20.235134   463 net.cpp:435] conv2/relu_3x3 <- conv2/3x3
I0810 21:05:20.235157   463 net.cpp:396] conv2/relu_3x3 -> conv2/3x3 (in-place)
I0810 21:05:20.235209   463 net.cpp:144] Setting up conv2/relu_3x3
I0810 21:05:20.235220   463 net.cpp:151] Top shape: 6 192 160 160 (29491200)
I0810 21:05:20.235226   463 net.cpp:159] Memory required for data: 795150048
I0810 21:05:20.235234   463 layer_factory.hpp:77] Creating layer conv2/norm2
I0810 21:05:20.235286   463 net.cpp:94] Creating Layer conv2/norm2
I0810 21:05:20.235296   463 net.cpp:435] conv2/norm2 <- conv2/3x3
I0810 21:05:20.235306   463 net.cpp:409] conv2/norm2 -> conv2/norm2
I0810 21:05:20.235378   463 net.cpp:144] Setting up conv2/norm2
I0810 21:05:20.235389   463 net.cpp:151] Top shape: 6 192 160 160 (29491200)
I0810 21:05:20.235395   463 net.cpp:159] Memory required for data: 913114848
I0810 21:05:20.235401   463 layer_factory.hpp:77] Creating layer pool2/3x3_s2
I0810 21:05:20.235412   463 net.cpp:94] Creating Layer pool2/3x3_s2
I0810 21:05:20.235419   463 net.cpp:435] pool2/3x3_s2 <- conv2/norm2
I0810 21:05:20.235429   463 net.cpp:409] pool2/3x3_s2 -> pool2/3x3_s2
I0810 21:05:20.235477   463 net.cpp:144] Setting up pool2/3x3_s2
I0810 21:05:20.235487   463 net.cpp:151] Top shape: 6 192 80 80 (7372800)
I0810 21:05:20.235493   463 net.cpp:159] Memory required for data: 942606048
I0810 21:05:20.235499   463 layer_factory.hpp:77] Creating layer pool2/3x3_s2_pool2/3x3_s2_0_split
I0810 21:05:20.235509   463 net.cpp:94] Creating Layer pool2/3x3_s2_pool2/3x3_s2_0_split
I0810 21:05:20.235517   463 net.cpp:435] pool2/3x3_s2_pool2/3x3_s2_0_split <- pool2/3x3_s2
I0810 21:05:20.235527   463 net.cpp:409] pool2/3x3_s2_pool2/3x3_s2_0_split -> pool2/3x3_s2_pool2/3x3_s2_0_split_0
I0810 21:05:20.235536   463 net.cpp:409] pool2/3x3_s2_pool2/3x3_s2_0_split -> pool2/3x3_s2_pool2/3x3_s2_0_split_1
I0810 21:05:20.235548   463 net.cpp:409] pool2/3x3_s2_pool2/3x3_s2_0_split -> pool2/3x3_s2_pool2/3x3_s2_0_split_2
I0810 21:05:20.235558   463 net.cpp:409] pool2/3x3_s2_pool2/3x3_s2_0_split -> pool2/3x3_s2_pool2/3x3_s2_0_split_3
I0810 21:05:20.235625   463 net.cpp:144] Setting up pool2/3x3_s2_pool2/3x3_s2_0_split
I0810 21:05:20.235635   463 net.cpp:151] Top shape: 6 192 80 80 (7372800)
I0810 21:05:20.235641   463 net.cpp:151] Top shape: 6 192 80 80 (7372800)
I0810 21:05:20.235648   463 net.cpp:151] Top shape: 6 192 80 80 (7372800)
I0810 21:05:20.235654   463 net.cpp:151] Top shape: 6 192 80 80 (7372800)
I0810 21:05:20.235661   463 net.cpp:159] Memory required for data: 1060570848
I0810 21:05:20.235666   463 layer_factory.hpp:77] Creating layer inception_3a/1x1
I0810 21:05:20.235682   463 net.cpp:94] Creating Layer inception_3a/1x1
I0810 21:05:20.235688   463 net.cpp:435] inception_3a/1x1 <- pool2/3x3_s2_pool2/3x3_s2_0_split_0
I0810 21:05:20.235700   463 net.cpp:409] inception_3a/1x1 -> inception_3a/1x1
I0810 21:05:20.236057   463 net.cpp:144] Setting up inception_3a/1x1
I0810 21:05:20.236070   463 net.cpp:151] Top shape: 6 64 80 80 (2457600)
I0810 21:05:20.236076   463 net.cpp:159] Memory required for data: 1070401248
I0810 21:05:20.236086   463 layer_factory.hpp:77] Creating layer inception_3a/relu_1x1
I0810 21:05:20.236095   463 net.cpp:94] Creating Layer inception_3a/relu_1x1
I0810 21:05:20.236102   463 net.cpp:435] inception_3a/relu_1x1 <- inception_3a/1x1
I0810 21:05:20.236111   463 net.cpp:396] inception_3a/relu_1x1 -> inception_3a/1x1 (in-place)
I0810 21:05:20.236121   463 net.cpp:144] Setting up inception_3a/relu_1x1
I0810 21:05:20.236129   463 net.cpp:151] Top shape: 6 64 80 80 (2457600)
I0810 21:05:20.236135   463 net.cpp:159] Memory required for data: 1080231648
I0810 21:05:20.236140   463 layer_factory.hpp:77] Creating layer inception_3a/3x3_reduce
I0810 21:05:20.236152   463 net.cpp:94] Creating Layer inception_3a/3x3_reduce
I0810 21:05:20.236160   463 net.cpp:435] inception_3a/3x3_reduce <- pool2/3x3_s2_pool2/3x3_s2_0_split_1
I0810 21:05:20.236171   463 net.cpp:409] inception_3a/3x3_reduce -> inception_3a/3x3_reduce
I0810 21:05:20.236593   463 net.cpp:144] Setting up inception_3a/3x3_reduce
I0810 21:05:20.236605   463 net.cpp:151] Top shape: 6 96 80 80 (3686400)
I0810 21:05:20.236611   463 net.cpp:159] Memory required for data: 1094977248
I0810 21:05:20.236639   463 layer_factory.hpp:77] Creating layer inception_3a/relu_3x3_reduce
I0810 21:05:20.236649   463 net.cpp:94] Creating Layer inception_3a/relu_3x3_reduce
I0810 21:05:20.236656   463 net.cpp:435] inception_3a/relu_3x3_reduce <- inception_3a/3x3_reduce
I0810 21:05:20.236665   463 net.cpp:396] inception_3a/relu_3x3_reduce -> inception_3a/3x3_reduce (in-place)
I0810 21:05:20.236675   463 net.cpp:144] Setting up inception_3a/relu_3x3_reduce
I0810 21:05:20.236683   463 net.cpp:151] Top shape: 6 96 80 80 (3686400)
I0810 21:05:20.236690   463 net.cpp:159] Memory required for data: 1109722848
I0810 21:05:20.236696   463 layer_factory.hpp:77] Creating layer inception_3a/3x3
I0810 21:05:20.236708   463 net.cpp:94] Creating Layer inception_3a/3x3
I0810 21:05:20.236716   463 net.cpp:435] inception_3a/3x3 <- inception_3a/3x3_reduce
I0810 21:05:20.236726   463 net.cpp:409] inception_3a/3x3 -> inception_3a/3x3
I0810 21:05:20.237610   463 net.cpp:144] Setting up inception_3a/3x3
I0810 21:05:20.237624   463 net.cpp:151] Top shape: 6 128 80 80 (4915200)
I0810 21:05:20.237630   463 net.cpp:159] Memory required for data: 1129383648
I0810 21:05:20.237640   463 layer_factory.hpp:77] Creating layer inception_3a/relu_3x3
I0810 21:05:20.237658   463 net.cpp:94] Creating Layer inception_3a/relu_3x3
I0810 21:05:20.237664   463 net.cpp:435] inception_3a/relu_3x3 <- inception_3a/3x3
I0810 21:05:20.237673   463 net.cpp:396] inception_3a/relu_3x3 -> inception_3a/3x3 (in-place)
I0810 21:05:20.237684   463 net.cpp:144] Setting up inception_3a/relu_3x3
I0810 21:05:20.237690   463 net.cpp:151] Top shape: 6 128 80 80 (4915200)
I0810 21:05:20.237696   463 net.cpp:159] Memory required for data: 1149044448
I0810 21:05:20.237702   463 layer_factory.hpp:77] Creating layer inception_3a/5x5_reduce
I0810 21:05:20.237715   463 net.cpp:94] Creating Layer inception_3a/5x5_reduce
I0810 21:05:20.237721   463 net.cpp:435] inception_3a/5x5_reduce <- pool2/3x3_s2_pool2/3x3_s2_0_split_2
I0810 21:05:20.237732   463 net.cpp:409] inception_3a/5x5_reduce -> inception_3a/5x5_reduce
I0810 21:05:20.238026   463 net.cpp:144] Setting up inception_3a/5x5_reduce
I0810 21:05:20.238039   463 net.cpp:151] Top shape: 6 16 80 80 (614400)
I0810 21:05:20.238044   463 net.cpp:159] Memory required for data: 1151502048
I0810 21:05:20.238054   463 layer_factory.hpp:77] Creating layer inception_3a/relu_5x5_reduce
I0810 21:05:20.238062   463 net.cpp:94] Creating Layer inception_3a/relu_5x5_reduce
I0810 21:05:20.238070   463 net.cpp:435] inception_3a/relu_5x5_reduce <- inception_3a/5x5_reduce
I0810 21:05:20.238078   463 net.cpp:396] inception_3a/relu_5x5_reduce -> inception_3a/5x5_reduce (in-place)
I0810 21:05:20.238087   463 net.cpp:144] Setting up inception_3a/relu_5x5_reduce
I0810 21:05:20.238095   463 net.cpp:151] Top shape: 6 16 80 80 (614400)
I0810 21:05:20.238101   463 net.cpp:159] Memory required for data: 1153959648
I0810 21:05:20.238107   463 layer_factory.hpp:77] Creating layer inception_3a/5x5
I0810 21:05:20.238118   463 net.cpp:94] Creating Layer inception_3a/5x5
I0810 21:05:20.238126   463 net.cpp:435] inception_3a/5x5 <- inception_3a/5x5_reduce
I0810 21:05:20.238135   463 net.cpp:409] inception_3a/5x5 -> inception_3a/5x5
I0810 21:05:20.238497   463 net.cpp:144] Setting up inception_3a/5x5
I0810 21:05:20.238508   463 net.cpp:151] Top shape: 6 32 80 80 (1228800)
I0810 21:05:20.238514   463 net.cpp:159] Memory required for data: 1158874848
I0810 21:05:20.238523   463 layer_factory.hpp:77] Creating layer inception_3a/relu_5x5
I0810 21:05:20.238533   463 net.cpp:94] Creating Layer inception_3a/relu_5x5
I0810 21:05:20.238538   463 net.cpp:435] inception_3a/relu_5x5 <- inception_3a/5x5
I0810 21:05:20.238548   463 net.cpp:396] inception_3a/relu_5x5 -> inception_3a/5x5 (in-place)
I0810 21:05:20.238557   463 net.cpp:144] Setting up inception_3a/relu_5x5
I0810 21:05:20.238565   463 net.cpp:151] Top shape: 6 32 80 80 (1228800)
I0810 21:05:20.238571   463 net.cpp:159] Memory required for data: 1163790048
I0810 21:05:20.238590   463 layer_factory.hpp:77] Creating layer inception_3a/pool
I0810 21:05:20.238600   463 net.cpp:94] Creating Layer inception_3a/pool
I0810 21:05:20.238607   463 net.cpp:435] inception_3a/pool <- pool2/3x3_s2_pool2/3x3_s2_0_split_3
I0810 21:05:20.238615   463 net.cpp:409] inception_3a/pool -> inception_3a/pool
I0810 21:05:20.238668   463 net.cpp:144] Setting up inception_3a/pool
I0810 21:05:20.238678   463 net.cpp:151] Top shape: 6 192 80 80 (7372800)
I0810 21:05:20.238683   463 net.cpp:159] Memory required for data: 1193281248
I0810 21:05:20.238690   463 layer_factory.hpp:77] Creating layer inception_3a/pool_proj
I0810 21:05:20.238704   463 net.cpp:94] Creating Layer inception_3a/pool_proj
I0810 21:05:20.238711   463 net.cpp:435] inception_3a/pool_proj <- inception_3a/pool
I0810 21:05:20.238721   463 net.cpp:409] inception_3a/pool_proj -> inception_3a/pool_proj
I0810 21:05:20.239739   463 net.cpp:144] Setting up inception_3a/pool_proj
I0810 21:05:20.239758   463 net.cpp:151] Top shape: 6 32 80 80 (1228800)
I0810 21:05:20.239764   463 net.cpp:159] Memory required for data: 1198196448
I0810 21:05:20.239778   463 layer_factory.hpp:77] Creating layer inception_3a/relu_pool_proj
I0810 21:05:20.239790   463 net.cpp:94] Creating Layer inception_3a/relu_pool_proj
I0810 21:05:20.239797   463 net.cpp:435] inception_3a/relu_pool_proj <- inception_3a/pool_proj
I0810 21:05:20.239806   463 net.cpp:396] inception_3a/relu_pool_proj -> inception_3a/pool_proj (in-place)
I0810 21:05:20.239818   463 net.cpp:144] Setting up inception_3a/relu_pool_proj
I0810 21:05:20.239827   463 net.cpp:151] Top shape: 6 32 80 80 (1228800)
I0810 21:05:20.239833   463 net.cpp:159] Memory required for data: 1203111648
I0810 21:05:20.239840   463 layer_factory.hpp:77] Creating layer inception_3a/output
I0810 21:05:20.239850   463 net.cpp:94] Creating Layer inception_3a/output
I0810 21:05:20.239856   463 net.cpp:435] inception_3a/output <- inception_3a/1x1
I0810 21:05:20.239864   463 net.cpp:435] inception_3a/output <- inception_3a/3x3
I0810 21:05:20.239871   463 net.cpp:435] inception_3a/output <- inception_3a/5x5
I0810 21:05:20.239878   463 net.cpp:435] inception_3a/output <- inception_3a/pool_proj
I0810 21:05:20.239887   463 net.cpp:409] inception_3a/output -> inception_3a/output
I0810 21:05:20.239926   463 net.cpp:144] Setting up inception_3a/output
I0810 21:05:20.239935   463 net.cpp:151] Top shape: 6 256 80 80 (9830400)
I0810 21:05:20.239941   463 net.cpp:159] Memory required for data: 1242433248
I0810 21:05:20.239948   463 layer_factory.hpp:77] Creating layer inception_3a/output_inception_3a/output_0_split
I0810 21:05:20.239958   463 net.cpp:94] Creating Layer inception_3a/output_inception_3a/output_0_split
I0810 21:05:20.239964   463 net.cpp:435] inception_3a/output_inception_3a/output_0_split <- inception_3a/output
I0810 21:05:20.239974   463 net.cpp:409] inception_3a/output_inception_3a/output_0_split -> inception_3a/output_inception_3a/output_0_split_0
I0810 21:05:20.239985   463 net.cpp:409] inception_3a/output_inception_3a/output_0_split -> inception_3a/output_inception_3a/output_0_split_1
I0810 21:05:20.239995   463 net.cpp:409] inception_3a/output_inception_3a/output_0_split -> inception_3a/output_inception_3a/output_0_split_2
I0810 21:05:20.240005   463 net.cpp:409] inception_3a/output_inception_3a/output_0_split -> inception_3a/output_inception_3a/output_0_split_3
I0810 21:05:20.240072   463 net.cpp:144] Setting up inception_3a/output_inception_3a/output_0_split
I0810 21:05:20.240082   463 net.cpp:151] Top shape: 6 256 80 80 (9830400)
I0810 21:05:20.240088   463 net.cpp:151] Top shape: 6 256 80 80 (9830400)
I0810 21:05:20.240094   463 net.cpp:151] Top shape: 6 256 80 80 (9830400)
I0810 21:05:20.240101   463 net.cpp:151] Top shape: 6 256 80 80 (9830400)
I0810 21:05:20.240108   463 net.cpp:159] Memory required for data: 1399719648
I0810 21:05:20.240113   463 layer_factory.hpp:77] Creating layer inception_3b/1x1
I0810 21:05:20.240125   463 net.cpp:94] Creating Layer inception_3b/1x1
I0810 21:05:20.240133   463 net.cpp:435] inception_3b/1x1 <- inception_3a/output_inception_3a/output_0_split_0
I0810 21:05:20.240157   463 net.cpp:409] inception_3b/1x1 -> inception_3b/1x1
I0810 21:05:20.240615   463 net.cpp:144] Setting up inception_3b/1x1
I0810 21:05:20.240628   463 net.cpp:151] Top shape: 6 128 80 80 (4915200)
I0810 21:05:20.240634   463 net.cpp:159] Memory required for data: 1419380448
I0810 21:05:20.240643   463 layer_factory.hpp:77] Creating layer inception_3b/relu_1x1
I0810 21:05:20.240653   463 net.cpp:94] Creating Layer inception_3b/relu_1x1
I0810 21:05:20.240660   463 net.cpp:435] inception_3b/relu_1x1 <- inception_3b/1x1
I0810 21:05:20.240670   463 net.cpp:396] inception_3b/relu_1x1 -> inception_3b/1x1 (in-place)
I0810 21:05:20.240680   463 net.cpp:144] Setting up inception_3b/relu_1x1
I0810 21:05:20.240689   463 net.cpp:151] Top shape: 6 128 80 80 (4915200)
I0810 21:05:20.240694   463 net.cpp:159] Memory required for data: 1439041248
I0810 21:05:20.240700   463 layer_factory.hpp:77] Creating layer inception_3b/3x3_reduce
I0810 21:05:20.240710   463 net.cpp:94] Creating Layer inception_3b/3x3_reduce
I0810 21:05:20.240717   463 net.cpp:435] inception_3b/3x3_reduce <- inception_3a/output_inception_3a/output_0_split_1
I0810 21:05:20.240727   463 net.cpp:409] inception_3b/3x3_reduce -> inception_3b/3x3_reduce
I0810 21:05:20.241212   463 net.cpp:144] Setting up inception_3b/3x3_reduce
I0810 21:05:20.241226   463 net.cpp:151] Top shape: 6 128 80 80 (4915200)
I0810 21:05:20.241232   463 net.cpp:159] Memory required for data: 1458702048
I0810 21:05:20.241241   463 layer_factory.hpp:77] Creating layer inception_3b/relu_3x3_reduce
I0810 21:05:20.241258   463 net.cpp:94] Creating Layer inception_3b/relu_3x3_reduce
I0810 21:05:20.241266   463 net.cpp:435] inception_3b/relu_3x3_reduce <- inception_3b/3x3_reduce
I0810 21:05:20.241276   463 net.cpp:396] inception_3b/relu_3x3_reduce -> inception_3b/3x3_reduce (in-place)
I0810 21:05:20.241287   463 net.cpp:144] Setting up inception_3b/relu_3x3_reduce
I0810 21:05:20.241294   463 net.cpp:151] Top shape: 6 128 80 80 (4915200)
I0810 21:05:20.241300   463 net.cpp:159] Memory required for data: 1478362848
I0810 21:05:20.241307   463 layer_factory.hpp:77] Creating layer inception_3b/3x3
I0810 21:05:20.241317   463 net.cpp:94] Creating Layer inception_3b/3x3
I0810 21:05:20.241323   463 net.cpp:435] inception_3b/3x3 <- inception_3b/3x3_reduce
I0810 21:05:20.241333   463 net.cpp:409] inception_3b/3x3 -> inception_3b/3x3
I0810 21:05:20.243415   463 net.cpp:144] Setting up inception_3b/3x3
I0810 21:05:20.243432   463 net.cpp:151] Top shape: 6 192 80 80 (7372800)
I0810 21:05:20.243438   463 net.cpp:159] Memory required for data: 1507854048
I0810 21:05:20.243448   463 layer_factory.hpp:77] Creating layer inception_3b/relu_3x3
I0810 21:05:20.243458   463 net.cpp:94] Creating Layer inception_3b/relu_3x3
I0810 21:05:20.243465   463 net.cpp:435] inception_3b/relu_3x3 <- inception_3b/3x3
I0810 21:05:20.243475   463 net.cpp:396] inception_3b/relu_3x3 -> inception_3b/3x3 (in-place)
I0810 21:05:20.243487   463 net.cpp:144] Setting up inception_3b/relu_3x3
I0810 21:05:20.243495   463 net.cpp:151] Top shape: 6 192 80 80 (7372800)
I0810 21:05:20.243501   463 net.cpp:159] Memory required for data: 1537345248
I0810 21:05:20.243507   463 layer_factory.hpp:77] Creating layer inception_3b/5x5_reduce
I0810 21:05:20.243520   463 net.cpp:94] Creating Layer inception_3b/5x5_reduce
I0810 21:05:20.243526   463 net.cpp:435] inception_3b/5x5_reduce <- inception_3a/output_inception_3a/output_0_split_2
I0810 21:05:20.243536   463 net.cpp:409] inception_3b/5x5_reduce -> inception_3b/5x5_reduce
I0810 21:05:20.243846   463 net.cpp:144] Setting up inception_3b/5x5_reduce
I0810 21:05:20.243858   463 net.cpp:151] Top shape: 6 32 80 80 (1228800)
I0810 21:05:20.243865   463 net.cpp:159] Memory required for data: 1542260448
I0810 21:05:20.243873   463 layer_factory.hpp:77] Creating layer inception_3b/relu_5x5_reduce
I0810 21:05:20.243882   463 net.cpp:94] Creating Layer inception_3b/relu_5x5_reduce
I0810 21:05:20.243890   463 net.cpp:435] inception_3b/relu_5x5_reduce <- inception_3b/5x5_reduce
I0810 21:05:20.243913   463 net.cpp:396] inception_3b/relu_5x5_reduce -> inception_3b/5x5_reduce (in-place)
I0810 21:05:20.243924   463 net.cpp:144] Setting up inception_3b/relu_5x5_reduce
I0810 21:05:20.243932   463 net.cpp:151] Top shape: 6 32 80 80 (1228800)
I0810 21:05:20.243937   463 net.cpp:159] Memory required for data: 1547175648
I0810 21:05:20.243943   463 layer_factory.hpp:77] Creating layer inception_3b/5x5
I0810 21:05:20.243957   463 net.cpp:94] Creating Layer inception_3b/5x5
I0810 21:05:20.243964   463 net.cpp:435] inception_3b/5x5 <- inception_3b/5x5_reduce
I0810 21:05:20.243974   463 net.cpp:409] inception_3b/5x5 -> inception_3b/5x5
I0810 21:05:20.244709   463 net.cpp:144] Setting up inception_3b/5x5
I0810 21:05:20.244721   463 net.cpp:151] Top shape: 6 96 80 80 (3686400)
I0810 21:05:20.244727   463 net.cpp:159] Memory required for data: 1561921248
I0810 21:05:20.244736   463 layer_factory.hpp:77] Creating layer inception_3b/relu_5x5
I0810 21:05:20.244745   463 net.cpp:94] Creating Layer inception_3b/relu_5x5
I0810 21:05:20.244753   463 net.cpp:435] inception_3b/relu_5x5 <- inception_3b/5x5
I0810 21:05:20.244763   463 net.cpp:396] inception_3b/relu_5x5 -> inception_3b/5x5 (in-place)
I0810 21:05:20.244773   463 net.cpp:144] Setting up inception_3b/relu_5x5
I0810 21:05:20.244781   463 net.cpp:151] Top shape: 6 96 80 80 (3686400)
I0810 21:05:20.244786   463 net.cpp:159] Memory required for data: 1576666848
I0810 21:05:20.244792   463 layer_factory.hpp:77] Creating layer inception_3b/pool
I0810 21:05:20.244801   463 net.cpp:94] Creating Layer inception_3b/pool
I0810 21:05:20.244808   463 net.cpp:435] inception_3b/pool <- inception_3a/output_inception_3a/output_0_split_3
I0810 21:05:20.244817   463 net.cpp:409] inception_3b/pool -> inception_3b/pool
I0810 21:05:20.244868   463 net.cpp:144] Setting up inception_3b/pool
I0810 21:05:20.244877   463 net.cpp:151] Top shape: 6 256 80 80 (9830400)
I0810 21:05:20.244902   463 net.cpp:159] Memory required for data: 1615988448
I0810 21:05:20.244910   463 layer_factory.hpp:77] Creating layer inception_3b/pool_proj
I0810 21:05:20.244922   463 net.cpp:94] Creating Layer inception_3b/pool_proj
I0810 21:05:20.244930   463 net.cpp:435] inception_3b/pool_proj <- inception_3b/pool
I0810 21:05:20.244940   463 net.cpp:409] inception_3b/pool_proj -> inception_3b/pool_proj
I0810 21:05:20.245301   463 net.cpp:144] Setting up inception_3b/pool_proj
I0810 21:05:20.245312   463 net.cpp:151] Top shape: 6 64 80 80 (2457600)
I0810 21:05:20.245318   463 net.cpp:159] Memory required for data: 1625818848
I0810 21:05:20.245327   463 layer_factory.hpp:77] Creating layer inception_3b/relu_pool_proj
I0810 21:05:20.245337   463 net.cpp:94] Creating Layer inception_3b/relu_pool_proj
I0810 21:05:20.245344   463 net.cpp:435] inception_3b/relu_pool_proj <- inception_3b/pool_proj
I0810 21:05:20.245354   463 net.cpp:396] inception_3b/relu_pool_proj -> inception_3b/pool_proj (in-place)
I0810 21:05:20.245364   463 net.cpp:144] Setting up inception_3b/relu_pool_proj
I0810 21:05:20.245371   463 net.cpp:151] Top shape: 6 64 80 80 (2457600)
I0810 21:05:20.245378   463 net.cpp:159] Memory required for data: 1635649248
I0810 21:05:20.245383   463 layer_factory.hpp:77] Creating layer inception_3b/output
I0810 21:05:20.245393   463 net.cpp:94] Creating Layer inception_3b/output
I0810 21:05:20.245398   463 net.cpp:435] inception_3b/output <- inception_3b/1x1
I0810 21:05:20.245406   463 net.cpp:435] inception_3b/output <- inception_3b/3x3
I0810 21:05:20.245414   463 net.cpp:435] inception_3b/output <- inception_3b/5x5
I0810 21:05:20.245420   463 net.cpp:435] inception_3b/output <- inception_3b/pool_proj
I0810 21:05:20.245429   463 net.cpp:409] inception_3b/output -> inception_3b/output
I0810 21:05:20.245465   463 net.cpp:144] Setting up inception_3b/output
I0810 21:05:20.245473   463 net.cpp:151] Top shape: 6 480 80 80 (18432000)
I0810 21:05:20.245479   463 net.cpp:159] Memory required for data: 1709377248
I0810 21:05:20.245486   463 layer_factory.hpp:77] Creating layer pool3/3x3_s2
I0810 21:05:20.245507   463 net.cpp:94] Creating Layer pool3/3x3_s2
I0810 21:05:20.245515   463 net.cpp:435] pool3/3x3_s2 <- inception_3b/output
I0810 21:05:20.245525   463 net.cpp:409] pool3/3x3_s2 -> pool3/3x3_s2
I0810 21:05:20.245676   463 net.cpp:144] Setting up pool3/3x3_s2
I0810 21:05:20.245697   463 net.cpp:151] Top shape: 6 480 40 40 (4608000)
I0810 21:05:20.245703   463 net.cpp:159] Memory required for data: 1727809248
I0810 21:05:20.245712   463 layer_factory.hpp:77] Creating layer pool3/3x3_s2_pool3/3x3_s2_0_split
I0810 21:05:20.245725   463 net.cpp:94] Creating Layer pool3/3x3_s2_pool3/3x3_s2_0_split
I0810 21:05:20.245733   463 net.cpp:435] pool3/3x3_s2_pool3/3x3_s2_0_split <- pool3/3x3_s2
I0810 21:05:20.245744   463 net.cpp:409] pool3/3x3_s2_pool3/3x3_s2_0_split -> pool3/3x3_s2_pool3/3x3_s2_0_split_0
I0810 21:05:20.245770   463 net.cpp:409] pool3/3x3_s2_pool3/3x3_s2_0_split -> pool3/3x3_s2_pool3/3x3_s2_0_split_1
I0810 21:05:20.245780   463 net.cpp:409] pool3/3x3_s2_pool3/3x3_s2_0_split -> pool3/3x3_s2_pool3/3x3_s2_0_split_2
I0810 21:05:20.245792   463 net.cpp:409] pool3/3x3_s2_pool3/3x3_s2_0_split -> pool3/3x3_s2_pool3/3x3_s2_0_split_3
I0810 21:05:20.245867   463 net.cpp:144] Setting up pool3/3x3_s2_pool3/3x3_s2_0_split
I0810 21:05:20.245878   463 net.cpp:151] Top shape: 6 480 40 40 (4608000)
I0810 21:05:20.245885   463 net.cpp:151] Top shape: 6 480 40 40 (4608000)
I0810 21:05:20.245893   463 net.cpp:151] Top shape: 6 480 40 40 (4608000)
I0810 21:05:20.245898   463 net.cpp:151] Top shape: 6 480 40 40 (4608000)
I0810 21:05:20.245904   463 net.cpp:159] Memory required for data: 1801537248
I0810 21:05:20.245910   463 layer_factory.hpp:77] Creating layer inception_4a/1x1
I0810 21:05:20.245924   463 net.cpp:94] Creating Layer inception_4a/1x1
I0810 21:05:20.245931   463 net.cpp:435] inception_4a/1x1 <- pool3/3x3_s2_pool3/3x3_s2_0_split_0
I0810 21:05:20.245942   463 net.cpp:409] inception_4a/1x1 -> inception_4a/1x1
I0810 21:05:20.246759   463 net.cpp:144] Setting up inception_4a/1x1
I0810 21:05:20.246773   463 net.cpp:151] Top shape: 6 192 40 40 (1843200)
I0810 21:05:20.246778   463 net.cpp:159] Memory required for data: 1808910048
I0810 21:05:20.246789   463 layer_factory.hpp:77] Creating layer inception_4a/relu_1x1
I0810 21:05:20.246799   463 net.cpp:94] Creating Layer inception_4a/relu_1x1
I0810 21:05:20.246806   463 net.cpp:435] inception_4a/relu_1x1 <- inception_4a/1x1
I0810 21:05:20.246815   463 net.cpp:396] inception_4a/relu_1x1 -> inception_4a/1x1 (in-place)
I0810 21:05:20.246827   463 net.cpp:144] Setting up inception_4a/relu_1x1
I0810 21:05:20.246834   463 net.cpp:151] Top shape: 6 192 40 40 (1843200)
I0810 21:05:20.246840   463 net.cpp:159] Memory required for data: 1816282848
I0810 21:05:20.246846   463 layer_factory.hpp:77] Creating layer inception_4a/3x3_reduce
I0810 21:05:20.246858   463 net.cpp:94] Creating Layer inception_4a/3x3_reduce
I0810 21:05:20.246865   463 net.cpp:435] inception_4a/3x3_reduce <- pool3/3x3_s2_pool3/3x3_s2_0_split_1
I0810 21:05:20.246876   463 net.cpp:409] inception_4a/3x3_reduce -> inception_4a/3x3_reduce
I0810 21:05:20.247500   463 net.cpp:144] Setting up inception_4a/3x3_reduce
I0810 21:05:20.247515   463 net.cpp:151] Top shape: 6 96 40 40 (921600)
I0810 21:05:20.247521   463 net.cpp:159] Memory required for data: 1819969248
I0810 21:05:20.247539   463 layer_factory.hpp:77] Creating layer inception_4a/relu_3x3_reduce
I0810 21:05:20.247550   463 net.cpp:94] Creating Layer inception_4a/relu_3x3_reduce
I0810 21:05:20.247557   463 net.cpp:435] inception_4a/relu_3x3_reduce <- inception_4a/3x3_reduce
I0810 21:05:20.247567   463 net.cpp:396] inception_4a/relu_3x3_reduce -> inception_4a/3x3_reduce (in-place)
I0810 21:05:20.247578   463 net.cpp:144] Setting up inception_4a/relu_3x3_reduce
I0810 21:05:20.247586   463 net.cpp:151] Top shape: 6 96 40 40 (921600)
I0810 21:05:20.247591   463 net.cpp:159] Memory required for data: 1823655648
I0810 21:05:20.247597   463 layer_factory.hpp:77] Creating layer inception_4a/3x3
I0810 21:05:20.247608   463 net.cpp:94] Creating Layer inception_4a/3x3
I0810 21:05:20.247633   463 net.cpp:435] inception_4a/3x3 <- inception_4a/3x3_reduce
I0810 21:05:20.247645   463 net.cpp:409] inception_4a/3x3 -> inception_4a/3x3
I0810 21:05:20.262312   463 net.cpp:144] Setting up inception_4a/3x3
I0810 21:05:20.262367   463 net.cpp:151] Top shape: 6 208 40 40 (1996800)
I0810 21:05:20.262373   463 net.cpp:159] Memory required for data: 1831642848
I0810 21:05:20.262388   463 layer_factory.hpp:77] Creating layer inception_4a/relu_3x3
I0810 21:05:20.262404   463 net.cpp:94] Creating Layer inception_4a/relu_3x3
I0810 21:05:20.262414   463 net.cpp:435] inception_4a/relu_3x3 <- inception_4a/3x3
I0810 21:05:20.262428   463 net.cpp:396] inception_4a/relu_3x3 -> inception_4a/3x3 (in-place)
I0810 21:05:20.262444   463 net.cpp:144] Setting up inception_4a/relu_3x3
I0810 21:05:20.262452   463 net.cpp:151] Top shape: 6 208 40 40 (1996800)
I0810 21:05:20.262459   463 net.cpp:159] Memory required for data: 1839630048
I0810 21:05:20.262465   463 layer_factory.hpp:77] Creating layer inception_4a/5x5_reduce
I0810 21:05:20.262501   463 net.cpp:94] Creating Layer inception_4a/5x5_reduce
I0810 21:05:20.262511   463 net.cpp:435] inception_4a/5x5_reduce <- pool3/3x3_s2_pool3/3x3_s2_0_split_2
I0810 21:05:20.262521   463 net.cpp:409] inception_4a/5x5_reduce -> inception_4a/5x5_reduce
I0810 21:05:20.262871   463 net.cpp:144] Setting up inception_4a/5x5_reduce
I0810 21:05:20.262884   463 net.cpp:151] Top shape: 6 16 40 40 (153600)
I0810 21:05:20.262889   463 net.cpp:159] Memory required for data: 1840244448
I0810 21:05:20.262899   463 layer_factory.hpp:77] Creating layer inception_4a/relu_5x5_reduce
I0810 21:05:20.262908   463 net.cpp:94] Creating Layer inception_4a/relu_5x5_reduce
I0810 21:05:20.262917   463 net.cpp:435] inception_4a/relu_5x5_reduce <- inception_4a/5x5_reduce
I0810 21:05:20.262925   463 net.cpp:396] inception_4a/relu_5x5_reduce -> inception_4a/5x5_reduce (in-place)
I0810 21:05:20.262936   463 net.cpp:144] Setting up inception_4a/relu_5x5_reduce
I0810 21:05:20.262943   463 net.cpp:151] Top shape: 6 16 40 40 (153600)
I0810 21:05:20.262949   463 net.cpp:159] Memory required for data: 1840858848
I0810 21:05:20.262955   463 layer_factory.hpp:77] Creating layer inception_4a/5x5
I0810 21:05:20.262966   463 net.cpp:94] Creating Layer inception_4a/5x5
I0810 21:05:20.262974   463 net.cpp:435] inception_4a/5x5 <- inception_4a/5x5_reduce
I0810 21:05:20.262984   463 net.cpp:409] inception_4a/5x5 -> inception_4a/5x5
I0810 21:05:20.263386   463 net.cpp:144] Setting up inception_4a/5x5
I0810 21:05:20.263399   463 net.cpp:151] Top shape: 6 48 40 40 (460800)
I0810 21:05:20.263406   463 net.cpp:159] Memory required for data: 1842702048
I0810 21:05:20.263414   463 layer_factory.hpp:77] Creating layer inception_4a/relu_5x5
I0810 21:05:20.263424   463 net.cpp:94] Creating Layer inception_4a/relu_5x5
I0810 21:05:20.263432   463 net.cpp:435] inception_4a/relu_5x5 <- inception_4a/5x5
I0810 21:05:20.263442   463 net.cpp:396] inception_4a/relu_5x5 -> inception_4a/5x5 (in-place)
I0810 21:05:20.263453   463 net.cpp:144] Setting up inception_4a/relu_5x5
I0810 21:05:20.263459   463 net.cpp:151] Top shape: 6 48 40 40 (460800)
I0810 21:05:20.263465   463 net.cpp:159] Memory required for data: 1844545248
I0810 21:05:20.263471   463 layer_factory.hpp:77] Creating layer inception_4a/pool
I0810 21:05:20.263483   463 net.cpp:94] Creating Layer inception_4a/pool
I0810 21:05:20.263489   463 net.cpp:435] inception_4a/pool <- pool3/3x3_s2_pool3/3x3_s2_0_split_3
I0810 21:05:20.263499   463 net.cpp:409] inception_4a/pool -> inception_4a/pool
I0810 21:05:20.263553   463 net.cpp:144] Setting up inception_4a/pool
I0810 21:05:20.263563   463 net.cpp:151] Top shape: 6 480 40 40 (4608000)
I0810 21:05:20.263568   463 net.cpp:159] Memory required for data: 1862977248
I0810 21:05:20.263574   463 layer_factory.hpp:77] Creating layer inception_4a/pool_proj
I0810 21:05:20.263587   463 net.cpp:94] Creating Layer inception_4a/pool_proj
I0810 21:05:20.263594   463 net.cpp:435] inception_4a/pool_proj <- inception_4a/pool
I0810 21:05:20.263605   463 net.cpp:409] inception_4a/pool_proj -> inception_4a/pool_proj
I0810 21:05:20.264108   463 net.cpp:144] Setting up inception_4a/pool_proj
I0810 21:05:20.264122   463 net.cpp:151] Top shape: 6 64 40 40 (614400)
I0810 21:05:20.264127   463 net.cpp:159] Memory required for data: 1865434848
I0810 21:05:20.264137   463 layer_factory.hpp:77] Creating layer inception_4a/relu_pool_proj
I0810 21:05:20.264148   463 net.cpp:94] Creating Layer inception_4a/relu_pool_proj
I0810 21:05:20.264155   463 net.cpp:435] inception_4a/relu_pool_proj <- inception_4a/pool_proj
I0810 21:05:20.264164   463 net.cpp:396] inception_4a/relu_pool_proj -> inception_4a/pool_proj (in-place)
I0810 21:05:20.264174   463 net.cpp:144] Setting up inception_4a/relu_pool_proj
I0810 21:05:20.264181   463 net.cpp:151] Top shape: 6 64 40 40 (614400)
I0810 21:05:20.264187   463 net.cpp:159] Memory required for data: 1867892448
I0810 21:05:20.264194   463 layer_factory.hpp:77] Creating layer inception_4a/output
I0810 21:05:20.264204   463 net.cpp:94] Creating Layer inception_4a/output
I0810 21:05:20.264210   463 net.cpp:435] inception_4a/output <- inception_4a/1x1
I0810 21:05:20.264219   463 net.cpp:435] inception_4a/output <- inception_4a/3x3
I0810 21:05:20.264226   463 net.cpp:435] inception_4a/output <- inception_4a/5x5
I0810 21:05:20.264233   463 net.cpp:435] inception_4a/output <- inception_4a/pool_proj
I0810 21:05:20.264242   463 net.cpp:409] inception_4a/output -> inception_4a/output
I0810 21:05:20.264279   463 net.cpp:144] Setting up inception_4a/output
I0810 21:05:20.264288   463 net.cpp:151] Top shape: 6 512 40 40 (4915200)
I0810 21:05:20.264294   463 net.cpp:159] Memory required for data: 1887553248
I0810 21:05:20.264300   463 layer_factory.hpp:77] Creating layer inception_4a/output_inception_4a/output_0_split
I0810 21:05:20.264312   463 net.cpp:94] Creating Layer inception_4a/output_inception_4a/output_0_split
I0810 21:05:20.264325   463 net.cpp:435] inception_4a/output_inception_4a/output_0_split <- inception_4a/output
I0810 21:05:20.264336   463 net.cpp:409] inception_4a/output_inception_4a/output_0_split -> inception_4a/output_inception_4a/output_0_split_0
I0810 21:05:20.264348   463 net.cpp:409] inception_4a/output_inception_4a/output_0_split -> inception_4a/output_inception_4a/output_0_split_1
I0810 21:05:20.264358   463 net.cpp:409] inception_4a/output_inception_4a/output_0_split -> inception_4a/output_inception_4a/output_0_split_2
I0810 21:05:20.264369   463 net.cpp:409] inception_4a/output_inception_4a/output_0_split -> inception_4a/output_inception_4a/output_0_split_3
I0810 21:05:20.264441   463 net.cpp:144] Setting up inception_4a/output_inception_4a/output_0_split
I0810 21:05:20.264451   463 net.cpp:151] Top shape: 6 512 40 40 (4915200)
I0810 21:05:20.264456   463 net.cpp:151] Top shape: 6 512 40 40 (4915200)
I0810 21:05:20.264463   463 net.cpp:151] Top shape: 6 512 40 40 (4915200)
I0810 21:05:20.264470   463 net.cpp:151] Top shape: 6 512 40 40 (4915200)
I0810 21:05:20.264475   463 net.cpp:159] Memory required for data: 1966196448
I0810 21:05:20.264482   463 layer_factory.hpp:77] Creating layer inception_4b/1x1
I0810 21:05:20.264493   463 net.cpp:94] Creating Layer inception_4b/1x1
I0810 21:05:20.264499   463 net.cpp:435] inception_4b/1x1 <- inception_4a/output_inception_4a/output_0_split_0
I0810 21:05:20.264511   463 net.cpp:409] inception_4b/1x1 -> inception_4b/1x1
I0810 21:05:20.265283   463 net.cpp:144] Setting up inception_4b/1x1
I0810 21:05:20.265297   463 net.cpp:151] Top shape: 6 160 40 40 (1536000)
I0810 21:05:20.265303   463 net.cpp:159] Memory required for data: 1972340448
I0810 21:05:20.265312   463 layer_factory.hpp:77] Creating layer inception_4b/relu_1x1
I0810 21:05:20.265329   463 net.cpp:94] Creating Layer inception_4b/relu_1x1
I0810 21:05:20.265337   463 net.cpp:435] inception_4b/relu_1x1 <- inception_4b/1x1
I0810 21:05:20.265347   463 net.cpp:396] inception_4b/relu_1x1 -> inception_4b/1x1 (in-place)
I0810 21:05:20.265357   463 net.cpp:144] Setting up inception_4b/relu_1x1
I0810 21:05:20.265365   463 net.cpp:151] Top shape: 6 160 40 40 (1536000)
I0810 21:05:20.265385   463 net.cpp:159] Memory required for data: 1978484448
I0810 21:05:20.265393   463 layer_factory.hpp:77] Creating layer inception_4b/3x3_reduce
I0810 21:05:20.265405   463 net.cpp:94] Creating Layer inception_4b/3x3_reduce
I0810 21:05:20.265413   463 net.cpp:435] inception_4b/3x3_reduce <- inception_4a/output_inception_4a/output_0_split_1
I0810 21:05:20.265424   463 net.cpp:409] inception_4b/3x3_reduce -> inception_4b/3x3_reduce
I0810 21:05:20.266930   463 net.cpp:144] Setting up inception_4b/3x3_reduce
I0810 21:05:20.266948   463 net.cpp:151] Top shape: 6 112 40 40 (1075200)
I0810 21:05:20.266954   463 net.cpp:159] Memory required for data: 1982785248
I0810 21:05:20.266964   463 layer_factory.hpp:77] Creating layer inception_4b/relu_3x3_reduce
I0810 21:05:20.266975   463 net.cpp:94] Creating Layer inception_4b/relu_3x3_reduce
I0810 21:05:20.266983   463 net.cpp:435] inception_4b/relu_3x3_reduce <- inception_4b/3x3_reduce
I0810 21:05:20.266993   463 net.cpp:396] inception_4b/relu_3x3_reduce -> inception_4b/3x3_reduce (in-place)
I0810 21:05:20.267004   463 net.cpp:144] Setting up inception_4b/relu_3x3_reduce
I0810 21:05:20.267012   463 net.cpp:151] Top shape: 6 112 40 40 (1075200)
I0810 21:05:20.267019   463 net.cpp:159] Memory required for data: 1987086048
I0810 21:05:20.267024   463 layer_factory.hpp:77] Creating layer inception_4b/3x3
I0810 21:05:20.267035   463 net.cpp:94] Creating Layer inception_4b/3x3
I0810 21:05:20.267042   463 net.cpp:435] inception_4b/3x3 <- inception_4b/3x3_reduce
I0810 21:05:20.267053   463 net.cpp:409] inception_4b/3x3 -> inception_4b/3x3
I0810 21:05:20.269335   463 net.cpp:144] Setting up inception_4b/3x3
I0810 21:05:20.269353   463 net.cpp:151] Top shape: 6 224 40 40 (2150400)
I0810 21:05:20.269361   463 net.cpp:159] Memory required for data: 1995687648
I0810 21:05:20.269371   463 layer_factory.hpp:77] Creating layer inception_4b/relu_3x3
I0810 21:05:20.269381   463 net.cpp:94] Creating Layer inception_4b/relu_3x3
I0810 21:05:20.269388   463 net.cpp:435] inception_4b/relu_3x3 <- inception_4b/3x3
I0810 21:05:20.269399   463 net.cpp:396] inception_4b/relu_3x3 -> inception_4b/3x3 (in-place)
I0810 21:05:20.269412   463 net.cpp:144] Setting up inception_4b/relu_3x3
I0810 21:05:20.269418   463 net.cpp:151] Top shape: 6 224 40 40 (2150400)
I0810 21:05:20.269424   463 net.cpp:159] Memory required for data: 2004289248
I0810 21:05:20.269430   463 layer_factory.hpp:77] Creating layer inception_4b/5x5_reduce
I0810 21:05:20.269443   463 net.cpp:94] Creating Layer inception_4b/5x5_reduce
I0810 21:05:20.269449   463 net.cpp:435] inception_4b/5x5_reduce <- inception_4a/output_inception_4a/output_0_split_2
I0810 21:05:20.269460   463 net.cpp:409] inception_4b/5x5_reduce -> inception_4b/5x5_reduce
I0810 21:05:20.269822   463 net.cpp:144] Setting up inception_4b/5x5_reduce
I0810 21:05:20.269834   463 net.cpp:151] Top shape: 6 24 40 40 (230400)
I0810 21:05:20.269840   463 net.cpp:159] Memory required for data: 2005210848
I0810 21:05:20.269850   463 layer_factory.hpp:77] Creating layer inception_4b/relu_5x5_reduce
I0810 21:05:20.269860   463 net.cpp:94] Creating Layer inception_4b/relu_5x5_reduce
I0810 21:05:20.269866   463 net.cpp:435] inception_4b/relu_5x5_reduce <- inception_4b/5x5_reduce
I0810 21:05:20.269876   463 net.cpp:396] inception_4b/relu_5x5_reduce -> inception_4b/5x5_reduce (in-place)
I0810 21:05:20.269886   463 net.cpp:144] Setting up inception_4b/relu_5x5_reduce
I0810 21:05:20.269892   463 net.cpp:151] Top shape: 6 24 40 40 (230400)
I0810 21:05:20.269898   463 net.cpp:159] Memory required for data: 2006132448
I0810 21:05:20.269904   463 layer_factory.hpp:77] Creating layer inception_4b/5x5
I0810 21:05:20.269917   463 net.cpp:94] Creating Layer inception_4b/5x5
I0810 21:05:20.269923   463 net.cpp:435] inception_4b/5x5 <- inception_4b/5x5_reduce
I0810 21:05:20.269934   463 net.cpp:409] inception_4b/5x5 -> inception_4b/5x5
I0810 21:05:20.270427   463 net.cpp:144] Setting up inception_4b/5x5
I0810 21:05:20.270439   463 net.cpp:151] Top shape: 6 64 40 40 (614400)
I0810 21:05:20.270462   463 net.cpp:159] Memory required for data: 2008590048
I0810 21:05:20.270472   463 layer_factory.hpp:77] Creating layer inception_4b/relu_5x5
I0810 21:05:20.270481   463 net.cpp:94] Creating Layer inception_4b/relu_5x5
I0810 21:05:20.270488   463 net.cpp:435] inception_4b/relu_5x5 <- inception_4b/5x5
I0810 21:05:20.270498   463 net.cpp:396] inception_4b/relu_5x5 -> inception_4b/5x5 (in-place)
I0810 21:05:20.270509   463 net.cpp:144] Setting up inception_4b/relu_5x5
I0810 21:05:20.270517   463 net.cpp:151] Top shape: 6 64 40 40 (614400)
I0810 21:05:20.270522   463 net.cpp:159] Memory required for data: 2011047648
I0810 21:05:20.270529   463 layer_factory.hpp:77] Creating layer inception_4b/pool
I0810 21:05:20.270539   463 net.cpp:94] Creating Layer inception_4b/pool
I0810 21:05:20.270545   463 net.cpp:435] inception_4b/pool <- inception_4a/output_inception_4a/output_0_split_3
I0810 21:05:20.270555   463 net.cpp:409] inception_4b/pool -> inception_4b/pool
I0810 21:05:20.270611   463 net.cpp:144] Setting up inception_4b/pool
I0810 21:05:20.270620   463 net.cpp:151] Top shape: 6 512 40 40 (4915200)
I0810 21:05:20.270625   463 net.cpp:159] Memory required for data: 2030708448
I0810 21:05:20.270632   463 layer_factory.hpp:77] Creating layer inception_4b/pool_proj
I0810 21:05:20.270644   463 net.cpp:94] Creating Layer inception_4b/pool_proj
I0810 21:05:20.270651   463 net.cpp:435] inception_4b/pool_proj <- inception_4b/pool
I0810 21:05:20.270661   463 net.cpp:409] inception_4b/pool_proj -> inception_4b/pool_proj
I0810 21:05:20.271109   463 net.cpp:144] Setting up inception_4b/pool_proj
I0810 21:05:20.271121   463 net.cpp:151] Top shape: 6 64 40 40 (614400)
I0810 21:05:20.271127   463 net.cpp:159] Memory required for data: 2033166048
I0810 21:05:20.271136   463 layer_factory.hpp:77] Creating layer inception_4b/relu_pool_proj
I0810 21:05:20.271147   463 net.cpp:94] Creating Layer inception_4b/relu_pool_proj
I0810 21:05:20.271153   463 net.cpp:435] inception_4b/relu_pool_proj <- inception_4b/pool_proj
I0810 21:05:20.271162   463 net.cpp:396] inception_4b/relu_pool_proj -> inception_4b/pool_proj (in-place)
I0810 21:05:20.271173   463 net.cpp:144] Setting up inception_4b/relu_pool_proj
I0810 21:05:20.271180   463 net.cpp:151] Top shape: 6 64 40 40 (614400)
I0810 21:05:20.271185   463 net.cpp:159] Memory required for data: 2035623648
I0810 21:05:20.271191   463 layer_factory.hpp:77] Creating layer inception_4b/output
I0810 21:05:20.271201   463 net.cpp:94] Creating Layer inception_4b/output
I0810 21:05:20.271209   463 net.cpp:435] inception_4b/output <- inception_4b/1x1
I0810 21:05:20.271215   463 net.cpp:435] inception_4b/output <- inception_4b/3x3
I0810 21:05:20.271222   463 net.cpp:435] inception_4b/output <- inception_4b/5x5
I0810 21:05:20.271230   463 net.cpp:435] inception_4b/output <- inception_4b/pool_proj
I0810 21:05:20.271239   463 net.cpp:409] inception_4b/output -> inception_4b/output
I0810 21:05:20.271275   463 net.cpp:144] Setting up inception_4b/output
I0810 21:05:20.271286   463 net.cpp:151] Top shape: 6 512 40 40 (4915200)
I0810 21:05:20.271291   463 net.cpp:159] Memory required for data: 2055284448
I0810 21:05:20.271296   463 layer_factory.hpp:77] Creating layer inception_4b/output_inception_4b/output_0_split
I0810 21:05:20.271307   463 net.cpp:94] Creating Layer inception_4b/output_inception_4b/output_0_split
I0810 21:05:20.271314   463 net.cpp:435] inception_4b/output_inception_4b/output_0_split <- inception_4b/output
I0810 21:05:20.271333   463 net.cpp:409] inception_4b/output_inception_4b/output_0_split -> inception_4b/output_inception_4b/output_0_split_0
I0810 21:05:20.271345   463 net.cpp:409] inception_4b/output_inception_4b/output_0_split -> inception_4b/output_inception_4b/output_0_split_1
I0810 21:05:20.271356   463 net.cpp:409] inception_4b/output_inception_4b/output_0_split -> inception_4b/output_inception_4b/output_0_split_2
I0810 21:05:20.271366   463 net.cpp:409] inception_4b/output_inception_4b/output_0_split -> inception_4b/output_inception_4b/output_0_split_3
I0810 21:05:20.271456   463 net.cpp:144] Setting up inception_4b/output_inception_4b/output_0_split
I0810 21:05:20.271466   463 net.cpp:151] Top shape: 6 512 40 40 (4915200)
I0810 21:05:20.271473   463 net.cpp:151] Top shape: 6 512 40 40 (4915200)
I0810 21:05:20.271481   463 net.cpp:151] Top shape: 6 512 40 40 (4915200)
I0810 21:05:20.271488   463 net.cpp:151] Top shape: 6 512 40 40 (4915200)
I0810 21:05:20.271493   463 net.cpp:159] Memory required for data: 2133927648
I0810 21:05:20.271500   463 layer_factory.hpp:77] Creating layer inception_4c/1x1
I0810 21:05:20.271512   463 net.cpp:94] Creating Layer inception_4c/1x1
I0810 21:05:20.271519   463 net.cpp:435] inception_4c/1x1 <- inception_4b/output_inception_4b/output_0_split_0
I0810 21:05:20.271530   463 net.cpp:409] inception_4c/1x1 -> inception_4c/1x1
I0810 21:05:20.272155   463 net.cpp:144] Setting up inception_4c/1x1
I0810 21:05:20.272166   463 net.cpp:151] Top shape: 6 128 40 40 (1228800)
I0810 21:05:20.272172   463 net.cpp:159] Memory required for data: 2138842848
I0810 21:05:20.272181   463 layer_factory.hpp:77] Creating layer inception_4c/relu_1x1
I0810 21:05:20.272192   463 net.cpp:94] Creating Layer inception_4c/relu_1x1
I0810 21:05:20.272198   463 net.cpp:435] inception_4c/relu_1x1 <- inception_4c/1x1
I0810 21:05:20.272208   463 net.cpp:396] inception_4c/relu_1x1 -> inception_4c/1x1 (in-place)
I0810 21:05:20.272217   463 net.cpp:144] Setting up inception_4c/relu_1x1
I0810 21:05:20.272225   463 net.cpp:151] Top shape: 6 128 40 40 (1228800)
I0810 21:05:20.272230   463 net.cpp:159] Memory required for data: 2143758048
I0810 21:05:20.272236   463 layer_factory.hpp:77] Creating layer inception_4c/3x3_reduce
I0810 21:05:20.272248   463 net.cpp:94] Creating Layer inception_4c/3x3_reduce
I0810 21:05:20.272255   463 net.cpp:435] inception_4c/3x3_reduce <- inception_4b/output_inception_4b/output_0_split_1
I0810 21:05:20.272266   463 net.cpp:409] inception_4c/3x3_reduce -> inception_4c/3x3_reduce
I0810 21:05:20.292088   463 net.cpp:144] Setting up inception_4c/3x3_reduce
I0810 21:05:20.292132   463 net.cpp:151] Top shape: 6 128 40 40 (1228800)
I0810 21:05:20.292140   463 net.cpp:159] Memory required for data: 2148673248
I0810 21:05:20.292156   463 layer_factory.hpp:77] Creating layer inception_4c/relu_3x3_reduce
I0810 21:05:20.292174   463 net.cpp:94] Creating Layer inception_4c/relu_3x3_reduce
I0810 21:05:20.292199   463 net.cpp:435] inception_4c/relu_3x3_reduce <- inception_4c/3x3_reduce
I0810 21:05:20.292214   463 net.cpp:396] inception_4c/relu_3x3_reduce -> inception_4c/3x3_reduce (in-place)
I0810 21:05:20.292234   463 net.cpp:144] Setting up inception_4c/relu_3x3_reduce
I0810 21:05:20.292243   463 net.cpp:151] Top shape: 6 128 40 40 (1228800)
I0810 21:05:20.292248   463 net.cpp:159] Memory required for data: 2153588448
I0810 21:05:20.292254   463 layer_factory.hpp:77] Creating layer inception_4c/3x3
I0810 21:05:20.292271   463 net.cpp:94] Creating Layer inception_4c/3x3
I0810 21:05:20.292279   463 net.cpp:435] inception_4c/3x3 <- inception_4c/3x3_reduce
I0810 21:05:20.292289   463 net.cpp:409] inception_4c/3x3 -> inception_4c/3x3
I0810 21:05:20.295351   463 net.cpp:144] Setting up inception_4c/3x3
I0810 21:05:20.295369   463 net.cpp:151] Top shape: 6 256 40 40 (2457600)
I0810 21:05:20.295377   463 net.cpp:159] Memory required for data: 2163418848
I0810 21:05:20.295387   463 layer_factory.hpp:77] Creating layer inception_4c/relu_3x3
I0810 21:05:20.295397   463 net.cpp:94] Creating Layer inception_4c/relu_3x3
I0810 21:05:20.295404   463 net.cpp:435] inception_4c/relu_3x3 <- inception_4c/3x3
I0810 21:05:20.295415   463 net.cpp:396] inception_4c/relu_3x3 -> inception_4c/3x3 (in-place)
I0810 21:05:20.295428   463 net.cpp:144] Setting up inception_4c/relu_3x3
I0810 21:05:20.295435   463 net.cpp:151] Top shape: 6 256 40 40 (2457600)
I0810 21:05:20.295441   463 net.cpp:159] Memory required for data: 2173249248
I0810 21:05:20.295447   463 layer_factory.hpp:77] Creating layer inception_4c/5x5_reduce
I0810 21:05:20.295459   463 net.cpp:94] Creating Layer inception_4c/5x5_reduce
I0810 21:05:20.295497   463 net.cpp:435] inception_4c/5x5_reduce <- inception_4b/output_inception_4b/output_0_split_2
I0810 21:05:20.295509   463 net.cpp:409] inception_4c/5x5_reduce -> inception_4c/5x5_reduce
I0810 21:05:20.296044   463 net.cpp:144] Setting up inception_4c/5x5_reduce
I0810 21:05:20.296063   463 net.cpp:151] Top shape: 6 24 40 40 (230400)
I0810 21:05:20.296070   463 net.cpp:159] Memory required for data: 2174170848
I0810 21:05:20.296080   463 layer_factory.hpp:77] Creating layer inception_4c/relu_5x5_reduce
I0810 21:05:20.296092   463 net.cpp:94] Creating Layer inception_4c/relu_5x5_reduce
I0810 21:05:20.296100   463 net.cpp:435] inception_4c/relu_5x5_reduce <- inception_4c/5x5_reduce
I0810 21:05:20.296110   463 net.cpp:396] inception_4c/relu_5x5_reduce -> inception_4c/5x5_reduce (in-place)
I0810 21:05:20.296123   463 net.cpp:144] Setting up inception_4c/relu_5x5_reduce
I0810 21:05:20.296131   463 net.cpp:151] Top shape: 6 24 40 40 (230400)
I0810 21:05:20.296136   463 net.cpp:159] Memory required for data: 2175092448
I0810 21:05:20.296142   463 layer_factory.hpp:77] Creating layer inception_4c/5x5
I0810 21:05:20.296156   463 net.cpp:94] Creating Layer inception_4c/5x5
I0810 21:05:20.296178   463 net.cpp:435] inception_4c/5x5 <- inception_4c/5x5_reduce
I0810 21:05:20.296190   463 net.cpp:409] inception_4c/5x5 -> inception_4c/5x5
I0810 21:05:20.297744   463 net.cpp:144] Setting up inception_4c/5x5
I0810 21:05:20.297762   463 net.cpp:151] Top shape: 6 64 40 40 (614400)
I0810 21:05:20.297770   463 net.cpp:159] Memory required for data: 2177550048
I0810 21:05:20.297780   463 layer_factory.hpp:77] Creating layer inception_4c/relu_5x5
I0810 21:05:20.297791   463 net.cpp:94] Creating Layer inception_4c/relu_5x5
I0810 21:05:20.297797   463 net.cpp:435] inception_4c/relu_5x5 <- inception_4c/5x5
I0810 21:05:20.297808   463 net.cpp:396] inception_4c/relu_5x5 -> inception_4c/5x5 (in-place)
I0810 21:05:20.297821   463 net.cpp:144] Setting up inception_4c/relu_5x5
I0810 21:05:20.297828   463 net.cpp:151] Top shape: 6 64 40 40 (614400)
I0810 21:05:20.297834   463 net.cpp:159] Memory required for data: 2180007648
I0810 21:05:20.297840   463 layer_factory.hpp:77] Creating layer inception_4c/pool
I0810 21:05:20.297850   463 net.cpp:94] Creating Layer inception_4c/pool
I0810 21:05:20.297857   463 net.cpp:435] inception_4c/pool <- inception_4b/output_inception_4b/output_0_split_3
I0810 21:05:20.297868   463 net.cpp:409] inception_4c/pool -> inception_4c/pool
I0810 21:05:20.297927   463 net.cpp:144] Setting up inception_4c/pool
I0810 21:05:20.297937   463 net.cpp:151] Top shape: 6 512 40 40 (4915200)
I0810 21:05:20.297943   463 net.cpp:159] Memory required for data: 2199668448
I0810 21:05:20.297950   463 layer_factory.hpp:77] Creating layer inception_4c/pool_proj
I0810 21:05:20.297961   463 net.cpp:94] Creating Layer inception_4c/pool_proj
I0810 21:05:20.297968   463 net.cpp:435] inception_4c/pool_proj <- inception_4c/pool
I0810 21:05:20.297979   463 net.cpp:409] inception_4c/pool_proj -> inception_4c/pool_proj
I0810 21:05:20.298434   463 net.cpp:144] Setting up inception_4c/pool_proj
I0810 21:05:20.298446   463 net.cpp:151] Top shape: 6 64 40 40 (614400)
I0810 21:05:20.298452   463 net.cpp:159] Memory required for data: 2202126048
I0810 21:05:20.298477   463 layer_factory.hpp:77] Creating layer inception_4c/relu_pool_proj
I0810 21:05:20.298487   463 net.cpp:94] Creating Layer inception_4c/relu_pool_proj
I0810 21:05:20.298494   463 net.cpp:435] inception_4c/relu_pool_proj <- inception_4c/pool_proj
I0810 21:05:20.298503   463 net.cpp:396] inception_4c/relu_pool_proj -> inception_4c/pool_proj (in-place)
I0810 21:05:20.298516   463 net.cpp:144] Setting up inception_4c/relu_pool_proj
I0810 21:05:20.298522   463 net.cpp:151] Top shape: 6 64 40 40 (614400)
I0810 21:05:20.298528   463 net.cpp:159] Memory required for data: 2204583648
I0810 21:05:20.298534   463 layer_factory.hpp:77] Creating layer inception_4c/output
I0810 21:05:20.298544   463 net.cpp:94] Creating Layer inception_4c/output
I0810 21:05:20.298552   463 net.cpp:435] inception_4c/output <- inception_4c/1x1
I0810 21:05:20.298575   463 net.cpp:435] inception_4c/output <- inception_4c/3x3
I0810 21:05:20.298584   463 net.cpp:435] inception_4c/output <- inception_4c/5x5
I0810 21:05:20.298591   463 net.cpp:435] inception_4c/output <- inception_4c/pool_proj
I0810 21:05:20.298600   463 net.cpp:409] inception_4c/output -> inception_4c/output
I0810 21:05:20.298643   463 net.cpp:144] Setting up inception_4c/output
I0810 21:05:20.298653   463 net.cpp:151] Top shape: 6 512 40 40 (4915200)
I0810 21:05:20.298660   463 net.cpp:159] Memory required for data: 2224244448
I0810 21:05:20.298665   463 layer_factory.hpp:77] Creating layer inception_4c/output_inception_4c/output_0_split
I0810 21:05:20.298676   463 net.cpp:94] Creating Layer inception_4c/output_inception_4c/output_0_split
I0810 21:05:20.298683   463 net.cpp:435] inception_4c/output_inception_4c/output_0_split <- inception_4c/output
I0810 21:05:20.298693   463 net.cpp:409] inception_4c/output_inception_4c/output_0_split -> inception_4c/output_inception_4c/output_0_split_0
I0810 21:05:20.298704   463 net.cpp:409] inception_4c/output_inception_4c/output_0_split -> inception_4c/output_inception_4c/output_0_split_1
I0810 21:05:20.298715   463 net.cpp:409] inception_4c/output_inception_4c/output_0_split -> inception_4c/output_inception_4c/output_0_split_2
I0810 21:05:20.298725   463 net.cpp:409] inception_4c/output_inception_4c/output_0_split -> inception_4c/output_inception_4c/output_0_split_3
I0810 21:05:20.298795   463 net.cpp:144] Setting up inception_4c/output_inception_4c/output_0_split
I0810 21:05:20.298805   463 net.cpp:151] Top shape: 6 512 40 40 (4915200)
I0810 21:05:20.298812   463 net.cpp:151] Top shape: 6 512 40 40 (4915200)
I0810 21:05:20.298818   463 net.cpp:151] Top shape: 6 512 40 40 (4915200)
I0810 21:05:20.298825   463 net.cpp:151] Top shape: 6 512 40 40 (4915200)
I0810 21:05:20.298830   463 net.cpp:159] Memory required for data: 2302887648
I0810 21:05:20.298836   463 layer_factory.hpp:77] Creating layer inception_4d/1x1
I0810 21:05:20.298848   463 net.cpp:94] Creating Layer inception_4d/1x1
I0810 21:05:20.298856   463 net.cpp:435] inception_4d/1x1 <- inception_4c/output_inception_4c/output_0_split_0
I0810 21:05:20.298866   463 net.cpp:409] inception_4d/1x1 -> inception_4d/1x1
I0810 21:05:20.299445   463 net.cpp:144] Setting up inception_4d/1x1
I0810 21:05:20.299458   463 net.cpp:151] Top shape: 6 112 40 40 (1075200)
I0810 21:05:20.299463   463 net.cpp:159] Memory required for data: 2307188448
I0810 21:05:20.299473   463 layer_factory.hpp:77] Creating layer inception_4d/relu_1x1
I0810 21:05:20.299482   463 net.cpp:94] Creating Layer inception_4d/relu_1x1
I0810 21:05:20.299489   463 net.cpp:435] inception_4d/relu_1x1 <- inception_4d/1x1
I0810 21:05:20.299499   463 net.cpp:396] inception_4d/relu_1x1 -> inception_4d/1x1 (in-place)
I0810 21:05:20.299509   463 net.cpp:144] Setting up inception_4d/relu_1x1
I0810 21:05:20.299515   463 net.cpp:151] Top shape: 6 112 40 40 (1075200)
I0810 21:05:20.299521   463 net.cpp:159] Memory required for data: 2311489248
I0810 21:05:20.299527   463 layer_factory.hpp:77] Creating layer inception_4d/3x3_reduce
I0810 21:05:20.299540   463 net.cpp:94] Creating Layer inception_4d/3x3_reduce
I0810 21:05:20.299546   463 net.cpp:435] inception_4d/3x3_reduce <- inception_4c/output_inception_4c/output_0_split_1
I0810 21:05:20.299556   463 net.cpp:409] inception_4d/3x3_reduce -> inception_4d/3x3_reduce
I0810 21:05:20.300276   463 net.cpp:144] Setting up inception_4d/3x3_reduce
I0810 21:05:20.300288   463 net.cpp:151] Top shape: 6 144 40 40 (1382400)
I0810 21:05:20.300294   463 net.cpp:159] Memory required for data: 2317018848
I0810 21:05:20.300303   463 layer_factory.hpp:77] Creating layer inception_4d/relu_3x3_reduce
I0810 21:05:20.300313   463 net.cpp:94] Creating Layer inception_4d/relu_3x3_reduce
I0810 21:05:20.300320   463 net.cpp:435] inception_4d/relu_3x3_reduce <- inception_4d/3x3_reduce
I0810 21:05:20.300329   463 net.cpp:396] inception_4d/relu_3x3_reduce -> inception_4d/3x3_reduce (in-place)
I0810 21:05:20.300354   463 net.cpp:144] Setting up inception_4d/relu_3x3_reduce
I0810 21:05:20.300362   463 net.cpp:151] Top shape: 6 144 40 40 (1382400)
I0810 21:05:20.300369   463 net.cpp:159] Memory required for data: 2322548448
I0810 21:05:20.300376   463 layer_factory.hpp:77] Creating layer inception_4d/3x3
I0810 21:05:20.300390   463 net.cpp:94] Creating Layer inception_4d/3x3
I0810 21:05:20.300396   463 net.cpp:435] inception_4d/3x3 <- inception_4d/3x3_reduce
I0810 21:05:20.300406   463 net.cpp:409] inception_4d/3x3 -> inception_4d/3x3
I0810 21:05:20.316694   463 net.cpp:144] Setting up inception_4d/3x3
I0810 21:05:20.316731   463 net.cpp:151] Top shape: 6 288 40 40 (2764800)
I0810 21:05:20.316738   463 net.cpp:159] Memory required for data: 2333607648
I0810 21:05:20.316752   463 layer_factory.hpp:77] Creating layer inception_4d/relu_3x3
I0810 21:05:20.316766   463 net.cpp:94] Creating Layer inception_4d/relu_3x3
I0810 21:05:20.316776   463 net.cpp:435] inception_4d/relu_3x3 <- inception_4d/3x3
I0810 21:05:20.316788   463 net.cpp:396] inception_4d/relu_3x3 -> inception_4d/3x3 (in-place)
I0810 21:05:20.316803   463 net.cpp:144] Setting up inception_4d/relu_3x3
I0810 21:05:20.316812   463 net.cpp:151] Top shape: 6 288 40 40 (2764800)
I0810 21:05:20.316817   463 net.cpp:159] Memory required for data: 2344666848
I0810 21:05:20.316823   463 layer_factory.hpp:77] Creating layer inception_4d/5x5_reduce
I0810 21:05:20.316836   463 net.cpp:94] Creating Layer inception_4d/5x5_reduce
I0810 21:05:20.316844   463 net.cpp:435] inception_4d/5x5_reduce <- inception_4c/output_inception_4c/output_0_split_2
I0810 21:05:20.316854   463 net.cpp:409] inception_4d/5x5_reduce -> inception_4d/5x5_reduce
I0810 21:05:20.317311   463 net.cpp:144] Setting up inception_4d/5x5_reduce
I0810 21:05:20.317325   463 net.cpp:151] Top shape: 6 32 40 40 (307200)
I0810 21:05:20.317332   463 net.cpp:159] Memory required for data: 2345895648
I0810 21:05:20.317342   463 layer_factory.hpp:77] Creating layer inception_4d/relu_5x5_reduce
I0810 21:05:20.317351   463 net.cpp:94] Creating Layer inception_4d/relu_5x5_reduce
I0810 21:05:20.317358   463 net.cpp:435] inception_4d/relu_5x5_reduce <- inception_4d/5x5_reduce
I0810 21:05:20.317368   463 net.cpp:396] inception_4d/relu_5x5_reduce -> inception_4d/5x5_reduce (in-place)
I0810 21:05:20.317379   463 net.cpp:144] Setting up inception_4d/relu_5x5_reduce
I0810 21:05:20.317387   463 net.cpp:151] Top shape: 6 32 40 40 (307200)
I0810 21:05:20.317394   463 net.cpp:159] Memory required for data: 2347124448
I0810 21:05:20.317399   463 layer_factory.hpp:77] Creating layer inception_4d/5x5
I0810 21:05:20.317411   463 net.cpp:94] Creating Layer inception_4d/5x5
I0810 21:05:20.317418   463 net.cpp:435] inception_4d/5x5 <- inception_4d/5x5_reduce
I0810 21:05:20.317430   463 net.cpp:409] inception_4d/5x5 -> inception_4d/5x5
I0810 21:05:20.318017   463 net.cpp:144] Setting up inception_4d/5x5
I0810 21:05:20.318028   463 net.cpp:151] Top shape: 6 64 40 40 (614400)
I0810 21:05:20.318034   463 net.cpp:159] Memory required for data: 2349582048
I0810 21:05:20.318043   463 layer_factory.hpp:77] Creating layer inception_4d/relu_5x5
I0810 21:05:20.318053   463 net.cpp:94] Creating Layer inception_4d/relu_5x5
I0810 21:05:20.318060   463 net.cpp:435] inception_4d/relu_5x5 <- inception_4d/5x5
I0810 21:05:20.318069   463 net.cpp:396] inception_4d/relu_5x5 -> inception_4d/5x5 (in-place)
I0810 21:05:20.318078   463 net.cpp:144] Setting up inception_4d/relu_5x5
I0810 21:05:20.318086   463 net.cpp:151] Top shape: 6 64 40 40 (614400)
I0810 21:05:20.318092   463 net.cpp:159] Memory required for data: 2352039648
I0810 21:05:20.318099   463 layer_factory.hpp:77] Creating layer inception_4d/pool
I0810 21:05:20.318109   463 net.cpp:94] Creating Layer inception_4d/pool
I0810 21:05:20.318115   463 net.cpp:435] inception_4d/pool <- inception_4c/output_inception_4c/output_0_split_3
I0810 21:05:20.318125   463 net.cpp:409] inception_4d/pool -> inception_4d/pool
I0810 21:05:20.318192   463 net.cpp:144] Setting up inception_4d/pool
I0810 21:05:20.318202   463 net.cpp:151] Top shape: 6 512 40 40 (4915200)
I0810 21:05:20.318244   463 net.cpp:159] Memory required for data: 2371700448
I0810 21:05:20.318251   463 layer_factory.hpp:77] Creating layer inception_4d/pool_proj
I0810 21:05:20.318264   463 net.cpp:94] Creating Layer inception_4d/pool_proj
I0810 21:05:20.318271   463 net.cpp:435] inception_4d/pool_proj <- inception_4d/pool
I0810 21:05:20.318282   463 net.cpp:409] inception_4d/pool_proj -> inception_4d/pool_proj
I0810 21:05:20.318756   463 net.cpp:144] Setting up inception_4d/pool_proj
I0810 21:05:20.318768   463 net.cpp:151] Top shape: 6 64 40 40 (614400)
I0810 21:05:20.318773   463 net.cpp:159] Memory required for data: 2374158048
I0810 21:05:20.318783   463 layer_factory.hpp:77] Creating layer inception_4d/relu_pool_proj
I0810 21:05:20.318792   463 net.cpp:94] Creating Layer inception_4d/relu_pool_proj
I0810 21:05:20.318799   463 net.cpp:435] inception_4d/relu_pool_proj <- inception_4d/pool_proj
I0810 21:05:20.318809   463 net.cpp:396] inception_4d/relu_pool_proj -> inception_4d/pool_proj (in-place)
I0810 21:05:20.318819   463 net.cpp:144] Setting up inception_4d/relu_pool_proj
I0810 21:05:20.318826   463 net.cpp:151] Top shape: 6 64 40 40 (614400)
I0810 21:05:20.318832   463 net.cpp:159] Memory required for data: 2376615648
I0810 21:05:20.318837   463 layer_factory.hpp:77] Creating layer inception_4d/output
I0810 21:05:20.318847   463 net.cpp:94] Creating Layer inception_4d/output
I0810 21:05:20.318855   463 net.cpp:435] inception_4d/output <- inception_4d/1x1
I0810 21:05:20.318861   463 net.cpp:435] inception_4d/output <- inception_4d/3x3
I0810 21:05:20.318869   463 net.cpp:435] inception_4d/output <- inception_4d/5x5
I0810 21:05:20.318876   463 net.cpp:435] inception_4d/output <- inception_4d/pool_proj
I0810 21:05:20.318886   463 net.cpp:409] inception_4d/output -> inception_4d/output
I0810 21:05:20.318922   463 net.cpp:144] Setting up inception_4d/output
I0810 21:05:20.318933   463 net.cpp:151] Top shape: 6 528 40 40 (5068800)
I0810 21:05:20.318938   463 net.cpp:159] Memory required for data: 2396890848
I0810 21:05:20.318943   463 layer_factory.hpp:77] Creating layer inception_4d/output_inception_4d/output_0_split
I0810 21:05:20.318954   463 net.cpp:94] Creating Layer inception_4d/output_inception_4d/output_0_split
I0810 21:05:20.318961   463 net.cpp:435] inception_4d/output_inception_4d/output_0_split <- inception_4d/output
I0810 21:05:20.318970   463 net.cpp:409] inception_4d/output_inception_4d/output_0_split -> inception_4d/output_inception_4d/output_0_split_0
I0810 21:05:20.318981   463 net.cpp:409] inception_4d/output_inception_4d/output_0_split -> inception_4d/output_inception_4d/output_0_split_1
I0810 21:05:20.318991   463 net.cpp:409] inception_4d/output_inception_4d/output_0_split -> inception_4d/output_inception_4d/output_0_split_2
I0810 21:05:20.319002   463 net.cpp:409] inception_4d/output_inception_4d/output_0_split -> inception_4d/output_inception_4d/output_0_split_3
I0810 21:05:20.319073   463 net.cpp:144] Setting up inception_4d/output_inception_4d/output_0_split
I0810 21:05:20.319082   463 net.cpp:151] Top shape: 6 528 40 40 (5068800)
I0810 21:05:20.319089   463 net.cpp:151] Top shape: 6 528 40 40 (5068800)
I0810 21:05:20.319097   463 net.cpp:151] Top shape: 6 528 40 40 (5068800)
I0810 21:05:20.319103   463 net.cpp:151] Top shape: 6 528 40 40 (5068800)
I0810 21:05:20.319108   463 net.cpp:159] Memory required for data: 2477991648
I0810 21:05:20.319114   463 layer_factory.hpp:77] Creating layer inception_4e/1x1
I0810 21:05:20.319125   463 net.cpp:94] Creating Layer inception_4e/1x1
I0810 21:05:20.319133   463 net.cpp:435] inception_4e/1x1 <- inception_4d/output_inception_4d/output_0_split_0
I0810 21:05:20.319144   463 net.cpp:409] inception_4e/1x1 -> inception_4e/1x1
I0810 21:05:20.321804   463 net.cpp:144] Setting up inception_4e/1x1
I0810 21:05:20.321822   463 net.cpp:151] Top shape: 6 256 40 40 (2457600)
I0810 21:05:20.321828   463 net.cpp:159] Memory required for data: 2487822048
I0810 21:05:20.321840   463 layer_factory.hpp:77] Creating layer inception_4e/relu_1x1
I0810 21:05:20.321866   463 net.cpp:94] Creating Layer inception_4e/relu_1x1
I0810 21:05:20.321874   463 net.cpp:435] inception_4e/relu_1x1 <- inception_4e/1x1
I0810 21:05:20.321887   463 net.cpp:396] inception_4e/relu_1x1 -> inception_4e/1x1 (in-place)
I0810 21:05:20.321898   463 net.cpp:144] Setting up inception_4e/relu_1x1
I0810 21:05:20.321907   463 net.cpp:151] Top shape: 6 256 40 40 (2457600)
I0810 21:05:20.321913   463 net.cpp:159] Memory required for data: 2497652448
I0810 21:05:20.321918   463 layer_factory.hpp:77] Creating layer inception_4e/3x3_reduce
I0810 21:05:20.321931   463 net.cpp:94] Creating Layer inception_4e/3x3_reduce
I0810 21:05:20.321938   463 net.cpp:435] inception_4e/3x3_reduce <- inception_4d/output_inception_4d/output_0_split_1
I0810 21:05:20.321949   463 net.cpp:409] inception_4e/3x3_reduce -> inception_4e/3x3_reduce
I0810 21:05:20.322692   463 net.cpp:144] Setting up inception_4e/3x3_reduce
I0810 21:05:20.322705   463 net.cpp:151] Top shape: 6 160 40 40 (1536000)
I0810 21:05:20.322710   463 net.cpp:159] Memory required for data: 2503796448
I0810 21:05:20.322719   463 layer_factory.hpp:77] Creating layer inception_4e/relu_3x3_reduce
I0810 21:05:20.322729   463 net.cpp:94] Creating Layer inception_4e/relu_3x3_reduce
I0810 21:05:20.322736   463 net.cpp:435] inception_4e/relu_3x3_reduce <- inception_4e/3x3_reduce
I0810 21:05:20.322746   463 net.cpp:396] inception_4e/relu_3x3_reduce -> inception_4e/3x3_reduce (in-place)
I0810 21:05:20.322757   463 net.cpp:144] Setting up inception_4e/relu_3x3_reduce
I0810 21:05:20.322764   463 net.cpp:151] Top shape: 6 160 40 40 (1536000)
I0810 21:05:20.322769   463 net.cpp:159] Memory required for data: 2509940448
I0810 21:05:20.322775   463 layer_factory.hpp:77] Creating layer inception_4e/3x3
I0810 21:05:20.322788   463 net.cpp:94] Creating Layer inception_4e/3x3
I0810 21:05:20.322794   463 net.cpp:435] inception_4e/3x3 <- inception_4e/3x3_reduce
I0810 21:05:20.322805   463 net.cpp:409] inception_4e/3x3 -> inception_4e/3x3
I0810 21:05:20.347710   463 net.cpp:144] Setting up inception_4e/3x3
I0810 21:05:20.347751   463 net.cpp:151] Top shape: 6 320 40 40 (3072000)
I0810 21:05:20.347759   463 net.cpp:159] Memory required for data: 2522228448
I0810 21:05:20.347774   463 layer_factory.hpp:77] Creating layer inception_4e/relu_3x3
I0810 21:05:20.347789   463 net.cpp:94] Creating Layer inception_4e/relu_3x3
I0810 21:05:20.347798   463 net.cpp:435] inception_4e/relu_3x3 <- inception_4e/3x3
I0810 21:05:20.347811   463 net.cpp:396] inception_4e/relu_3x3 -> inception_4e/3x3 (in-place)
I0810 21:05:20.347829   463 net.cpp:144] Setting up inception_4e/relu_3x3
I0810 21:05:20.347837   463 net.cpp:151] Top shape: 6 320 40 40 (3072000)
I0810 21:05:20.347842   463 net.cpp:159] Memory required for data: 2534516448
I0810 21:05:20.347848   463 layer_factory.hpp:77] Creating layer inception_4e/5x5_reduce
I0810 21:05:20.347863   463 net.cpp:94] Creating Layer inception_4e/5x5_reduce
I0810 21:05:20.347870   463 net.cpp:435] inception_4e/5x5_reduce <- inception_4d/output_inception_4d/output_0_split_2
I0810 21:05:20.347882   463 net.cpp:409] inception_4e/5x5_reduce -> inception_4e/5x5_reduce
I0810 21:05:20.348315   463 net.cpp:144] Setting up inception_4e/5x5_reduce
I0810 21:05:20.348330   463 net.cpp:151] Top shape: 6 32 40 40 (307200)
I0810 21:05:20.348335   463 net.cpp:159] Memory required for data: 2535745248
I0810 21:05:20.348345   463 layer_factory.hpp:77] Creating layer inception_4e/relu_5x5_reduce
I0810 21:05:20.348354   463 net.cpp:94] Creating Layer inception_4e/relu_5x5_reduce
I0810 21:05:20.348362   463 net.cpp:435] inception_4e/relu_5x5_reduce <- inception_4e/5x5_reduce
I0810 21:05:20.348371   463 net.cpp:396] inception_4e/relu_5x5_reduce -> inception_4e/5x5_reduce (in-place)
I0810 21:05:20.348382   463 net.cpp:144] Setting up inception_4e/relu_5x5_reduce
I0810 21:05:20.348389   463 net.cpp:151] Top shape: 6 32 40 40 (307200)
I0810 21:05:20.348395   463 net.cpp:159] Memory required for data: 2536974048
I0810 21:05:20.348402   463 layer_factory.hpp:77] Creating layer inception_4e/5x5
I0810 21:05:20.348450   463 net.cpp:94] Creating Layer inception_4e/5x5
I0810 21:05:20.348459   463 net.cpp:435] inception_4e/5x5 <- inception_4e/5x5_reduce
I0810 21:05:20.348469   463 net.cpp:409] inception_4e/5x5 -> inception_4e/5x5
I0810 21:05:20.353647   463 net.cpp:144] Setting up inception_4e/5x5
I0810 21:05:20.353667   463 net.cpp:151] Top shape: 6 128 40 40 (1228800)
I0810 21:05:20.353674   463 net.cpp:159] Memory required for data: 2541889248
I0810 21:05:20.353684   463 layer_factory.hpp:77] Creating layer inception_4e/relu_5x5
I0810 21:05:20.353695   463 net.cpp:94] Creating Layer inception_4e/relu_5x5
I0810 21:05:20.353703   463 net.cpp:435] inception_4e/relu_5x5 <- inception_4e/5x5
I0810 21:05:20.353713   463 net.cpp:396] inception_4e/relu_5x5 -> inception_4e/5x5 (in-place)
I0810 21:05:20.353725   463 net.cpp:144] Setting up inception_4e/relu_5x5
I0810 21:05:20.353734   463 net.cpp:151] Top shape: 6 128 40 40 (1228800)
I0810 21:05:20.353739   463 net.cpp:159] Memory required for data: 2546804448
I0810 21:05:20.353745   463 layer_factory.hpp:77] Creating layer inception_4e/pool
I0810 21:05:20.353793   463 net.cpp:94] Creating Layer inception_4e/pool
I0810 21:05:20.353801   463 net.cpp:435] inception_4e/pool <- inception_4d/output_inception_4d/output_0_split_3
I0810 21:05:20.353809   463 net.cpp:409] inception_4e/pool -> inception_4e/pool
I0810 21:05:20.353866   463 net.cpp:144] Setting up inception_4e/pool
I0810 21:05:20.353876   463 net.cpp:151] Top shape: 6 528 40 40 (5068800)
I0810 21:05:20.353883   463 net.cpp:159] Memory required for data: 2567079648
I0810 21:05:20.353888   463 layer_factory.hpp:77] Creating layer inception_4e/pool_proj
I0810 21:05:20.353900   463 net.cpp:94] Creating Layer inception_4e/pool_proj
I0810 21:05:20.353907   463 net.cpp:435] inception_4e/pool_proj <- inception_4e/pool
I0810 21:05:20.353919   463 net.cpp:409] inception_4e/pool_proj -> inception_4e/pool_proj
I0810 21:05:20.354568   463 net.cpp:144] Setting up inception_4e/pool_proj
I0810 21:05:20.354583   463 net.cpp:151] Top shape: 6 128 40 40 (1228800)
I0810 21:05:20.354589   463 net.cpp:159] Memory required for data: 2571994848
I0810 21:05:20.354598   463 layer_factory.hpp:77] Creating layer inception_4e/relu_pool_proj
I0810 21:05:20.354607   463 net.cpp:94] Creating Layer inception_4e/relu_pool_proj
I0810 21:05:20.354614   463 net.cpp:435] inception_4e/relu_pool_proj <- inception_4e/pool_proj
I0810 21:05:20.354624   463 net.cpp:396] inception_4e/relu_pool_proj -> inception_4e/pool_proj (in-place)
I0810 21:05:20.354635   463 net.cpp:144] Setting up inception_4e/relu_pool_proj
I0810 21:05:20.354642   463 net.cpp:151] Top shape: 6 128 40 40 (1228800)
I0810 21:05:20.354648   463 net.cpp:159] Memory required for data: 2576910048
I0810 21:05:20.354655   463 layer_factory.hpp:77] Creating layer inception_4e/output
I0810 21:05:20.354665   463 net.cpp:94] Creating Layer inception_4e/output
I0810 21:05:20.354672   463 net.cpp:435] inception_4e/output <- inception_4e/1x1
I0810 21:05:20.354681   463 net.cpp:435] inception_4e/output <- inception_4e/3x3
I0810 21:05:20.354687   463 net.cpp:435] inception_4e/output <- inception_4e/5x5
I0810 21:05:20.354694   463 net.cpp:435] inception_4e/output <- inception_4e/pool_proj
I0810 21:05:20.354703   463 net.cpp:409] inception_4e/output -> inception_4e/output
I0810 21:05:20.354743   463 net.cpp:144] Setting up inception_4e/output
I0810 21:05:20.354753   463 net.cpp:151] Top shape: 6 832 40 40 (7987200)
I0810 21:05:20.354758   463 net.cpp:159] Memory required for data: 2608858848
I0810 21:05:20.354763   463 layer_factory.hpp:77] Creating layer inception_4e/output_inception_4e/output_0_split
I0810 21:05:20.354774   463 net.cpp:94] Creating Layer inception_4e/output_inception_4e/output_0_split
I0810 21:05:20.354780   463 net.cpp:435] inception_4e/output_inception_4e/output_0_split <- inception_4e/output
I0810 21:05:20.354790   463 net.cpp:409] inception_4e/output_inception_4e/output_0_split -> inception_4e/output_inception_4e/output_0_split_0
I0810 21:05:20.354801   463 net.cpp:409] inception_4e/output_inception_4e/output_0_split -> inception_4e/output_inception_4e/output_0_split_1
I0810 21:05:20.354832   463 net.cpp:409] inception_4e/output_inception_4e/output_0_split -> inception_4e/output_inception_4e/output_0_split_2
I0810 21:05:20.354843   463 net.cpp:409] inception_4e/output_inception_4e/output_0_split -> inception_4e/output_inception_4e/output_0_split_3
I0810 21:05:20.354918   463 net.cpp:144] Setting up inception_4e/output_inception_4e/output_0_split
I0810 21:05:20.354928   463 net.cpp:151] Top shape: 6 832 40 40 (7987200)
I0810 21:05:20.354934   463 net.cpp:151] Top shape: 6 832 40 40 (7987200)
I0810 21:05:20.354941   463 net.cpp:151] Top shape: 6 832 40 40 (7987200)
I0810 21:05:20.354948   463 net.cpp:151] Top shape: 6 832 40 40 (7987200)
I0810 21:05:20.354954   463 net.cpp:159] Memory required for data: 2736654048
I0810 21:05:20.354959   463 layer_factory.hpp:77] Creating layer inception_5a/1x1
I0810 21:05:20.354970   463 net.cpp:94] Creating Layer inception_5a/1x1
I0810 21:05:20.354977   463 net.cpp:435] inception_5a/1x1 <- inception_4e/output_inception_4e/output_0_split_0
I0810 21:05:20.354988   463 net.cpp:409] inception_5a/1x1 -> inception_5a/1x1
I0810 21:05:20.370445   463 net.cpp:144] Setting up inception_5a/1x1
I0810 21:05:20.370494   463 net.cpp:151] Top shape: 6 256 40 40 (2457600)
I0810 21:05:20.370510   463 net.cpp:159] Memory required for data: 2746484448
I0810 21:05:20.370523   463 layer_factory.hpp:77] Creating layer inception_5a/relu_1x1
I0810 21:05:20.370537   463 net.cpp:94] Creating Layer inception_5a/relu_1x1
I0810 21:05:20.370548   463 net.cpp:435] inception_5a/relu_1x1 <- inception_5a/1x1
I0810 21:05:20.370558   463 net.cpp:396] inception_5a/relu_1x1 -> inception_5a/1x1 (in-place)
I0810 21:05:20.370573   463 net.cpp:144] Setting up inception_5a/relu_1x1
I0810 21:05:20.370580   463 net.cpp:151] Top shape: 6 256 40 40 (2457600)
I0810 21:05:20.370585   463 net.cpp:159] Memory required for data: 2756314848
I0810 21:05:20.370599   463 layer_factory.hpp:77] Creating layer inception_5a/3x3_reduce
I0810 21:05:20.370625   463 net.cpp:94] Creating Layer inception_5a/3x3_reduce
I0810 21:05:20.370631   463 net.cpp:435] inception_5a/3x3_reduce <- inception_4e/output_inception_4e/output_0_split_1
I0810 21:05:20.370643   463 net.cpp:409] inception_5a/3x3_reduce -> inception_5a/3x3_reduce
I0810 21:05:20.373409   463 net.cpp:144] Setting up inception_5a/3x3_reduce
I0810 21:05:20.373426   463 net.cpp:151] Top shape: 6 160 40 40 (1536000)
I0810 21:05:20.373432   463 net.cpp:159] Memory required for data: 2762458848
I0810 21:05:20.373443   463 layer_factory.hpp:77] Creating layer inception_5a/relu_3x3_reduce
I0810 21:05:20.373453   463 net.cpp:94] Creating Layer inception_5a/relu_3x3_reduce
I0810 21:05:20.373461   463 net.cpp:435] inception_5a/relu_3x3_reduce <- inception_5a/3x3_reduce
I0810 21:05:20.373471   463 net.cpp:396] inception_5a/relu_3x3_reduce -> inception_5a/3x3_reduce (in-place)
I0810 21:05:20.373482   463 net.cpp:144] Setting up inception_5a/relu_3x3_reduce
I0810 21:05:20.373491   463 net.cpp:151] Top shape: 6 160 40 40 (1536000)
I0810 21:05:20.373497   463 net.cpp:159] Memory required for data: 2768602848
I0810 21:05:20.373502   463 layer_factory.hpp:77] Creating layer inception_5a/3x3
I0810 21:05:20.373515   463 net.cpp:94] Creating Layer inception_5a/3x3
I0810 21:05:20.373522   463 net.cpp:435] inception_5a/3x3 <- inception_5a/3x3_reduce
I0810 21:05:20.373533   463 net.cpp:409] inception_5a/3x3 -> inception_5a/3x3
I0810 21:05:20.377594   463 net.cpp:144] Setting up inception_5a/3x3
I0810 21:05:20.377612   463 net.cpp:151] Top shape: 6 320 40 40 (3072000)
I0810 21:05:20.377619   463 net.cpp:159] Memory required for data: 2780890848
I0810 21:05:20.377629   463 layer_factory.hpp:77] Creating layer inception_5a/relu_3x3
I0810 21:05:20.377640   463 net.cpp:94] Creating Layer inception_5a/relu_3x3
I0810 21:05:20.377647   463 net.cpp:435] inception_5a/relu_3x3 <- inception_5a/3x3
I0810 21:05:20.377657   463 net.cpp:396] inception_5a/relu_3x3 -> inception_5a/3x3 (in-place)
I0810 21:05:20.377704   463 net.cpp:144] Setting up inception_5a/relu_3x3
I0810 21:05:20.377713   463 net.cpp:151] Top shape: 6 320 40 40 (3072000)
I0810 21:05:20.377719   463 net.cpp:159] Memory required for data: 2793178848
I0810 21:05:20.377725   463 layer_factory.hpp:77] Creating layer inception_5a/5x5_reduce
I0810 21:05:20.377738   463 net.cpp:94] Creating Layer inception_5a/5x5_reduce
I0810 21:05:20.377746   463 net.cpp:435] inception_5a/5x5_reduce <- inception_4e/output_inception_4e/output_0_split_2
I0810 21:05:20.377758   463 net.cpp:409] inception_5a/5x5_reduce -> inception_5a/5x5_reduce
I0810 21:05:20.378233   463 net.cpp:144] Setting up inception_5a/5x5_reduce
I0810 21:05:20.378245   463 net.cpp:151] Top shape: 6 32 40 40 (307200)
I0810 21:05:20.378252   463 net.cpp:159] Memory required for data: 2794407648
I0810 21:05:20.378260   463 layer_factory.hpp:77] Creating layer inception_5a/relu_5x5_reduce
I0810 21:05:20.378270   463 net.cpp:94] Creating Layer inception_5a/relu_5x5_reduce
I0810 21:05:20.378278   463 net.cpp:435] inception_5a/relu_5x5_reduce <- inception_5a/5x5_reduce
I0810 21:05:20.378288   463 net.cpp:396] inception_5a/relu_5x5_reduce -> inception_5a/5x5_reduce (in-place)
I0810 21:05:20.378298   463 net.cpp:144] Setting up inception_5a/relu_5x5_reduce
I0810 21:05:20.378305   463 net.cpp:151] Top shape: 6 32 40 40 (307200)
I0810 21:05:20.378311   463 net.cpp:159] Memory required for data: 2795636448
I0810 21:05:20.378317   463 layer_factory.hpp:77] Creating layer inception_5a/5x5
I0810 21:05:20.378329   463 net.cpp:94] Creating Layer inception_5a/5x5
I0810 21:05:20.378335   463 net.cpp:435] inception_5a/5x5 <- inception_5a/5x5_reduce
I0810 21:05:20.378346   463 net.cpp:409] inception_5a/5x5 -> inception_5a/5x5
I0810 21:05:20.379242   463 net.cpp:144] Setting up inception_5a/5x5
I0810 21:05:20.379254   463 net.cpp:151] Top shape: 6 128 40 40 (1228800)
I0810 21:05:20.379261   463 net.cpp:159] Memory required for data: 2800551648
I0810 21:05:20.379271   463 layer_factory.hpp:77] Creating layer inception_5a/relu_5x5
I0810 21:05:20.379281   463 net.cpp:94] Creating Layer inception_5a/relu_5x5
I0810 21:05:20.379287   463 net.cpp:435] inception_5a/relu_5x5 <- inception_5a/5x5
I0810 21:05:20.379297   463 net.cpp:396] inception_5a/relu_5x5 -> inception_5a/5x5 (in-place)
I0810 21:05:20.379307   463 net.cpp:144] Setting up inception_5a/relu_5x5
I0810 21:05:20.379314   463 net.cpp:151] Top shape: 6 128 40 40 (1228800)
I0810 21:05:20.379319   463 net.cpp:159] Memory required for data: 2805466848
I0810 21:05:20.379325   463 layer_factory.hpp:77] Creating layer inception_5a/pool
I0810 21:05:20.379336   463 net.cpp:94] Creating Layer inception_5a/pool
I0810 21:05:20.379343   463 net.cpp:435] inception_5a/pool <- inception_4e/output_inception_4e/output_0_split_3
I0810 21:05:20.379354   463 net.cpp:409] inception_5a/pool -> inception_5a/pool
I0810 21:05:20.379411   463 net.cpp:144] Setting up inception_5a/pool
I0810 21:05:20.379421   463 net.cpp:151] Top shape: 6 832 40 40 (7987200)
I0810 21:05:20.379427   463 net.cpp:159] Memory required for data: 2837415648
I0810 21:05:20.379433   463 layer_factory.hpp:77] Creating layer inception_5a/pool_proj
I0810 21:05:20.379446   463 net.cpp:94] Creating Layer inception_5a/pool_proj
I0810 21:05:20.379452   463 net.cpp:435] inception_5a/pool_proj <- inception_5a/pool
I0810 21:05:20.379463   463 net.cpp:409] inception_5a/pool_proj -> inception_5a/pool_proj
I0810 21:05:20.381026   463 net.cpp:144] Setting up inception_5a/pool_proj
I0810 21:05:20.381043   463 net.cpp:151] Top shape: 6 128 40 40 (1228800)
I0810 21:05:20.381049   463 net.cpp:159] Memory required for data: 2842330848
I0810 21:05:20.381059   463 layer_factory.hpp:77] Creating layer inception_5a/relu_pool_proj
I0810 21:05:20.381072   463 net.cpp:94] Creating Layer inception_5a/relu_pool_proj
I0810 21:05:20.381078   463 net.cpp:435] inception_5a/relu_pool_proj <- inception_5a/pool_proj
I0810 21:05:20.381088   463 net.cpp:396] inception_5a/relu_pool_proj -> inception_5a/pool_proj (in-place)
I0810 21:05:20.381100   463 net.cpp:144] Setting up inception_5a/relu_pool_proj
I0810 21:05:20.381132   463 net.cpp:151] Top shape: 6 128 40 40 (1228800)
I0810 21:05:20.381139   463 net.cpp:159] Memory required for data: 2847246048
I0810 21:05:20.381145   463 layer_factory.hpp:77] Creating layer inception_5a/output
I0810 21:05:20.381156   463 net.cpp:94] Creating Layer inception_5a/output
I0810 21:05:20.381172   463 net.cpp:435] inception_5a/output <- inception_5a/1x1
I0810 21:05:20.381181   463 net.cpp:435] inception_5a/output <- inception_5a/3x3
I0810 21:05:20.381187   463 net.cpp:435] inception_5a/output <- inception_5a/5x5
I0810 21:05:20.381194   463 net.cpp:435] inception_5a/output <- inception_5a/pool_proj
I0810 21:05:20.381204   463 net.cpp:409] inception_5a/output -> inception_5a/output
I0810 21:05:20.381253   463 net.cpp:144] Setting up inception_5a/output
I0810 21:05:20.381263   463 net.cpp:151] Top shape: 6 832 40 40 (7987200)
I0810 21:05:20.381269   463 net.cpp:159] Memory required for data: 2879194848
I0810 21:05:20.381275   463 layer_factory.hpp:77] Creating layer inception_5a/output_inception_5a/output_0_split
I0810 21:05:20.381286   463 net.cpp:94] Creating Layer inception_5a/output_inception_5a/output_0_split
I0810 21:05:20.381294   463 net.cpp:435] inception_5a/output_inception_5a/output_0_split <- inception_5a/output
I0810 21:05:20.381304   463 net.cpp:409] inception_5a/output_inception_5a/output_0_split -> inception_5a/output_inception_5a/output_0_split_0
I0810 21:05:20.381314   463 net.cpp:409] inception_5a/output_inception_5a/output_0_split -> inception_5a/output_inception_5a/output_0_split_1
I0810 21:05:20.381325   463 net.cpp:409] inception_5a/output_inception_5a/output_0_split -> inception_5a/output_inception_5a/output_0_split_2
I0810 21:05:20.381342   463 net.cpp:409] inception_5a/output_inception_5a/output_0_split -> inception_5a/output_inception_5a/output_0_split_3
I0810 21:05:20.381418   463 net.cpp:144] Setting up inception_5a/output_inception_5a/output_0_split
I0810 21:05:20.381428   463 net.cpp:151] Top shape: 6 832 40 40 (7987200)
I0810 21:05:20.381435   463 net.cpp:151] Top shape: 6 832 40 40 (7987200)
I0810 21:05:20.381443   463 net.cpp:151] Top shape: 6 832 40 40 (7987200)
I0810 21:05:20.381448   463 net.cpp:151] Top shape: 6 832 40 40 (7987200)
I0810 21:05:20.381454   463 net.cpp:159] Memory required for data: 3006990048
I0810 21:05:20.381460   463 layer_factory.hpp:77] Creating layer inception_5b/1x1
I0810 21:05:20.381472   463 net.cpp:94] Creating Layer inception_5b/1x1
I0810 21:05:20.381479   463 net.cpp:435] inception_5b/1x1 <- inception_5a/output_inception_5a/output_0_split_0
I0810 21:05:20.381489   463 net.cpp:409] inception_5b/1x1 -> inception_5b/1x1
I0810 21:05:20.384256   463 net.cpp:144] Setting up inception_5b/1x1
I0810 21:05:20.384279   463 net.cpp:151] Top shape: 6 384 40 40 (3686400)
I0810 21:05:20.384285   463 net.cpp:159] Memory required for data: 3021735648
I0810 21:05:20.384295   463 layer_factory.hpp:77] Creating layer inception_5b/relu_1x1
I0810 21:05:20.384305   463 net.cpp:94] Creating Layer inception_5b/relu_1x1
I0810 21:05:20.384312   463 net.cpp:435] inception_5b/relu_1x1 <- inception_5b/1x1
I0810 21:05:20.384322   463 net.cpp:396] inception_5b/relu_1x1 -> inception_5b/1x1 (in-place)
I0810 21:05:20.384335   463 net.cpp:144] Setting up inception_5b/relu_1x1
I0810 21:05:20.384342   463 net.cpp:151] Top shape: 6 384 40 40 (3686400)
I0810 21:05:20.384348   463 net.cpp:159] Memory required for data: 3036481248
I0810 21:05:20.384354   463 layer_factory.hpp:77] Creating layer inception_5b/3x3_reduce
I0810 21:05:20.384366   463 net.cpp:94] Creating Layer inception_5b/3x3_reduce
I0810 21:05:20.384372   463 net.cpp:435] inception_5b/3x3_reduce <- inception_5a/output_inception_5a/output_0_split_1
I0810 21:05:20.384393   463 net.cpp:409] inception_5b/3x3_reduce -> inception_5b/3x3_reduce
I0810 21:05:20.386274   463 net.cpp:144] Setting up inception_5b/3x3_reduce
I0810 21:05:20.386291   463 net.cpp:151] Top shape: 6 192 40 40 (1843200)
I0810 21:05:20.386298   463 net.cpp:159] Memory required for data: 3043854048
I0810 21:05:20.386324   463 layer_factory.hpp:77] Creating layer inception_5b/relu_3x3_reduce
I0810 21:05:20.386337   463 net.cpp:94] Creating Layer inception_5b/relu_3x3_reduce
I0810 21:05:20.386343   463 net.cpp:435] inception_5b/relu_3x3_reduce <- inception_5b/3x3_reduce
I0810 21:05:20.386353   463 net.cpp:396] inception_5b/relu_3x3_reduce -> inception_5b/3x3_reduce (in-place)
I0810 21:05:20.386365   463 net.cpp:144] Setting up inception_5b/relu_3x3_reduce
I0810 21:05:20.386373   463 net.cpp:151] Top shape: 6 192 40 40 (1843200)
I0810 21:05:20.386379   463 net.cpp:159] Memory required for data: 3051226848
I0810 21:05:20.386385   463 layer_factory.hpp:77] Creating layer inception_5b/3x3
I0810 21:05:20.386399   463 net.cpp:94] Creating Layer inception_5b/3x3
I0810 21:05:20.386405   463 net.cpp:435] inception_5b/3x3 <- inception_5b/3x3_reduce
I0810 21:05:20.386416   463 net.cpp:409] inception_5b/3x3 -> inception_5b/3x3
I0810 21:05:20.392453   463 net.cpp:144] Setting up inception_5b/3x3
I0810 21:05:20.392472   463 net.cpp:151] Top shape: 6 384 40 40 (3686400)
I0810 21:05:20.392478   463 net.cpp:159] Memory required for data: 3065972448
I0810 21:05:20.392488   463 layer_factory.hpp:77] Creating layer inception_5b/relu_3x3
I0810 21:05:20.392499   463 net.cpp:94] Creating Layer inception_5b/relu_3x3
I0810 21:05:20.392508   463 net.cpp:435] inception_5b/relu_3x3 <- inception_5b/3x3
I0810 21:05:20.392516   463 net.cpp:396] inception_5b/relu_3x3 -> inception_5b/3x3 (in-place)
I0810 21:05:20.392529   463 net.cpp:144] Setting up inception_5b/relu_3x3
I0810 21:05:20.392536   463 net.cpp:151] Top shape: 6 384 40 40 (3686400)
I0810 21:05:20.392542   463 net.cpp:159] Memory required for data: 3080718048
I0810 21:05:20.392549   463 layer_factory.hpp:77] Creating layer inception_5b/5x5_reduce
I0810 21:05:20.392561   463 net.cpp:94] Creating Layer inception_5b/5x5_reduce
I0810 21:05:20.392570   463 net.cpp:435] inception_5b/5x5_reduce <- inception_5a/output_inception_5a/output_0_split_2
I0810 21:05:20.392580   463 net.cpp:409] inception_5b/5x5_reduce -> inception_5b/5x5_reduce
I0810 21:05:20.393793   463 net.cpp:144] Setting up inception_5b/5x5_reduce
I0810 21:05:20.393810   463 net.cpp:151] Top shape: 6 48 40 40 (460800)
I0810 21:05:20.393817   463 net.cpp:159] Memory required for data: 3082561248
I0810 21:05:20.393827   463 layer_factory.hpp:77] Creating layer inception_5b/relu_5x5_reduce
I0810 21:05:20.393838   463 net.cpp:94] Creating Layer inception_5b/relu_5x5_reduce
I0810 21:05:20.393846   463 net.cpp:435] inception_5b/relu_5x5_reduce <- inception_5b/5x5_reduce
I0810 21:05:20.393856   463 net.cpp:396] inception_5b/relu_5x5_reduce -> inception_5b/5x5_reduce (in-place)
I0810 21:05:20.393867   463 net.cpp:144] Setting up inception_5b/relu_5x5_reduce
I0810 21:05:20.393874   463 net.cpp:151] Top shape: 6 48 40 40 (460800)
I0810 21:05:20.393880   463 net.cpp:159] Memory required for data: 3084404448
I0810 21:05:20.393887   463 layer_factory.hpp:77] Creating layer inception_5b/5x5
I0810 21:05:20.393899   463 net.cpp:94] Creating Layer inception_5b/5x5
I0810 21:05:20.393906   463 net.cpp:435] inception_5b/5x5 <- inception_5b/5x5_reduce
I0810 21:05:20.393918   463 net.cpp:409] inception_5b/5x5 -> inception_5b/5x5
I0810 21:05:20.395053   463 net.cpp:144] Setting up inception_5b/5x5
I0810 21:05:20.395066   463 net.cpp:151] Top shape: 6 128 40 40 (1228800)
I0810 21:05:20.395072   463 net.cpp:159] Memory required for data: 3089319648
I0810 21:05:20.395081   463 layer_factory.hpp:77] Creating layer inception_5b/relu_5x5
I0810 21:05:20.395092   463 net.cpp:94] Creating Layer inception_5b/relu_5x5
I0810 21:05:20.395098   463 net.cpp:435] inception_5b/relu_5x5 <- inception_5b/5x5
I0810 21:05:20.395107   463 net.cpp:396] inception_5b/relu_5x5 -> inception_5b/5x5 (in-place)
I0810 21:05:20.395118   463 net.cpp:144] Setting up inception_5b/relu_5x5
I0810 21:05:20.395125   463 net.cpp:151] Top shape: 6 128 40 40 (1228800)
I0810 21:05:20.395131   463 net.cpp:159] Memory required for data: 3094234848
I0810 21:05:20.395138   463 layer_factory.hpp:77] Creating layer inception_5b/pool
I0810 21:05:20.395175   463 net.cpp:94] Creating Layer inception_5b/pool
I0810 21:05:20.395184   463 net.cpp:435] inception_5b/pool <- inception_5a/output_inception_5a/output_0_split_3
I0810 21:05:20.395195   463 net.cpp:409] inception_5b/pool -> inception_5b/pool
I0810 21:05:20.395243   463 net.cpp:144] Setting up inception_5b/pool
I0810 21:05:20.395253   463 net.cpp:151] Top shape: 6 832 40 40 (7987200)
I0810 21:05:20.395259   463 net.cpp:159] Memory required for data: 3126183648
I0810 21:05:20.395265   463 layer_factory.hpp:77] Creating layer inception_5b/pool_proj
I0810 21:05:20.395278   463 net.cpp:94] Creating Layer inception_5b/pool_proj
I0810 21:05:20.395285   463 net.cpp:435] inception_5b/pool_proj <- inception_5b/pool
I0810 21:05:20.395295   463 net.cpp:409] inception_5b/pool_proj -> inception_5b/pool_proj
I0810 21:05:20.396829   463 net.cpp:144] Setting up inception_5b/pool_proj
I0810 21:05:20.396845   463 net.cpp:151] Top shape: 6 128 40 40 (1228800)
I0810 21:05:20.396852   463 net.cpp:159] Memory required for data: 3131098848
I0810 21:05:20.396862   463 layer_factory.hpp:77] Creating layer inception_5b/relu_pool_proj
I0810 21:05:20.396872   463 net.cpp:94] Creating Layer inception_5b/relu_pool_proj
I0810 21:05:20.396898   463 net.cpp:435] inception_5b/relu_pool_proj <- inception_5b/pool_proj
I0810 21:05:20.396910   463 net.cpp:396] inception_5b/relu_pool_proj -> inception_5b/pool_proj (in-place)
I0810 21:05:20.396922   463 net.cpp:144] Setting up inception_5b/relu_pool_proj
I0810 21:05:20.396930   463 net.cpp:151] Top shape: 6 128 40 40 (1228800)
I0810 21:05:20.396935   463 net.cpp:159] Memory required for data: 3136014048
I0810 21:05:20.396942   463 layer_factory.hpp:77] Creating layer inception_5b/output
I0810 21:05:20.396951   463 net.cpp:94] Creating Layer inception_5b/output
I0810 21:05:20.396958   463 net.cpp:435] inception_5b/output <- inception_5b/1x1
I0810 21:05:20.396966   463 net.cpp:435] inception_5b/output <- inception_5b/3x3
I0810 21:05:20.396973   463 net.cpp:435] inception_5b/output <- inception_5b/5x5
I0810 21:05:20.396981   463 net.cpp:435] inception_5b/output <- inception_5b/pool_proj
I0810 21:05:20.396989   463 net.cpp:409] inception_5b/output -> inception_5b/output
I0810 21:05:20.397024   463 net.cpp:144] Setting up inception_5b/output
I0810 21:05:20.397033   463 net.cpp:151] Top shape: 6 1024 40 40 (9830400)
I0810 21:05:20.397038   463 net.cpp:159] Memory required for data: 3175335648
I0810 21:05:20.397044   463 layer_factory.hpp:77] Creating layer pool5/drop_s1
I0810 21:05:20.397054   463 net.cpp:94] Creating Layer pool5/drop_s1
I0810 21:05:20.397060   463 net.cpp:435] pool5/drop_s1 <- inception_5b/output
I0810 21:05:20.397071   463 net.cpp:409] pool5/drop_s1 -> pool5/drop_s1
I0810 21:05:20.397114   463 net.cpp:144] Setting up pool5/drop_s1
I0810 21:05:20.397122   463 net.cpp:151] Top shape: 6 1024 40 40 (9830400)
I0810 21:05:20.397128   463 net.cpp:159] Memory required for data: 3214657248
I0810 21:05:20.397133   463 layer_factory.hpp:77] Creating layer pool5/drop_s1_pool5/drop_s1_0_split
I0810 21:05:20.397155   463 net.cpp:94] Creating Layer pool5/drop_s1_pool5/drop_s1_0_split
I0810 21:05:20.397169   463 net.cpp:435] pool5/drop_s1_pool5/drop_s1_0_split <- pool5/drop_s1
I0810 21:05:20.397179   463 net.cpp:409] pool5/drop_s1_pool5/drop_s1_0_split -> pool5/drop_s1_pool5/drop_s1_0_split_0
I0810 21:05:20.397189   463 net.cpp:409] pool5/drop_s1_pool5/drop_s1_0_split -> pool5/drop_s1_pool5/drop_s1_0_split_1
I0810 21:05:20.397231   463 net.cpp:144] Setting up pool5/drop_s1_pool5/drop_s1_0_split
I0810 21:05:20.397240   463 net.cpp:151] Top shape: 6 1024 40 40 (9830400)
I0810 21:05:20.397248   463 net.cpp:151] Top shape: 6 1024 40 40 (9830400)
I0810 21:05:20.397253   463 net.cpp:159] Memory required for data: 3293300448
I0810 21:05:20.397258   463 layer_factory.hpp:77] Creating layer cvg/classifier
I0810 21:05:20.397270   463 net.cpp:94] Creating Layer cvg/classifier
I0810 21:05:20.397277   463 net.cpp:435] cvg/classifier <- pool5/drop_s1_pool5/drop_s1_0_split_0
I0810 21:05:20.397303   463 net.cpp:409] cvg/classifier -> cvg/classifier
I0810 21:05:20.397570   463 net.cpp:144] Setting up cvg/classifier
I0810 21:05:20.397583   463 net.cpp:151] Top shape: 6 1 40 40 (9600)
I0810 21:05:20.397588   463 net.cpp:159] Memory required for data: 3293338848
I0810 21:05:20.397598   463 layer_factory.hpp:77] Creating layer coverage/sig
I0810 21:05:20.397606   463 net.cpp:94] Creating Layer coverage/sig
I0810 21:05:20.397613   463 net.cpp:435] coverage/sig <- cvg/classifier
I0810 21:05:20.397621   463 net.cpp:409] coverage/sig -> coverage
I0810 21:05:20.397655   463 net.cpp:144] Setting up coverage/sig
I0810 21:05:20.397680   463 net.cpp:151] Top shape: 6 1 40 40 (9600)
I0810 21:05:20.397686   463 net.cpp:159] Memory required for data: 3293377248
I0810 21:05:20.397692   463 layer_factory.hpp:77] Creating layer coverage_coverage/sig_0_split
I0810 21:05:20.397702   463 net.cpp:94] Creating Layer coverage_coverage/sig_0_split
I0810 21:05:20.397708   463 net.cpp:435] coverage_coverage/sig_0_split <- coverage
I0810 21:05:20.397717   463 net.cpp:409] coverage_coverage/sig_0_split -> coverage_coverage/sig_0_split_0
I0810 21:05:20.397727   463 net.cpp:409] coverage_coverage/sig_0_split -> coverage_coverage/sig_0_split_1
I0810 21:05:20.397768   463 net.cpp:144] Setting up coverage_coverage/sig_0_split
I0810 21:05:20.397776   463 net.cpp:151] Top shape: 6 1 40 40 (9600)
I0810 21:05:20.397783   463 net.cpp:151] Top shape: 6 1 40 40 (9600)
I0810 21:05:20.397789   463 net.cpp:159] Memory required for data: 3293454048
I0810 21:05:20.397794   463 layer_factory.hpp:77] Creating layer bbox/regressor
I0810 21:05:20.397806   463 net.cpp:94] Creating Layer bbox/regressor
I0810 21:05:20.397814   463 net.cpp:435] bbox/regressor <- pool5/drop_s1_pool5/drop_s1_0_split_1
I0810 21:05:20.397825   463 net.cpp:409] bbox/regressor -> bboxes
I0810 21:05:20.398098   463 net.cpp:144] Setting up bbox/regressor
I0810 21:05:20.398110   463 net.cpp:151] Top shape: 6 4 40 40 (38400)
I0810 21:05:20.398116   463 net.cpp:159] Memory required for data: 3293607648
I0810 21:05:20.398125   463 layer_factory.hpp:77] Creating layer bboxes_bbox/regressor_0_split
I0810 21:05:20.398134   463 net.cpp:94] Creating Layer bboxes_bbox/regressor_0_split
I0810 21:05:20.398141   463 net.cpp:435] bboxes_bbox/regressor_0_split <- bboxes
I0810 21:05:20.398151   463 net.cpp:409] bboxes_bbox/regressor_0_split -> bboxes_bbox/regressor_0_split_0
I0810 21:05:20.398169   463 net.cpp:409] bboxes_bbox/regressor_0_split -> bboxes_bbox/regressor_0_split_1
I0810 21:05:20.398223   463 net.cpp:144] Setting up bboxes_bbox/regressor_0_split
I0810 21:05:20.398232   463 net.cpp:151] Top shape: 6 4 40 40 (38400)
I0810 21:05:20.398239   463 net.cpp:151] Top shape: 6 4 40 40 (38400)
I0810 21:05:20.398244   463 net.cpp:159] Memory required for data: 3293914848
I0810 21:05:20.398250   463 layer_factory.hpp:77] Creating layer bbox_mask
I0810 21:05:20.398262   463 net.cpp:94] Creating Layer bbox_mask
I0810 21:05:20.398267   463 net.cpp:435] bbox_mask <- bboxes_bbox/regressor_0_split_0
I0810 21:05:20.398275   463 net.cpp:435] bbox_mask <- coverage-block
I0810 21:05:20.398285   463 net.cpp:409] bbox_mask -> bboxes-masked
I0810 21:05:20.398316   463 net.cpp:144] Setting up bbox_mask
I0810 21:05:20.398325   463 net.cpp:151] Top shape: 6 4 40 40 (38400)
I0810 21:05:20.398330   463 net.cpp:159] Memory required for data: 3294068448
I0810 21:05:20.398336   463 layer_factory.hpp:77] Creating layer bbox-norm
I0810 21:05:20.398346   463 net.cpp:94] Creating Layer bbox-norm
I0810 21:05:20.398352   463 net.cpp:435] bbox-norm <- bboxes-masked
I0810 21:05:20.398360   463 net.cpp:435] bbox-norm <- size-block_size-block_0_split_1
I0810 21:05:20.398370   463 net.cpp:409] bbox-norm -> bboxes-masked-norm
I0810 21:05:20.398398   463 net.cpp:144] Setting up bbox-norm
I0810 21:05:20.398407   463 net.cpp:151] Top shape: 6 4 40 40 (38400)
I0810 21:05:20.398510   463 net.cpp:159] Memory required for data: 3294222048
I0810 21:05:20.398521   463 layer_factory.hpp:77] Creating layer bbox-obj-norm
I0810 21:05:20.398551   463 net.cpp:94] Creating Layer bbox-obj-norm
I0810 21:05:20.398561   463 net.cpp:435] bbox-obj-norm <- bboxes-masked-norm
I0810 21:05:20.398571   463 net.cpp:435] bbox-obj-norm <- obj-block_obj-block_0_split_1
I0810 21:05:20.398581   463 net.cpp:409] bbox-obj-norm -> bboxes-obj-masked-norm
I0810 21:05:20.398633   463 net.cpp:144] Setting up bbox-obj-norm
I0810 21:05:20.398644   463 net.cpp:151] Top shape: 6 4 40 40 (38400)
I0810 21:05:20.398650   463 net.cpp:159] Memory required for data: 3294375648
I0810 21:05:20.398656   463 layer_factory.hpp:77] Creating layer bbox_loss
I0810 21:05:20.398667   463 net.cpp:94] Creating Layer bbox_loss
I0810 21:05:20.398674   463 net.cpp:435] bbox_loss <- bboxes-obj-masked-norm
I0810 21:05:20.398682   463 net.cpp:435] bbox_loss <- bbox-obj-label-norm
I0810 21:05:20.398694   463 net.cpp:409] bbox_loss -> loss_bbox
I0810 21:05:20.398759   463 net.cpp:144] Setting up bbox_loss
I0810 21:05:20.398769   463 net.cpp:151] Top shape: (1)
I0810 21:05:20.398774   463 net.cpp:154]     with loss weight 2
I0810 21:05:20.398790   463 net.cpp:159] Memory required for data: 3294375652
I0810 21:05:20.398797   463 layer_factory.hpp:77] Creating layer coverage_loss
I0810 21:05:20.398808   463 net.cpp:94] Creating Layer coverage_loss
I0810 21:05:20.398814   463 net.cpp:435] coverage_loss <- coverage_coverage/sig_0_split_0
I0810 21:05:20.398823   463 net.cpp:435] coverage_loss <- coverage-label_slice-label_4_split_0
I0810 21:05:20.398831   463 net.cpp:409] coverage_loss -> loss_coverage
I0810 21:05:20.398877   463 net.cpp:144] Setting up coverage_loss
I0810 21:05:20.398886   463 net.cpp:151] Top shape: (1)
I0810 21:05:20.398892   463 net.cpp:154]     with loss weight 1
I0810 21:05:20.398901   463 net.cpp:159] Memory required for data: 3294375656
I0810 21:05:20.398907   463 layer_factory.hpp:77] Creating layer cluster
I0810 21:05:21.092106   463 net.cpp:94] Creating Layer cluster
I0810 21:05:21.092149   463 net.cpp:435] cluster <- coverage_coverage/sig_0_split_1
I0810 21:05:21.092171   463 net.cpp:435] cluster <- bboxes_bbox/regressor_0_split_1
I0810 21:05:21.092186   463 net.cpp:409] cluster -> bbox-list
I0810 21:05:21.590293   463 net.cpp:144] Setting up cluster
I0810 21:05:21.590334   463 net.cpp:151] Top shape: 6 50 5 (1500)
I0810 21:05:21.590342   463 net.cpp:159] Memory required for data: 3294381656
I0810 21:05:21.590354   463 layer_factory.hpp:77] Creating layer cluster_gt
I0810 21:05:21.590410   463 net.cpp:94] Creating Layer cluster_gt
I0810 21:05:21.590422   463 net.cpp:435] cluster_gt <- coverage-label_slice-label_4_split_1
I0810 21:05:21.590435   463 net.cpp:435] cluster_gt <- bbox-label_slice-label_1_split_1
I0810 21:05:21.590445   463 net.cpp:409] cluster_gt -> bbox-list-label
I0810 21:05:21.590601   463 net.cpp:144] Setting up cluster_gt
I0810 21:05:21.590615   463 net.cpp:151] Top shape: 6 50 5 (1500)
I0810 21:05:21.590620   463 net.cpp:159] Memory required for data: 3294387656
I0810 21:05:21.590629   463 layer_factory.hpp:77] Creating layer score
I0810 21:05:21.590939   463 net.cpp:94] Creating Layer score
I0810 21:05:21.590956   463 net.cpp:435] score <- bbox-list-label
I0810 21:05:21.590970   463 net.cpp:435] score <- bbox-list
I0810 21:05:21.590984   463 net.cpp:409] score -> bbox-list-scored
I0810 21:05:21.591265   463 net.cpp:144] Setting up score
I0810 21:05:21.591284   463 net.cpp:151] Top shape: 6 50 5 (1500)
I0810 21:05:21.591292   463 net.cpp:159] Memory required for data: 3294393656
I0810 21:05:21.591302   463 layer_factory.hpp:77] Creating layer mAP
I0810 21:05:21.591343   463 net.cpp:94] Creating Layer mAP
I0810 21:05:21.591357   463 net.cpp:435] mAP <- bbox-list-scored
I0810 21:05:21.591373   463 net.cpp:409] mAP -> mAP
I0810 21:05:21.591398   463 net.cpp:409] mAP -> precision
I0810 21:05:21.591416   463 net.cpp:409] mAP -> recall
I0810 21:05:21.591547   463 net.cpp:144] Setting up mAP
I0810 21:05:21.591565   463 net.cpp:151] Top shape: 1 (1)
I0810 21:05:21.591576   463 net.cpp:151] Top shape: 1 (1)
I0810 21:05:21.591586   463 net.cpp:151] Top shape: 1 (1)
I0810 21:05:21.591627   463 net.cpp:159] Memory required for data: 3294393668
I0810 21:05:21.591639   463 net.cpp:222] mAP does not need backward computation.
I0810 21:05:21.591650   463 net.cpp:222] score does not need backward computation.
I0810 21:05:21.591660   463 net.cpp:222] cluster_gt does not need backward computation.
I0810 21:05:21.591670   463 net.cpp:222] cluster does not need backward computation.
I0810 21:05:21.591681   463 net.cpp:220] coverage_loss needs backward computation.
I0810 21:05:21.591691   463 net.cpp:220] bbox_loss needs backward computation.
I0810 21:05:21.591701   463 net.cpp:220] bbox-obj-norm needs backward computation.
I0810 21:05:21.591711   463 net.cpp:220] bbox-norm needs backward computation.
I0810 21:05:21.591722   463 net.cpp:220] bbox_mask needs backward computation.
I0810 21:05:21.591732   463 net.cpp:220] bboxes_bbox/regressor_0_split needs backward computation.
I0810 21:05:21.591742   463 net.cpp:220] bbox/regressor needs backward computation.
I0810 21:05:21.591750   463 net.cpp:220] coverage_coverage/sig_0_split needs backward computation.
I0810 21:05:21.591758   463 net.cpp:220] coverage/sig needs backward computation.
I0810 21:05:21.591768   463 net.cpp:220] cvg/classifier needs backward computation.
I0810 21:05:21.591776   463 net.cpp:220] pool5/drop_s1_pool5/drop_s1_0_split needs backward computation.
I0810 21:05:21.591784   463 net.cpp:220] pool5/drop_s1 needs backward computation.
I0810 21:05:21.591794   463 net.cpp:220] inception_5b/output needs backward computation.
I0810 21:05:21.591806   463 net.cpp:220] inception_5b/relu_pool_proj needs backward computation.
I0810 21:05:21.591816   463 net.cpp:220] inception_5b/pool_proj needs backward computation.
I0810 21:05:21.591825   463 net.cpp:220] inception_5b/pool needs backward computation.
I0810 21:05:21.591835   463 net.cpp:220] inception_5b/relu_5x5 needs backward computation.
I0810 21:05:21.591843   463 net.cpp:220] inception_5b/5x5 needs backward computation.
I0810 21:05:21.591852   463 net.cpp:220] inception_5b/relu_5x5_reduce needs backward computation.
I0810 21:05:21.591861   463 net.cpp:220] inception_5b/5x5_reduce needs backward computation.
I0810 21:05:21.591871   463 net.cpp:220] inception_5b/relu_3x3 needs backward computation.
I0810 21:05:21.591879   463 net.cpp:220] inception_5b/3x3 needs backward computation.
I0810 21:05:21.591888   463 net.cpp:220] inception_5b/relu_3x3_reduce needs backward computation.
I0810 21:05:21.591897   463 net.cpp:220] inception_5b/3x3_reduce needs backward computation.
I0810 21:05:21.591904   463 net.cpp:220] inception_5b/relu_1x1 needs backward computation.
I0810 21:05:21.591912   463 net.cpp:220] inception_5b/1x1 needs backward computation.
I0810 21:05:21.591918   463 net.cpp:220] inception_5a/output_inception_5a/output_0_split needs backward computation.
I0810 21:05:21.591925   463 net.cpp:220] inception_5a/output needs backward computation.
I0810 21:05:21.591934   463 net.cpp:220] inception_5a/relu_pool_proj needs backward computation.
I0810 21:05:21.591940   463 net.cpp:220] inception_5a/pool_proj needs backward computation.
I0810 21:05:21.591948   463 net.cpp:220] inception_5a/pool needs backward computation.
I0810 21:05:21.591954   463 net.cpp:220] inception_5a/relu_5x5 needs backward computation.
I0810 21:05:21.591961   463 net.cpp:220] inception_5a/5x5 needs backward computation.
I0810 21:05:21.591969   463 net.cpp:220] inception_5a/relu_5x5_reduce needs backward computation.
I0810 21:05:21.591974   463 net.cpp:220] inception_5a/5x5_reduce needs backward computation.
I0810 21:05:21.591981   463 net.cpp:220] inception_5a/relu_3x3 needs backward computation.
I0810 21:05:21.591987   463 net.cpp:220] inception_5a/3x3 needs backward computation.
I0810 21:05:21.591995   463 net.cpp:220] inception_5a/relu_3x3_reduce needs backward computation.
I0810 21:05:21.592000   463 net.cpp:220] inception_5a/3x3_reduce needs backward computation.
I0810 21:05:21.592007   463 net.cpp:220] inception_5a/relu_1x1 needs backward computation.
I0810 21:05:21.592015   463 net.cpp:220] inception_5a/1x1 needs backward computation.
I0810 21:05:21.592033   463 net.cpp:220] inception_4e/output_inception_4e/output_0_split needs backward computation.
I0810 21:05:21.592041   463 net.cpp:220] inception_4e/output needs backward computation.
I0810 21:05:21.592049   463 net.cpp:220] inception_4e/relu_pool_proj needs backward computation.
I0810 21:05:21.592056   463 net.cpp:220] inception_4e/pool_proj needs backward computation.
I0810 21:05:21.592063   463 net.cpp:220] inception_4e/pool needs backward computation.
I0810 21:05:21.592070   463 net.cpp:220] inception_4e/relu_5x5 needs backward computation.
I0810 21:05:21.592077   463 net.cpp:220] inception_4e/5x5 needs backward computation.
I0810 21:05:21.592083   463 net.cpp:220] inception_4e/relu_5x5_reduce needs backward computation.
I0810 21:05:21.592099   463 net.cpp:220] inception_4e/5x5_reduce needs backward computation.
I0810 21:05:21.592108   463 net.cpp:220] inception_4e/relu_3x3 needs backward computation.
I0810 21:05:21.592114   463 net.cpp:220] inception_4e/3x3 needs backward computation.
I0810 21:05:21.592121   463 net.cpp:220] inception_4e/relu_3x3_reduce needs backward computation.
I0810 21:05:21.592128   463 net.cpp:220] inception_4e/3x3_reduce needs backward computation.
I0810 21:05:21.592134   463 net.cpp:220] inception_4e/relu_1x1 needs backward computation.
I0810 21:05:21.592141   463 net.cpp:220] inception_4e/1x1 needs backward computation.
I0810 21:05:21.592147   463 net.cpp:220] inception_4d/output_inception_4d/output_0_split needs backward computation.
I0810 21:05:21.592154   463 net.cpp:220] inception_4d/output needs backward computation.
I0810 21:05:21.592167   463 net.cpp:220] inception_4d/relu_pool_proj needs backward computation.
I0810 21:05:21.592175   463 net.cpp:220] inception_4d/pool_proj needs backward computation.
I0810 21:05:21.592180   463 net.cpp:220] inception_4d/pool needs backward computation.
I0810 21:05:21.592187   463 net.cpp:220] inception_4d/relu_5x5 needs backward computation.
I0810 21:05:21.592195   463 net.cpp:220] inception_4d/5x5 needs backward computation.
I0810 21:05:21.592200   463 net.cpp:220] inception_4d/relu_5x5_reduce needs backward computation.
I0810 21:05:21.592207   463 net.cpp:220] inception_4d/5x5_reduce needs backward computation.
I0810 21:05:21.592214   463 net.cpp:220] inception_4d/relu_3x3 needs backward computation.
I0810 21:05:21.592221   463 net.cpp:220] inception_4d/3x3 needs backward computation.
I0810 21:05:21.592227   463 net.cpp:220] inception_4d/relu_3x3_reduce needs backward computation.
I0810 21:05:21.592233   463 net.cpp:220] inception_4d/3x3_reduce needs backward computation.
I0810 21:05:21.592241   463 net.cpp:220] inception_4d/relu_1x1 needs backward computation.
I0810 21:05:21.592247   463 net.cpp:220] inception_4d/1x1 needs backward computation.
I0810 21:05:21.592253   463 net.cpp:220] inception_4c/output_inception_4c/output_0_split needs backward computation.
I0810 21:05:21.592260   463 net.cpp:220] inception_4c/output needs backward computation.
I0810 21:05:21.592268   463 net.cpp:220] inception_4c/relu_pool_proj needs backward computation.
I0810 21:05:21.592274   463 net.cpp:220] inception_4c/pool_proj needs backward computation.
I0810 21:05:21.592281   463 net.cpp:220] inception_4c/pool needs backward computation.
I0810 21:05:21.592288   463 net.cpp:220] inception_4c/relu_5x5 needs backward computation.
I0810 21:05:21.592294   463 net.cpp:220] inception_4c/5x5 needs backward computation.
I0810 21:05:21.592300   463 net.cpp:220] inception_4c/relu_5x5_reduce needs backward computation.
I0810 21:05:21.592306   463 net.cpp:220] inception_4c/5x5_reduce needs backward computation.
I0810 21:05:21.592314   463 net.cpp:220] inception_4c/relu_3x3 needs backward computation.
I0810 21:05:21.592319   463 net.cpp:220] inception_4c/3x3 needs backward computation.
I0810 21:05:21.592326   463 net.cpp:220] inception_4c/relu_3x3_reduce needs backward computation.
I0810 21:05:21.592334   463 net.cpp:220] inception_4c/3x3_reduce needs backward computation.
I0810 21:05:21.592339   463 net.cpp:220] inception_4c/relu_1x1 needs backward computation.
I0810 21:05:21.592355   463 net.cpp:220] inception_4c/1x1 needs backward computation.
I0810 21:05:21.592362   463 net.cpp:220] inception_4b/output_inception_4b/output_0_split needs backward computation.
I0810 21:05:21.592368   463 net.cpp:220] inception_4b/output needs backward computation.
I0810 21:05:21.592376   463 net.cpp:220] inception_4b/relu_pool_proj needs backward computation.
I0810 21:05:21.592382   463 net.cpp:220] inception_4b/pool_proj needs backward computation.
I0810 21:05:21.592389   463 net.cpp:220] inception_4b/pool needs backward computation.
I0810 21:05:21.592396   463 net.cpp:220] inception_4b/relu_5x5 needs backward computation.
I0810 21:05:21.592402   463 net.cpp:220] inception_4b/5x5 needs backward computation.
I0810 21:05:21.592408   463 net.cpp:220] inception_4b/relu_5x5_reduce needs backward computation.
I0810 21:05:21.592414   463 net.cpp:220] inception_4b/5x5_reduce needs backward computation.
I0810 21:05:21.592422   463 net.cpp:220] inception_4b/relu_3x3 needs backward computation.
I0810 21:05:21.592428   463 net.cpp:220] inception_4b/3x3 needs backward computation.
I0810 21:05:21.592434   463 net.cpp:220] inception_4b/relu_3x3_reduce needs backward computation.
I0810 21:05:21.592442   463 net.cpp:220] inception_4b/3x3_reduce needs backward computation.
I0810 21:05:21.592447   463 net.cpp:220] inception_4b/relu_1x1 needs backward computation.
I0810 21:05:21.592454   463 net.cpp:220] inception_4b/1x1 needs backward computation.
I0810 21:05:21.592460   463 net.cpp:220] inception_4a/output_inception_4a/output_0_split needs backward computation.
I0810 21:05:21.592468   463 net.cpp:220] inception_4a/output needs backward computation.
I0810 21:05:21.592475   463 net.cpp:220] inception_4a/relu_pool_proj needs backward computation.
I0810 21:05:21.592481   463 net.cpp:220] inception_4a/pool_proj needs backward computation.
I0810 21:05:21.592489   463 net.cpp:220] inception_4a/pool needs backward computation.
I0810 21:05:21.592494   463 net.cpp:220] inception_4a/relu_5x5 needs backward computation.
I0810 21:05:21.592501   463 net.cpp:220] inception_4a/5x5 needs backward computation.
I0810 21:05:21.592509   463 net.cpp:220] inception_4a/relu_5x5_reduce needs backward computation.
I0810 21:05:21.592515   463 net.cpp:220] inception_4a/5x5_reduce needs backward computation.
I0810 21:05:21.592521   463 net.cpp:220] inception_4a/relu_3x3 needs backward computation.
I0810 21:05:21.592528   463 net.cpp:220] inception_4a/3x3 needs backward computation.
I0810 21:05:21.592535   463 net.cpp:220] inception_4a/relu_3x3_reduce needs backward computation.
I0810 21:05:21.592540   463 net.cpp:220] inception_4a/3x3_reduce needs backward computation.
I0810 21:05:21.592547   463 net.cpp:220] inception_4a/relu_1x1 needs backward computation.
I0810 21:05:21.592553   463 net.cpp:220] inception_4a/1x1 needs backward computation.
I0810 21:05:21.592561   463 net.cpp:220] pool3/3x3_s2_pool3/3x3_s2_0_split needs backward computation.
I0810 21:05:21.592567   463 net.cpp:220] pool3/3x3_s2 needs backward computation.
I0810 21:05:21.592574   463 net.cpp:220] inception_3b/output needs backward computation.
I0810 21:05:21.592582   463 net.cpp:220] inception_3b/relu_pool_proj needs backward computation.
I0810 21:05:21.592588   463 net.cpp:220] inception_3b/pool_proj needs backward computation.
I0810 21:05:21.592597   463 net.cpp:220] inception_3b/pool needs backward computation.
I0810 21:05:21.592604   463 net.cpp:220] inception_3b/relu_5x5 needs backward computation.
I0810 21:05:21.592610   463 net.cpp:220] inception_3b/5x5 needs backward computation.
I0810 21:05:21.592617   463 net.cpp:220] inception_3b/relu_5x5_reduce needs backward computation.
I0810 21:05:21.592623   463 net.cpp:220] inception_3b/5x5_reduce needs backward computation.
I0810 21:05:21.592630   463 net.cpp:220] inception_3b/relu_3x3 needs backward computation.
I0810 21:05:21.592636   463 net.cpp:220] inception_3b/3x3 needs backward computation.
I0810 21:05:21.592643   463 net.cpp:220] inception_3b/relu_3x3_reduce needs backward computation.
I0810 21:05:21.592658   463 net.cpp:220] inception_3b/3x3_reduce needs backward computation.
I0810 21:05:21.592665   463 net.cpp:220] inception_3b/relu_1x1 needs backward computation.
I0810 21:05:21.592671   463 net.cpp:220] inception_3b/1x1 needs backward computation.
I0810 21:05:21.592679   463 net.cpp:220] inception_3a/output_inception_3a/output_0_split needs backward computation.
I0810 21:05:21.592685   463 net.cpp:220] inception_3a/output needs backward computation.
I0810 21:05:21.592694   463 net.cpp:220] inception_3a/relu_pool_proj needs backward computation.
I0810 21:05:21.592700   463 net.cpp:220] inception_3a/pool_proj needs backward computation.
I0810 21:05:21.592707   463 net.cpp:220] inception_3a/pool needs backward computation.
I0810 21:05:21.592713   463 net.cpp:220] inception_3a/relu_5x5 needs backward computation.
I0810 21:05:21.592720   463 net.cpp:220] inception_3a/5x5 needs backward computation.
I0810 21:05:21.592726   463 net.cpp:220] inception_3a/relu_5x5_reduce needs backward computation.
I0810 21:05:21.592732   463 net.cpp:220] inception_3a/5x5_reduce needs backward computation.
I0810 21:05:21.592739   463 net.cpp:220] inception_3a/relu_3x3 needs backward computation.
I0810 21:05:21.592746   463 net.cpp:220] inception_3a/3x3 needs backward computation.
I0810 21:05:21.592752   463 net.cpp:220] inception_3a/relu_3x3_reduce needs backward computation.
I0810 21:05:21.592758   463 net.cpp:220] inception_3a/3x3_reduce needs backward computation.
I0810 21:05:21.592766   463 net.cpp:220] inception_3a/relu_1x1 needs backward computation.
I0810 21:05:21.592772   463 net.cpp:220] inception_3a/1x1 needs backward computation.
I0810 21:05:21.592777   463 net.cpp:220] pool2/3x3_s2_pool2/3x3_s2_0_split needs backward computation.
I0810 21:05:21.592784   463 net.cpp:220] pool2/3x3_s2 needs backward computation.
I0810 21:05:21.592792   463 net.cpp:220] conv2/norm2 needs backward computation.
I0810 21:05:21.592798   463 net.cpp:220] conv2/relu_3x3 needs backward computation.
I0810 21:05:21.592805   463 net.cpp:220] conv2/3x3 needs backward computation.
I0810 21:05:21.592813   463 net.cpp:220] conv2/relu_3x3_reduce needs backward computation.
I0810 21:05:21.592818   463 net.cpp:220] conv2/3x3_reduce needs backward computation.
I0810 21:05:21.592825   463 net.cpp:220] pool1/norm1 needs backward computation.
I0810 21:05:21.592831   463 net.cpp:220] pool1/3x3_s2 needs backward computation.
I0810 21:05:21.592839   463 net.cpp:220] conv1/relu_7x7 needs backward computation.
I0810 21:05:21.592844   463 net.cpp:220] conv1/7x7_s2 needs backward computation.
I0810 21:05:21.592852   463 net.cpp:222] bb-obj-norm does not need backward computation.
I0810 21:05:21.592860   463 net.cpp:222] bb-label-norm does not need backward computation.
I0810 21:05:21.592869   463 net.cpp:222] obj-block_obj-block_0_split does not need backward computation.
I0810 21:05:21.592876   463 net.cpp:222] obj-block does not need backward computation.
I0810 21:05:21.592921   463 net.cpp:222] size-block_size-block_0_split does not need backward computation.
I0810 21:05:21.592928   463 net.cpp:222] size-block does not need backward computation.
I0810 21:05:21.592936   463 net.cpp:222] coverage-block does not need backward computation.
I0810 21:05:21.592947   463 net.cpp:222] coverage-label_slice-label_4_split does not need backward computation.
I0810 21:05:21.592955   463 net.cpp:222] obj-label_slice-label_3_split does not need backward computation.
I0810 21:05:21.592963   463 net.cpp:222] size-label_slice-label_2_split does not need backward computation.
I0810 21:05:21.592972   463 net.cpp:222] bbox-label_slice-label_1_split does not need backward computation.
I0810 21:05:21.592979   463 net.cpp:222] foreground-label_slice-label_0_split does not need backward computation.
I0810 21:05:21.592988   463 net.cpp:222] slice-label does not need backward computation.
I0810 21:05:21.592995   463 net.cpp:222] val_transform does not need backward computation.
I0810 21:05:21.593003   463 net.cpp:222] val_label does not need backward computation.
I0810 21:05:21.593021   463 net.cpp:222] val_data does not need backward computation.
I0810 21:05:21.593027   463 net.cpp:264] This network produces output loss_bbox
I0810 21:05:21.593035   463 net.cpp:264] This network produces output loss_coverage
I0810 21:05:21.593042   463 net.cpp:264] This network produces output mAP
I0810 21:05:21.593049   463 net.cpp:264] This network produces output precision
I0810 21:05:21.593055   463 net.cpp:264] This network produces output recall
I0810 21:05:21.593261   463 net.cpp:284] Network initialization done.
I0810 21:05:21.594466   463 solver.cpp:60] Solver scaffolding done.
I0810 21:05:21.600378   463 caffe.cpp:135] Finetuning from /home/workspace/bvlc_googlenet.caffemodel
I0810 21:05:21.654029   463 upgrade_proto.cpp:52] Attempting to upgrade input file specified using deprecated V1LayerParameter: /home/workspace/bvlc_googlenet.caffemodel
I0810 21:05:21.738194   463 upgrade_proto.cpp:60] Successfully upgraded file specified using deprecated V1LayerParameter
I0810 21:05:21.738436   463 net.cpp:791] Ignoring source layer data
I0810 21:05:21.738446   463 net.cpp:791] Ignoring source layer label_data_1_split
I0810 21:05:21.739524   463 net.cpp:791] Ignoring source layer loss1/ave_pool
I0810 21:05:21.739533   463 net.cpp:791] Ignoring source layer loss1/conv
I0810 21:05:21.739539   463 net.cpp:791] Ignoring source layer loss1/relu_conv
I0810 21:05:21.739545   463 net.cpp:791] Ignoring source layer loss1/fc
I0810 21:05:21.739552   463 net.cpp:791] Ignoring source layer loss1/relu_fc
I0810 21:05:21.739557   463 net.cpp:791] Ignoring source layer loss1/drop_fc
I0810 21:05:21.739567   463 net.cpp:791] Ignoring source layer loss1/classifier
I0810 21:05:21.739573   463 net.cpp:791] Ignoring source layer loss1/loss
I0810 21:05:21.741134   463 net.cpp:791] Ignoring source layer loss2/ave_pool
I0810 21:05:21.741143   463 net.cpp:791] Ignoring source layer loss2/conv
I0810 21:05:21.741150   463 net.cpp:791] Ignoring source layer loss2/relu_conv
I0810 21:05:21.741155   463 net.cpp:791] Ignoring source layer loss2/fc
I0810 21:05:21.741161   463 net.cpp:791] Ignoring source layer loss2/relu_fc
I0810 21:05:21.741168   463 net.cpp:791] Ignoring source layer loss2/drop_fc
I0810 21:05:21.741173   463 net.cpp:791] Ignoring source layer loss2/classifier
I0810 21:05:21.741179   463 net.cpp:791] Ignoring source layer loss2/loss
I0810 21:05:21.742007   463 net.cpp:791] Ignoring source layer pool4/3x3_s2
I0810 21:05:21.742014   463 net.cpp:791] Ignoring source layer pool4/3x3_s2_pool4/3x3_s2_0_split
I0810 21:05:21.744453   463 net.cpp:791] Ignoring source layer pool5/7x7_s1
I0810 21:05:21.744463   463 net.cpp:791] Ignoring source layer pool5/drop_7x7_s1
I0810 21:05:21.744469   463 net.cpp:791] Ignoring source layer loss3/classifier
I0810 21:05:21.744475   463 net.cpp:791] Ignoring source layer loss3/loss3
I0810 21:05:21.804745   463 upgrade_proto.cpp:52] Attempting to upgrade input file specified using deprecated V1LayerParameter: /home/workspace/bvlc_googlenet.caffemodel
I0810 21:05:21.888798   463 upgrade_proto.cpp:60] Successfully upgraded file specified using deprecated V1LayerParameter
I0810 21:05:21.889065   463 net.cpp:791] Ignoring source layer data
I0810 21:05:21.889076   463 net.cpp:791] Ignoring source layer label_data_1_split
I0810 21:05:21.890200   463 net.cpp:791] Ignoring source layer loss1/ave_pool
I0810 21:05:21.890215   463 net.cpp:791] Ignoring source layer loss1/conv
I0810 21:05:21.890223   463 net.cpp:791] Ignoring source layer loss1/relu_conv
I0810 21:05:21.890228   463 net.cpp:791] Ignoring source layer loss1/fc
I0810 21:05:21.890234   463 net.cpp:791] Ignoring source layer loss1/relu_fc
I0810 21:05:21.890240   463 net.cpp:791] Ignoring source layer loss1/drop_fc
I0810 21:05:21.890247   463 net.cpp:791] Ignoring source layer loss1/classifier
I0810 21:05:21.890255   463 net.cpp:791] Ignoring source layer loss1/loss
I0810 21:05:21.891794   463 net.cpp:791] Ignoring source layer loss2/ave_pool
I0810 21:05:21.891806   463 net.cpp:791] Ignoring source layer loss2/conv
I0810 21:05:21.891813   463 net.cpp:791] Ignoring source layer loss2/relu_conv
I0810 21:05:21.891849   463 net.cpp:791] Ignoring source layer loss2/fc
I0810 21:05:21.891856   463 net.cpp:791] Ignoring source layer loss2/relu_fc
I0810 21:05:21.891862   463 net.cpp:791] Ignoring source layer loss2/drop_fc
I0810 21:05:21.891868   463 net.cpp:791] Ignoring source layer loss2/classifier
I0810 21:05:21.891875   463 net.cpp:791] Ignoring source layer loss2/loss
I0810 21:05:21.892715   463 net.cpp:791] Ignoring source layer pool4/3x3_s2
I0810 21:05:21.892724   463 net.cpp:791] Ignoring source layer pool4/3x3_s2_pool4/3x3_s2_0_split
I0810 21:05:21.895083   463 net.cpp:791] Ignoring source layer pool5/7x7_s1
I0810 21:05:21.895104   463 net.cpp:791] Ignoring source layer pool5/drop_7x7_s1
I0810 21:05:21.895112   463 net.cpp:791] Ignoring source layer loss3/classifier
I0810 21:05:21.895117   463 net.cpp:791] Ignoring source layer loss3/loss3
I0810 21:05:21.900478   463 caffe.cpp:231] Starting Optimization
I0810 21:05:21.900503   463 solver.cpp:304] Solving
I0810 21:05:21.900511   463 solver.cpp:305] Learning Rate Policy: step
I0810 21:05:21.908710   463 solver.cpp:362] Iteration 0, Testing net (#0)
I0810 21:05:21.908735   463 net.cpp:723] Ignoring source layer train_data
I0810 21:05:21.908741   463 net.cpp:723] Ignoring source layer train_label
I0810 21:05:21.908747   463 net.cpp:723] Ignoring source layer train_transform
I0810 21:05:34.107975   463 solver.cpp:429]     Test net output #0: loss_bbox = 1.53959 (* 2 = 3.07918 loss)
I0810 21:05:34.108016   463 solver.cpp:429]     Test net output #1: loss_coverage = 292.596 (* 1 = 292.596 loss)
I0810 21:05:34.108026   463 solver.cpp:429]     Test net output #2: mAP = 0
I0810 21:05:34.108033   463 solver.cpp:429]     Test net output #3: precision = 0
I0810 21:05:34.108041   463 solver.cpp:429]     Test net output #4: recall = 0
I0810 21:05:35.313477   463 solver.cpp:242] Iteration 0 (0 iter/s, 13.413s/22 iter), loss = 317.161
I0810 21:05:35.313537   463 solver.cpp:261]     Train net output #0: loss_bbox = 0.778369 (* 2 = 1.55674 loss)
I0810 21:05:35.313551   463 solver.cpp:261]     Train net output #1: loss_coverage = 315.604 (* 1 = 315.604 loss)
I0810 21:05:35.313576   463 sgd_solver.cpp:106] Iteration 0, lr = 1e-05
I0810 21:06:00.780325   463 solver.cpp:242] Iteration 22 (0.863865 iter/s, 25.4669s/22 iter), loss = 47.7659
I0810 21:06:00.780478   463 solver.cpp:261]     Train net output #0: loss_bbox = 2.05174 (* 2 = 4.10349 loss)
I0810 21:06:00.780493   463 solver.cpp:261]     Train net output #1: loss_coverage = 43.6624 (* 1 = 43.6624 loss)
I0810 21:06:00.780511   463 sgd_solver.cpp:106] Iteration 22, lr = 1e-05
I0810 21:06:26.260043   463 solver.cpp:242] Iteration 44 (0.863431 iter/s, 25.4797s/22 iter), loss = 23.6023
I0810 21:06:26.260102   463 solver.cpp:261]     Train net output #0: loss_bbox = 1.29429 (* 2 = 2.58859 loss)
I0810 21:06:26.260118   463 solver.cpp:261]     Train net output #1: loss_coverage = 21.0137 (* 1 = 21.0137 loss)
I0810 21:06:26.260134   463 sgd_solver.cpp:106] Iteration 44, lr = 1e-05
I0810 21:06:51.687448   463 solver.cpp:242] Iteration 66 (0.865205 iter/s, 25.4275s/22 iter), loss = 31.5935
I0810 21:06:51.687536   463 solver.cpp:261]     Train net output #0: loss_bbox = 1.75023 (* 2 = 3.50047 loss)
I0810 21:06:51.687551   463 solver.cpp:261]     Train net output #1: loss_coverage = 28.0931 (* 1 = 28.0931 loss)
I0810 21:06:51.687566   463 sgd_solver.cpp:106] Iteration 66, lr = 1e-05
I0810 21:07:17.133553   463 solver.cpp:242] Iteration 88 (0.86457 iter/s, 25.4462s/22 iter), loss = 21.4656
I0810 21:07:17.133615   463 solver.cpp:261]     Train net output #0: loss_bbox = 1.75416 (* 2 = 3.50831 loss)
I0810 21:07:17.133637   463 solver.cpp:261]     Train net output #1: loss_coverage = 17.9572 (* 1 = 17.9572 loss)
I0810 21:07:17.133658   463 sgd_solver.cpp:106] Iteration 88, lr = 1e-05
I0810 21:07:42.546110   463 solver.cpp:242] Iteration 110 (0.86571 iter/s, 25.4127s/22 iter), loss = 19.2271
I0810 21:07:42.546335   463 solver.cpp:261]     Train net output #0: loss_bbox = 1.48245 (* 2 = 2.96491 loss)
I0810 21:07:42.546353   463 solver.cpp:261]     Train net output #1: loss_coverage = 16.2622 (* 1 = 16.2622 loss)
I0810 21:07:42.546371   463 sgd_solver.cpp:106] Iteration 110, lr = 1e-05
I0810 21:08:07.950646   463 solver.cpp:242] Iteration 132 (0.865989 iter/s, 25.4045s/22 iter), loss = 14.8579
I0810 21:08:07.950708   463 solver.cpp:261]     Train net output #0: loss_bbox = 1.21548 (* 2 = 2.43097 loss)
I0810 21:08:07.950721   463 solver.cpp:261]     Train net output #1: loss_coverage = 12.427 (* 1 = 12.427 loss)
I0810 21:08:07.950738   463 sgd_solver.cpp:106] Iteration 132, lr = 1e-05
I0810 21:08:33.351357   463 solver.cpp:242] Iteration 154 (0.866114 iter/s, 25.4008s/22 iter), loss = 15.8067
I0810 21:08:33.351632   463 solver.cpp:261]     Train net output #0: loss_bbox = 1.35654 (* 2 = 2.71309 loss)
I0810 21:08:33.351655   463 solver.cpp:261]     Train net output #1: loss_coverage = 13.0936 (* 1 = 13.0936 loss)
I0810 21:08:33.351675   463 sgd_solver.cpp:106] Iteration 154, lr = 1e-05
I0810 21:08:58.729519   463 solver.cpp:242] Iteration 176 (0.866891 iter/s, 25.3781s/22 iter), loss = 12.7963
I0810 21:08:58.729583   463 solver.cpp:261]     Train net output #0: loss_bbox = 1.45003 (* 2 = 2.90006 loss)
I0810 21:08:58.729598   463 solver.cpp:261]     Train net output #1: loss_coverage = 9.8962 (* 1 = 9.8962 loss)
I0810 21:08:58.729614   463 sgd_solver.cpp:106] Iteration 176, lr = 1e-05
I0810 21:08:59.880585   463 solver.cpp:479] Snapshotting to binary proto file snapshot_iter_178.caffemodel
I0810 21:09:00.060483   463 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshot_iter_178.solverstate
I0810 21:09:00.116037   463 solver.cpp:362] Iteration 178, Testing net (#0)
I0810 21:09:00.116068   463 net.cpp:723] Ignoring source layer train_data
I0810 21:09:00.116075   463 net.cpp:723] Ignoring source layer train_label
I0810 21:09:00.116080   463 net.cpp:723] Ignoring source layer train_transform
I0810 21:09:11.068392   463 solver.cpp:429]     Test net output #0: loss_bbox = 1.53092 (* 2 = 3.06184 loss)
I0810 21:09:11.068650   463 solver.cpp:429]     Test net output #1: loss_coverage = 7.38495 (* 1 = 7.38495 loss)
I0810 21:09:11.068665   463 solver.cpp:429]     Test net output #2: mAP = 0
I0810 21:09:11.068673   463 solver.cpp:429]     Test net output #3: precision = 0
I0810 21:09:11.068681   463 solver.cpp:429]     Test net output #4: recall = 0
I0810 21:09:35.322458   463 solver.cpp:242] Iteration 198 (0.601206 iter/s, 36.5931s/22 iter), loss = 9.23296
I0810 21:09:35.322520   463 solver.cpp:261]     Train net output #0: loss_bbox = 1.02239 (* 2 = 2.04478 loss)
I0810 21:09:35.322535   463 solver.cpp:261]     Train net output #1: loss_coverage = 7.18818 (* 1 = 7.18818 loss)
I0810 21:09:35.322553   463 sgd_solver.cpp:106] Iteration 198, lr = 1e-05
I0810 21:10:00.732766   463 solver.cpp:242] Iteration 220 (0.865787 iter/s, 25.4104s/22 iter), loss = 9.20727
I0810 21:10:00.733036   463 solver.cpp:261]     Train net output #0: loss_bbox = 0.710021 (* 2 = 1.42004 loss)
I0810 21:10:00.733052   463 solver.cpp:261]     Train net output #1: loss_coverage = 7.78722 (* 1 = 7.78722 loss)
I0810 21:10:00.733070   463 sgd_solver.cpp:106] Iteration 220, lr = 1e-05
I0810 21:10:26.179996   463 solver.cpp:242] Iteration 242 (0.864538 iter/s, 25.4471s/22 iter), loss = 7.42589
I0810 21:10:26.180054   463 solver.cpp:261]     Train net output #0: loss_bbox = 0.995542 (* 2 = 1.99108 loss)
I0810 21:10:26.180068   463 solver.cpp:261]     Train net output #1: loss_coverage = 5.43481 (* 1 = 5.43481 loss)
I0810 21:10:26.180085   463 sgd_solver.cpp:106] Iteration 242, lr = 1e-05
I0810 21:10:51.593156   463 solver.cpp:242] Iteration 264 (0.865691 iter/s, 25.4132s/22 iter), loss = 13.255
I0810 21:10:51.593449   463 solver.cpp:261]     Train net output #0: loss_bbox = 0.921591 (* 2 = 1.84318 loss)
I0810 21:10:51.593467   463 solver.cpp:261]     Train net output #1: loss_coverage = 11.4118 (* 1 = 11.4118 loss)
I0810 21:10:51.593485   463 sgd_solver.cpp:106] Iteration 264, lr = 1e-05
I0810 21:11:17.010412   463 solver.cpp:242] Iteration 286 (0.865558 iter/s, 25.4171s/22 iter), loss = 15.6872
I0810 21:11:17.010474   463 solver.cpp:261]     Train net output #0: loss_bbox = 1.7907 (* 2 = 3.58141 loss)
I0810 21:11:17.010488   463 solver.cpp:261]     Train net output #1: loss_coverage = 12.1058 (* 1 = 12.1058 loss)
I0810 21:11:17.010507   463 sgd_solver.cpp:106] Iteration 286, lr = 1e-05
I0810 21:11:42.424856   463 solver.cpp:242] Iteration 308 (0.865646 iter/s, 25.4145s/22 iter), loss = 15.6898
I0810 21:11:42.425175   463 solver.cpp:261]     Train net output #0: loss_bbox = 1.22891 (* 2 = 2.45783 loss)
I0810 21:11:42.425194   463 solver.cpp:261]     Train net output #1: loss_coverage = 13.232 (* 1 = 13.232 loss)
I0810 21:11:42.425213   463 sgd_solver.cpp:106] Iteration 308, lr = 1e-05
I0810 21:12:07.837105   463 solver.cpp:242] Iteration 330 (0.86573 iter/s, 25.4121s/22 iter), loss = 8.48524
I0810 21:12:07.837185   463 solver.cpp:261]     Train net output #0: loss_bbox = 0.972633 (* 2 = 1.94527 loss)
I0810 21:12:07.837199   463 solver.cpp:261]     Train net output #1: loss_coverage = 6.53997 (* 1 = 6.53997 loss)
I0810 21:12:07.837218   463 sgd_solver.cpp:106] Iteration 330, lr = 1e-05
I0810 21:12:33.299329   463 solver.cpp:242] Iteration 352 (0.864022 iter/s, 25.4623s/22 iter), loss = 18.371
I0810 21:12:33.299574   463 solver.cpp:261]     Train net output #0: loss_bbox = 1.02611 (* 2 = 2.05223 loss)
I0810 21:12:33.299590   463 solver.cpp:261]     Train net output #1: loss_coverage = 16.3187 (* 1 = 16.3187 loss)
I0810 21:12:33.299615   463 sgd_solver.cpp:106] Iteration 352, lr = 1e-05
I0810 21:12:36.751449   463 solver.cpp:479] Snapshotting to binary proto file snapshot_iter_356.caffemodel
I0810 21:12:36.853443   463 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshot_iter_356.solverstate
I0810 21:12:36.909644   463 solver.cpp:362] Iteration 356, Testing net (#0)
I0810 21:12:36.909675   463 net.cpp:723] Ignoring source layer train_data
I0810 21:12:36.909682   463 net.cpp:723] Ignoring source layer train_label
I0810 21:12:36.909688   463 net.cpp:723] Ignoring source layer train_transform
I0810 21:12:47.843611   463 solver.cpp:429]     Test net output #0: loss_bbox = 1.51209 (* 2 = 3.02418 loss)
I0810 21:12:47.843647   463 solver.cpp:429]     Test net output #1: loss_coverage = 6.39902 (* 1 = 6.39902 loss)
I0810 21:12:47.843657   463 solver.cpp:429]     Test net output #2: mAP = 0
I0810 21:12:47.843664   463 solver.cpp:429]     Test net output #3: precision = 0
I0810 21:12:47.843672   463 solver.cpp:429]     Test net output #4: recall = 0
I0810 21:13:09.777665   463 solver.cpp:242] Iteration 374 (0.603098 iter/s, 36.4783s/22 iter), loss = 9.02573
I0810 21:13:09.777819   463 solver.cpp:261]     Train net output #0: loss_bbox = 1.30277 (* 2 = 2.60555 loss)
I0810 21:13:09.777834   463 solver.cpp:261]     Train net output #1: loss_coverage = 6.42018 (* 1 = 6.42018 loss)
I0810 21:13:09.777853   463 sgd_solver.cpp:106] Iteration 374, lr = 1e-05
I0810 21:13:35.182993   463 solver.cpp:242] Iteration 396 (0.86596 iter/s, 25.4053s/22 iter), loss = 14.2614
I0810 21:13:35.183055   463 solver.cpp:261]     Train net output #0: loss_bbox = 1.27086 (* 2 = 2.54173 loss)
I0810 21:13:35.183068   463 solver.cpp:261]     Train net output #1: loss_coverage = 11.7197 (* 1 = 11.7197 loss)
I0810 21:13:35.183089   463 sgd_solver.cpp:106] Iteration 396, lr = 1e-05
I0810 21:14:00.588737   463 solver.cpp:242] Iteration 418 (0.865942 iter/s, 25.4058s/22 iter), loss = 14.9512
I0810 21:14:00.588973   463 solver.cpp:261]     Train net output #0: loss_bbox = 1.22368 (* 2 = 2.44735 loss)
I0810 21:14:00.588989   463 solver.cpp:261]     Train net output #1: loss_coverage = 12.5038 (* 1 = 12.5038 loss)
I0810 21:14:00.589006   463 sgd_solver.cpp:106] Iteration 418, lr = 1e-05
I0810 21:14:26.009735   463 solver.cpp:242] Iteration 440 (0.865429 iter/s, 25.4209s/22 iter), loss = 17.8854
I0810 21:14:26.009797   463 solver.cpp:261]     Train net output #0: loss_bbox = 1.48589 (* 2 = 2.97178 loss)
I0810 21:14:26.009811   463 solver.cpp:261]     Train net output #1: loss_coverage = 14.9136 (* 1 = 14.9136 loss)
I0810 21:14:26.009829   463 sgd_solver.cpp:106] Iteration 440, lr = 1e-05
I0810 21:14:51.416007   463 solver.cpp:242] Iteration 462 (0.865925 iter/s, 25.4064s/22 iter), loss = 10.8976
I0810 21:14:51.416151   463 solver.cpp:261]     Train net output #0: loss_bbox = 1.22725 (* 2 = 2.45451 loss)
I0810 21:14:51.416165   463 solver.cpp:261]     Train net output #1: loss_coverage = 8.44306 (* 1 = 8.44306 loss)
I0810 21:14:51.416183   463 sgd_solver.cpp:106] Iteration 462, lr = 1e-05
I0810 21:15:16.834539   463 solver.cpp:242] Iteration 484 (0.86551 iter/s, 25.4185s/22 iter), loss = 13.2154
I0810 21:15:16.834625   463 solver.cpp:261]     Train net output #0: loss_bbox = 1.80815 (* 2 = 3.61629 loss)
I0810 21:15:16.834640   463 solver.cpp:261]     Train net output #1: loss_coverage = 9.59911 (* 1 = 9.59911 loss)
I0810 21:15:16.834656   463 sgd_solver.cpp:106] Iteration 484, lr = 1e-05
I0810 21:15:42.275216   463 solver.cpp:242] Iteration 506 (0.864754 iter/s, 25.4408s/22 iter), loss = 20.0427
I0810 21:15:42.275496   463 solver.cpp:261]     Train net output #0: loss_bbox = 1.71501 (* 2 = 3.43002 loss)
I0810 21:15:42.275512   463 solver.cpp:261]     Train net output #1: loss_coverage = 16.6127 (* 1 = 16.6127 loss)
I0810 21:15:42.275532   463 sgd_solver.cpp:106] Iteration 506, lr = 1e-05
I0810 21:16:07.685709   463 solver.cpp:242] Iteration 528 (0.865788 iter/s, 25.4104s/22 iter), loss = 15.0805
I0810 21:16:07.685770   463 solver.cpp:261]     Train net output #0: loss_bbox = 1.45097 (* 2 = 2.90194 loss)
I0810 21:16:07.685782   463 solver.cpp:261]     Train net output #1: loss_coverage = 12.1786 (* 1 = 12.1786 loss)
I0810 21:16:07.685799   463 sgd_solver.cpp:106] Iteration 528, lr = 1e-05
I0810 21:16:13.453711   463 solver.cpp:479] Snapshotting to binary proto file snapshot_iter_534.caffemodel
I0810 21:16:13.554584   463 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshot_iter_534.solverstate
I0810 21:16:13.611007   463 solver.cpp:362] Iteration 534, Testing net (#0)
I0810 21:16:13.611035   463 net.cpp:723] Ignoring source layer train_data
I0810 21:16:13.611043   463 net.cpp:723] Ignoring source layer train_label
I0810 21:16:13.611049   463 net.cpp:723] Ignoring source layer train_transform
I0810 21:16:24.545027   463 solver.cpp:429]     Test net output #0: loss_bbox = 1.50353 (* 2 = 3.00706 loss)
I0810 21:16:24.545059   463 solver.cpp:429]     Test net output #1: loss_coverage = 6.67737 (* 1 = 6.67737 loss)
I0810 21:16:24.545078   463 solver.cpp:429]     Test net output #2: mAP = 0
I0810 21:16:24.545087   463 solver.cpp:429]     Test net output #3: precision = 0
I0810 21:16:24.545094   463 solver.cpp:429]     Test net output #4: recall = 0
I0810 21:16:44.197741   463 solver.cpp:242] Iteration 550 (0.602538 iter/s, 36.5122s/22 iter), loss = 9.30568
I0810 21:16:44.198053   463 solver.cpp:261]     Train net output #0: loss_bbox = 1.47183 (* 2 = 2.94367 loss)
I0810 21:16:44.198073   463 solver.cpp:261]     Train net output #1: loss_coverage = 6.36202 (* 1 = 6.36202 loss)
I0810 21:16:44.198096   463 sgd_solver.cpp:106] Iteration 550, lr = 1e-05
I0810 21:17:09.634121   463 solver.cpp:242] Iteration 572 (0.864908 iter/s, 25.4362s/22 iter), loss = 8.41178
I0810 21:17:09.634207   463 solver.cpp:261]     Train net output #0: loss_bbox = 1.0249 (* 2 = 2.0498 loss)
I0810 21:17:09.634220   463 solver.cpp:261]     Train net output #1: loss_coverage = 6.36198 (* 1 = 6.36198 loss)
I0810 21:17:09.634236   463 sgd_solver.cpp:106] Iteration 572, lr = 1e-05
I0810 21:17:35.054126   463 solver.cpp:242] Iteration 594 (0.865458 iter/s, 25.4201s/22 iter), loss = 12.5911
I0810 21:17:35.054260   463 solver.cpp:261]     Train net output #0: loss_bbox = 0.899319 (* 2 = 1.79864 loss)
I0810 21:17:35.054275   463 solver.cpp:261]     Train net output #1: loss_coverage = 10.7925 (* 1 = 10.7925 loss)
I0810 21:17:35.054296   463 sgd_solver.cpp:106] Iteration 594, lr = 1e-05
I0810 21:18:00.443287   463 solver.cpp:242] Iteration 616 (0.866511 iter/s, 25.3892s/22 iter), loss = 15.405
I0810 21:18:00.443344   463 solver.cpp:261]     Train net output #0: loss_bbox = 1.95295 (* 2 = 3.90591 loss)
I0810 21:18:00.443357   463 solver.cpp:261]     Train net output #1: loss_coverage = 11.4991 (* 1 = 11.4991 loss)
I0810 21:18:00.443373   463 sgd_solver.cpp:106] Iteration 616, lr = 1e-05
I0810 21:18:25.845397   463 solver.cpp:242] Iteration 638 (0.866066 iter/s, 25.4022s/22 iter), loss = 10.1916
I0810 21:18:25.845731   463 solver.cpp:261]     Train net output #0: loss_bbox = 1.26592 (* 2 = 2.53184 loss)
I0810 21:18:25.845748   463 solver.cpp:261]     Train net output #1: loss_coverage = 7.65976 (* 1 = 7.65976 loss)
I0810 21:18:25.845767   463 sgd_solver.cpp:106] Iteration 638, lr = 1e-05
I0810 21:18:51.251509   463 solver.cpp:242] Iteration 660 (0.865939 iter/s, 25.4059s/22 iter), loss = 12.857
I0810 21:18:51.251576   463 solver.cpp:261]     Train net output #0: loss_bbox = 1.53108 (* 2 = 3.06216 loss)
I0810 21:18:51.251590   463 solver.cpp:261]     Train net output #1: loss_coverage = 9.7948 (* 1 = 9.7948 loss)
I0810 21:18:51.251617   463 sgd_solver.cpp:106] Iteration 660, lr = 1e-05
I0810 21:19:16.681919   463 solver.cpp:242] Iteration 682 (0.865103 iter/s, 25.4305s/22 iter), loss = 14.4359
I0810 21:19:16.682159   463 solver.cpp:261]     Train net output #0: loss_bbox = 1.42774 (* 2 = 2.85548 loss)
I0810 21:19:16.682179   463 solver.cpp:261]     Train net output #1: loss_coverage = 11.5804 (* 1 = 11.5804 loss)
I0810 21:19:16.682200   463 sgd_solver.cpp:106] Iteration 682, lr = 1e-05
I0810 21:19:42.064653   463 solver.cpp:242] Iteration 704 (0.866734 iter/s, 25.3827s/22 iter), loss = 5.37883
I0810 21:19:42.064708   463 solver.cpp:261]     Train net output #0: loss_bbox = 0.923431 (* 2 = 1.84686 loss)
I0810 21:19:42.064721   463 solver.cpp:261]     Train net output #1: loss_coverage = 3.53196 (* 1 = 3.53196 loss)
I0810 21:19:42.064738   463 sgd_solver.cpp:106] Iteration 704, lr = 1e-05
I0810 21:19:50.155156   463 solver.cpp:479] Snapshotting to binary proto file snapshot_iter_712.caffemodel
I0810 21:19:50.261413   463 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshot_iter_712.solverstate
I0810 21:19:50.317701   463 solver.cpp:362] Iteration 712, Testing net (#0)
I0810 21:19:50.317737   463 net.cpp:723] Ignoring source layer train_data
I0810 21:19:50.317745   463 net.cpp:723] Ignoring source layer train_label
I0810 21:19:50.317752   463 net.cpp:723] Ignoring source layer train_transform
I0810 21:20:01.276624   463 solver.cpp:429]     Test net output #0: loss_bbox = 1.48887 (* 2 = 2.97774 loss)
I0810 21:20:01.276659   463 solver.cpp:429]     Test net output #1: loss_coverage = 6.93797 (* 1 = 6.93797 loss)
I0810 21:20:01.276667   463 solver.cpp:429]     Test net output #2: mAP = 0
I0810 21:20:01.276675   463 solver.cpp:429]     Test net output #3: precision = 0
I0810 21:20:01.276682   463 solver.cpp:429]     Test net output #4: recall = 0
I0810 21:20:18.580004   463 solver.cpp:242] Iteration 726 (0.602483 iter/s, 36.5155s/22 iter), loss = 4.82209
I0810 21:20:18.580073   463 solver.cpp:261]     Train net output #0: loss_bbox = 0.674341 (* 2 = 1.34868 loss)
I0810 21:20:18.580090   463 solver.cpp:261]     Train net output #1: loss_coverage = 3.47341 (* 1 = 3.47341 loss)
I0810 21:20:18.580109   463 sgd_solver.cpp:106] Iteration 726, lr = 1e-05
I0810 21:20:43.989971   463 solver.cpp:242] Iteration 748 (0.865799 iter/s, 25.4101s/22 iter), loss = 15.4758
I0810 21:20:43.990249   463 solver.cpp:261]     Train net output #0: loss_bbox = 1.99628 (* 2 = 3.99256 loss)
I0810 21:20:43.990267   463 solver.cpp:261]     Train net output #1: loss_coverage = 11.4832 (* 1 = 11.4832 loss)
I0810 21:20:43.990284   463 sgd_solver.cpp:106] Iteration 748, lr = 1e-05
I0810 21:21:09.401504   463 solver.cpp:242] Iteration 770 (0.865753 iter/s, 25.4114s/22 iter), loss = 14.2052
I0810 21:21:09.401577   463 solver.cpp:261]     Train net output #0: loss_bbox = 1.71683 (* 2 = 3.43366 loss)
I0810 21:21:09.401592   463 solver.cpp:261]     Train net output #1: loss_coverage = 10.7716 (* 1 = 10.7716 loss)
I0810 21:21:09.401610   463 sgd_solver.cpp:106] Iteration 770, lr = 1e-05
I0810 21:21:34.816900   463 solver.cpp:242] Iteration 792 (0.865615 iter/s, 25.4155s/22 iter), loss = 12.1799
I0810 21:21:34.817291   463 solver.cpp:261]     Train net output #0: loss_bbox = 1.74938 (* 2 = 3.49876 loss)
I0810 21:21:34.817312   463 solver.cpp:261]     Train net output #1: loss_coverage = 8.68112 (* 1 = 8.68112 loss)
I0810 21:21:34.817332   463 sgd_solver.cpp:106] Iteration 792, lr = 1e-05
I0810 21:22:00.236544   463 solver.cpp:242] Iteration 814 (0.86548 iter/s, 25.4194s/22 iter), loss = 8.92996
I0810 21:22:00.236625   463 solver.cpp:261]     Train net output #0: loss_bbox = 1.1451 (* 2 = 2.29021 loss)
I0810 21:22:00.236639   463 solver.cpp:261]     Train net output #1: loss_coverage = 6.63976 (* 1 = 6.63976 loss)
I0810 21:22:00.236655   463 sgd_solver.cpp:106] Iteration 814, lr = 1e-05
I0810 21:22:25.633790   463 solver.cpp:242] Iteration 836 (0.866233 iter/s, 25.3973s/22 iter), loss = 8.04438
I0810 21:22:25.634091   463 solver.cpp:261]     Train net output #0: loss_bbox = 1.55392 (* 2 = 3.10784 loss)
I0810 21:22:25.634110   463 solver.cpp:261]     Train net output #1: loss_coverage = 4.93654 (* 1 = 4.93654 loss)
I0810 21:22:25.634155   463 sgd_solver.cpp:106] Iteration 836, lr = 1e-05
I0810 21:22:51.042670   463 solver.cpp:242] Iteration 858 (0.865844 iter/s, 25.4087s/22 iter), loss = 7.06572
I0810 21:22:51.042752   463 solver.cpp:261]     Train net output #0: loss_bbox = 0.757324 (* 2 = 1.51465 loss)
I0810 21:22:51.042768   463 solver.cpp:261]     Train net output #1: loss_coverage = 5.55107 (* 1 = 5.55107 loss)
I0810 21:22:51.042786   463 sgd_solver.cpp:106] Iteration 858, lr = 1e-05
I0810 21:23:16.431797   463 solver.cpp:242] Iteration 880 (0.86651 iter/s, 25.3892s/22 iter), loss = 9.75861
I0810 21:23:16.431999   463 solver.cpp:261]     Train net output #0: loss_bbox = 1.33571 (* 2 = 2.67141 loss)
I0810 21:23:16.432015   463 solver.cpp:261]     Train net output #1: loss_coverage = 7.0872 (* 1 = 7.0872 loss)
I0810 21:23:16.432034   463 sgd_solver.cpp:106] Iteration 880, lr = 1e-05
I0810 21:23:26.825636   463 solver.cpp:479] Snapshotting to binary proto file snapshot_iter_890.caffemodel
I0810 21:23:26.931597   463 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshot_iter_890.solverstate
I0810 21:23:26.988783   463 solver.cpp:362] Iteration 890, Testing net (#0)
I0810 21:23:26.988852   463 net.cpp:723] Ignoring source layer train_data
I0810 21:23:26.988862   463 net.cpp:723] Ignoring source layer train_label
I0810 21:23:26.988870   463 net.cpp:723] Ignoring source layer train_transform
I0810 21:23:37.950289   463 solver.cpp:429]     Test net output #0: loss_bbox = 1.49665 (* 2 = 2.99331 loss)
I0810 21:23:37.950323   463 solver.cpp:429]     Test net output #1: loss_coverage = 6.20766 (* 1 = 6.20766 loss)
I0810 21:23:37.950332   463 solver.cpp:429]     Test net output #2: mAP = 0
I0810 21:23:37.950340   463 solver.cpp:429]     Test net output #3: precision = 0
I0810 21:23:37.950347   463 solver.cpp:429]     Test net output #4: recall = 0
I0810 21:23:52.982954   463 solver.cpp:242] Iteration 902 (0.601895 iter/s, 36.5512s/22 iter), loss = 15.3698
I0810 21:23:52.983239   463 solver.cpp:261]     Train net output #0: loss_bbox = 1.748 (* 2 = 3.49599 loss)
I0810 21:23:52.983259   463 solver.cpp:261]     Train net output #1: loss_coverage = 11.8738 (* 1 = 11.8738 loss)
I0810 21:23:52.983281   463 sgd_solver.cpp:106] Iteration 902, lr = 1e-05
I0810 21:24:18.379601   463 solver.cpp:242] Iteration 924 (0.86626 iter/s, 25.3965s/22 iter), loss = 5.16458
I0810 21:24:18.379663   463 solver.cpp:261]     Train net output #0: loss_bbox = 0.994865 (* 2 = 1.98973 loss)
I0810 21:24:18.379678   463 solver.cpp:261]     Train net output #1: loss_coverage = 3.17484 (* 1 = 3.17484 loss)
I0810 21:24:18.379693   463 sgd_solver.cpp:106] Iteration 924, lr = 1e-05
I0810 21:24:43.763000   463 solver.cpp:242] Iteration 946 (0.866705 iter/s, 25.3835s/22 iter), loss = 9.35428
I0810 21:24:43.763260   463 solver.cpp:261]     Train net output #0: loss_bbox = 1.59125 (* 2 = 3.1825 loss)
I0810 21:24:43.763278   463 solver.cpp:261]     Train net output #1: loss_coverage = 6.17178 (* 1 = 6.17178 loss)
I0810 21:24:43.763295   463 sgd_solver.cpp:106] Iteration 946, lr = 1e-05
I0810 21:25:09.160248   463 solver.cpp:242] Iteration 968 (0.86624 iter/s, 25.3971s/22 iter), loss = 7.6154
I0810 21:25:09.160313   463 solver.cpp:261]     Train net output #0: loss_bbox = 1.2809 (* 2 = 2.56181 loss)
I0810 21:25:09.160327   463 solver.cpp:261]     Train net output #1: loss_coverage = 5.05359 (* 1 = 5.05359 loss)
I0810 21:25:09.160344   463 sgd_solver.cpp:106] Iteration 968, lr = 1e-05
I0810 21:25:34.585935   463 solver.cpp:242] Iteration 990 (0.865263 iter/s, 25.4258s/22 iter), loss = 10.0057
I0810 21:25:34.586043   463 solver.cpp:261]     Train net output #0: loss_bbox = 1.60424 (* 2 = 3.20848 loss)
I0810 21:25:34.586057   463 solver.cpp:261]     Train net output #1: loss_coverage = 6.79719 (* 1 = 6.79719 loss)
I0810 21:25:34.586076   463 sgd_solver.cpp:106] Iteration 990, lr = 1e-05
I0810 21:25:59.993224   463 solver.cpp:242] Iteration 1012 (0.865891 iter/s, 25.4073s/22 iter), loss = 11.182
I0810 21:25:59.993281   463 solver.cpp:261]     Train net output #0: loss_bbox = 1.72369 (* 2 = 3.44738 loss)
I0810 21:25:59.993294   463 solver.cpp:261]     Train net output #1: loss_coverage = 7.73459 (* 1 = 7.73459 loss)
I0810 21:25:59.993311   463 sgd_solver.cpp:106] Iteration 1012, lr = 1e-05
I0810 21:26:25.396497   463 solver.cpp:242] Iteration 1034 (0.866027 iter/s, 25.4034s/22 iter), loss = 8.23224
I0810 21:26:25.396757   463 solver.cpp:261]     Train net output #0: loss_bbox = 1.21219 (* 2 = 2.42438 loss)
I0810 21:26:25.396785   463 solver.cpp:261]     Train net output #1: loss_coverage = 5.80786 (* 1 = 5.80786 loss)
I0810 21:26:25.396814   463 sgd_solver.cpp:106] Iteration 1034, lr = 1e-05
I0810 21:26:50.795534   463 solver.cpp:242] Iteration 1056 (0.866178 iter/s, 25.3989s/22 iter), loss = 11.2425
I0810 21:26:50.795600   463 solver.cpp:261]     Train net output #0: loss_bbox = 1.73825 (* 2 = 3.4765 loss)
I0810 21:26:50.795615   463 solver.cpp:261]     Train net output #1: loss_coverage = 7.766 (* 1 = 7.766 loss)
I0810 21:26:50.795632   463 sgd_solver.cpp:106] Iteration 1056, lr = 1e-05
I0810 21:27:03.527253   463 solver.cpp:479] Snapshotting to binary proto file snapshot_iter_1068.caffemodel
I0810 21:27:03.625651   463 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshot_iter_1068.solverstate
I0810 21:27:03.680480   463 solver.cpp:362] Iteration 1068, Testing net (#0)
I0810 21:27:03.680512   463 net.cpp:723] Ignoring source layer train_data
I0810 21:27:03.680521   463 net.cpp:723] Ignoring source layer train_label
I0810 21:27:03.680526   463 net.cpp:723] Ignoring source layer train_transform
I0810 21:27:14.639874   463 solver.cpp:429]     Test net output #0: loss_bbox = 1.48799 (* 2 = 2.97598 loss)
I0810 21:27:14.639910   463 solver.cpp:429]     Test net output #1: loss_coverage = 5.85816 (* 1 = 5.85816 loss)
I0810 21:27:14.639919   463 solver.cpp:429]     Test net output #2: mAP = 0
I0810 21:27:14.639927   463 solver.cpp:429]     Test net output #3: precision = 0
I0810 21:27:14.639935   463 solver.cpp:429]     Test net output #4: recall = 0
I0810 21:27:27.335090   463 solver.cpp:242] Iteration 1078 (0.602084 iter/s, 36.5397s/22 iter), loss = 10.9551
I0810 21:27:27.335149   463 solver.cpp:261]     Train net output #0: loss_bbox = 1.86583 (* 2 = 3.73166 loss)
I0810 21:27:27.335162   463 solver.cpp:261]     Train net output #1: loss_coverage = 7.22346 (* 1 = 7.22346 loss)
I0810 21:27:27.335178   463 sgd_solver.cpp:106] Iteration 1078, lr = 1e-05
I0810 21:27:52.770952   463 solver.cpp:242] Iteration 1100 (0.864917 iter/s, 25.436s/22 iter), loss = 8.66099
I0810 21:27:52.771268   463 solver.cpp:261]     Train net output #0: loss_bbox = 1.44266 (* 2 = 2.88532 loss)
I0810 21:27:52.771291   463 solver.cpp:261]     Train net output #1: loss_coverage = 5.77567 (* 1 = 5.77567 loss)
I0810 21:27:52.771311   463 sgd_solver.cpp:106] Iteration 1100, lr = 1e-05
I0810 21:28:18.185832   463 solver.cpp:242] Iteration 1122 (0.86564 iter/s, 25.4147s/22 iter), loss = 7.94815
I0810 21:28:18.185887   463 solver.cpp:261]     Train net output #0: loss_bbox = 1.21119 (* 2 = 2.42238 loss)
I0810 21:28:18.185900   463 solver.cpp:261]     Train net output #1: loss_coverage = 5.52577 (* 1 = 5.52577 loss)
I0810 21:28:18.185916   463 sgd_solver.cpp:106] Iteration 1122, lr = 1e-05
I0810 21:28:43.548719   463 solver.cpp:242] Iteration 1144 (0.867406 iter/s, 25.363s/22 iter), loss = 13.5011
I0810 21:28:43.549018   463 solver.cpp:261]     Train net output #0: loss_bbox = 1.26929 (* 2 = 2.53858 loss)
I0810 21:28:43.549036   463 solver.cpp:261]     Train net output #1: loss_coverage = 10.9626 (* 1 = 10.9626 loss)
I0810 21:28:43.549055   463 sgd_solver.cpp:106] Iteration 1144, lr = 1e-05
I0810 21:29:08.938203   463 solver.cpp:242] Iteration 1166 (0.866505 iter/s, 25.3893s/22 iter), loss = 17.8254
I0810 21:29:08.938263   463 solver.cpp:261]     Train net output #0: loss_bbox = 1.67609 (* 2 = 3.35218 loss)
I0810 21:29:08.938277   463 solver.cpp:261]     Train net output #1: loss_coverage = 14.4732 (* 1 = 14.4732 loss)
I0810 21:29:08.938295   463 sgd_solver.cpp:106] Iteration 1166, lr = 1e-05
I0810 21:29:34.347990   463 solver.cpp:242] Iteration 1188 (0.865805 iter/s, 25.4099s/22 iter), loss = 14.6065
I0810 21:29:34.348287   463 solver.cpp:261]     Train net output #0: loss_bbox = 1.53994 (* 2 = 3.07987 loss)
I0810 21:29:34.348305   463 solver.cpp:261]     Train net output #1: loss_coverage = 11.5266 (* 1 = 11.5266 loss)
I0810 21:29:34.348325   463 sgd_solver.cpp:106] Iteration 1188, lr = 1e-05
I0810 21:29:59.715504   463 solver.cpp:242] Iteration 1210 (0.867255 iter/s, 25.3674s/22 iter), loss = 9.97239
I0810 21:29:59.715557   463 solver.cpp:261]     Train net output #0: loss_bbox = 1.53334 (* 2 = 3.06668 loss)
I0810 21:29:59.715570   463 solver.cpp:261]     Train net output #1: loss_coverage = 6.90571 (* 1 = 6.90571 loss)
I0810 21:29:59.715589   463 sgd_solver.cpp:106] Iteration 1210, lr = 1e-05
I0810 21:30:25.213987   463 solver.cpp:242] Iteration 1232 (0.862793 iter/s, 25.4986s/22 iter), loss = 8.92138
I0810 21:30:25.214290   463 solver.cpp:261]     Train net output #0: loss_bbox = 1.41407 (* 2 = 2.82814 loss)
I0810 21:30:25.214306   463 solver.cpp:261]     Train net output #1: loss_coverage = 6.09324 (* 1 = 6.09324 loss)
I0810 21:30:25.214324   463 sgd_solver.cpp:106] Iteration 1232, lr = 1e-05
I0810 21:30:40.216423   463 solver.cpp:479] Snapshotting to binary proto file snapshot_iter_1246.caffemodel
I0810 21:30:40.326273   463 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshot_iter_1246.solverstate
I0810 21:30:40.383690   463 solver.cpp:362] Iteration 1246, Testing net (#0)
I0810 21:30:40.383726   463 net.cpp:723] Ignoring source layer train_data
I0810 21:30:40.383733   463 net.cpp:723] Ignoring source layer train_label
I0810 21:30:40.383739   463 net.cpp:723] Ignoring source layer train_transform
I0810 21:30:51.333147   463 solver.cpp:429]     Test net output #0: loss_bbox = 1.49458 (* 2 = 2.98917 loss)
I0810 21:30:51.333181   463 solver.cpp:429]     Test net output #1: loss_coverage = 5.26331 (* 1 = 5.26331 loss)
I0810 21:30:51.333189   463 solver.cpp:429]     Test net output #2: mAP = 0
I0810 21:30:51.333197   463 solver.cpp:429]     Test net output #3: precision = 0
I0810 21:30:51.333204   463 solver.cpp:429]     Test net output #4: recall = 0
I0810 21:31:01.704766   463 solver.cpp:242] Iteration 1254 (0.602893 iter/s, 36.4907s/22 iter), loss = 13.8353
I0810 21:31:01.704978   463 solver.cpp:261]     Train net output #0: loss_bbox = 1.8519 (* 2 = 3.70379 loss)
I0810 21:31:01.704994   463 solver.cpp:261]     Train net output #1: loss_coverage = 10.1315 (* 1 = 10.1315 loss)
I0810 21:31:01.705011   463 sgd_solver.cpp:106] Iteration 1254, lr = 1e-05
I0810 21:31:27.120685   463 solver.cpp:242] Iteration 1276 (0.865601 iter/s, 25.4159s/22 iter), loss = 4.88784
I0810 21:31:27.120749   463 solver.cpp:261]     Train net output #0: loss_bbox = 0.946622 (* 2 = 1.89324 loss)
I0810 21:31:27.120765   463 solver.cpp:261]     Train net output #1: loss_coverage = 2.9946 (* 1 = 2.9946 loss)
I0810 21:31:27.120785   463 sgd_solver.cpp:106] Iteration 1276, lr = 1e-05
I0810 21:31:52.508704   463 solver.cpp:242] Iteration 1298 (0.866547 iter/s, 25.3881s/22 iter), loss = 3.68499
I0810 21:31:52.509021   463 solver.cpp:261]     Train net output #0: loss_bbox = 0.525121 (* 2 = 1.05024 loss)
I0810 21:31:52.509042   463 solver.cpp:261]     Train net output #1: loss_coverage = 2.63475 (* 1 = 2.63475 loss)
I0810 21:31:52.509063   463 sgd_solver.cpp:106] Iteration 1298, lr = 1e-05
I0810 21:32:17.919445   463 solver.cpp:242] Iteration 1320 (0.865781 iter/s, 25.4106s/22 iter), loss = 10.8651
I0810 21:32:17.919515   463 solver.cpp:261]     Train net output #0: loss_bbox = 1.71286 (* 2 = 3.42571 loss)
I0810 21:32:17.919531   463 solver.cpp:261]     Train net output #1: loss_coverage = 7.43935 (* 1 = 7.43935 loss)
I0810 21:32:17.919551   463 sgd_solver.cpp:106] Iteration 1320, lr = 1e-05
I0810 21:32:43.311527   463 solver.cpp:242] Iteration 1342 (0.866409 iter/s, 25.3922s/22 iter), loss = 9.07548
I0810 21:32:43.311791   463 solver.cpp:261]     Train net output #0: loss_bbox = 1.78572 (* 2 = 3.57143 loss)
I0810 21:32:43.311811   463 solver.cpp:261]     Train net output #1: loss_coverage = 5.50404 (* 1 = 5.50404 loss)
I0810 21:32:43.311831   463 sgd_solver.cpp:106] Iteration 1342, lr = 1e-05
I0810 21:33:08.710588   463 solver.cpp:242] Iteration 1364 (0.866177 iter/s, 25.399s/22 iter), loss = 8.59675
I0810 21:33:08.710644   463 solver.cpp:261]     Train net output #0: loss_bbox = 1.77425 (* 2 = 3.54851 loss)
I0810 21:33:08.710657   463 solver.cpp:261]     Train net output #1: loss_coverage = 5.04824 (* 1 = 5.04824 loss)
I0810 21:33:08.710674   463 sgd_solver.cpp:106] Iteration 1364, lr = 1e-05
I0810 21:33:34.126842   463 solver.cpp:242] Iteration 1386 (0.865585 iter/s, 25.4163s/22 iter), loss = 7.76486
I0810 21:33:34.127055   463 solver.cpp:261]     Train net output #0: loss_bbox = 1.44187 (* 2 = 2.88373 loss)
I0810 21:33:34.127075   463 solver.cpp:261]     Train net output #1: loss_coverage = 4.88113 (* 1 = 4.88113 loss)
I0810 21:33:34.127110   463 sgd_solver.cpp:106] Iteration 1386, lr = 1e-05
I0810 21:33:59.527914   463 solver.cpp:242] Iteration 1408 (0.866107 iter/s, 25.401s/22 iter), loss = 8.47313
I0810 21:33:59.527974   463 solver.cpp:261]     Train net output #0: loss_bbox = 1.34327 (* 2 = 2.68654 loss)
I0810 21:33:59.527987   463 solver.cpp:261]     Train net output #1: loss_coverage = 5.78659 (* 1 = 5.78659 loss)
I0810 21:33:59.528005   463 sgd_solver.cpp:106] Iteration 1408, lr = 1e-05
I0810 21:34:16.800341   463 solver.cpp:479] Snapshotting to binary proto file snapshot_iter_1424.caffemodel
I0810 21:34:16.899006   463 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshot_iter_1424.solverstate
I0810 21:34:16.952163   463 solver.cpp:362] Iteration 1424, Testing net (#0)
I0810 21:34:16.952193   463 net.cpp:723] Ignoring source layer train_data
I0810 21:34:16.952200   463 net.cpp:723] Ignoring source layer train_label
I0810 21:34:16.952205   463 net.cpp:723] Ignoring source layer train_transform
I0810 21:34:27.914260   463 solver.cpp:429]     Test net output #0: loss_bbox = 1.45737 (* 2 = 2.91475 loss)
I0810 21:34:27.914296   463 solver.cpp:429]     Test net output #1: loss_coverage = 6.61333 (* 1 = 6.61333 loss)
I0810 21:34:27.914305   463 solver.cpp:429]     Test net output #2: mAP = 0
I0810 21:34:27.914314   463 solver.cpp:429]     Test net output #3: precision = 0
I0810 21:34:27.914320   463 solver.cpp:429]     Test net output #4: recall = 0
I0810 21:34:35.979687   463 solver.cpp:242] Iteration 1430 (0.603534 iter/s, 36.452s/22 iter), loss = 6.98242
I0810 21:34:35.979746   463 solver.cpp:261]     Train net output #0: loss_bbox = 1.38201 (* 2 = 2.76402 loss)
I0810 21:34:35.979760   463 solver.cpp:261]     Train net output #1: loss_coverage = 4.2184 (* 1 = 4.2184 loss)
I0810 21:34:35.979776   463 sgd_solver.cpp:106] Iteration 1430, lr = 1e-05
I0810 21:35:01.352159   463 solver.cpp:242] Iteration 1452 (0.867079 iter/s, 25.3726s/22 iter), loss = 6.76005
I0810 21:35:01.352499   463 solver.cpp:261]     Train net output #0: loss_bbox = 1.23154 (* 2 = 2.46308 loss)
I0810 21:35:01.352519   463 solver.cpp:261]     Train net output #1: loss_coverage = 4.29698 (* 1 = 4.29698 loss)
I0810 21:35:01.352555   463 sgd_solver.cpp:106] Iteration 1452, lr = 1e-05
I0810 21:35:26.729815   463 solver.cpp:242] Iteration 1474 (0.86691 iter/s, 25.3775s/22 iter), loss = 6.20104
I0810 21:35:26.729873   463 solver.cpp:261]     Train net output #0: loss_bbox = 1.04328 (* 2 = 2.08657 loss)
I0810 21:35:26.729887   463 solver.cpp:261]     Train net output #1: loss_coverage = 4.11447 (* 1 = 4.11447 loss)
I0810 21:35:26.729903   463 sgd_solver.cpp:106] Iteration 1474, lr = 1e-05
I0810 21:35:52.108922   463 solver.cpp:242] Iteration 1496 (0.866852 iter/s, 25.3792s/22 iter), loss = 8.41229
I0810 21:35:52.109212   463 solver.cpp:261]     Train net output #0: loss_bbox = 1.30947 (* 2 = 2.61894 loss)
I0810 21:35:52.109228   463 solver.cpp:261]     Train net output #1: loss_coverage = 5.79334 (* 1 = 5.79334 loss)
I0810 21:35:52.109246   463 sgd_solver.cpp:106] Iteration 1496, lr = 1e-05
I0810 21:36:17.512042   463 solver.cpp:242] Iteration 1518 (0.866041 iter/s, 25.403s/22 iter), loss = 6.26713
I0810 21:36:17.512140   463 solver.cpp:261]     Train net output #0: loss_bbox = 1.28111 (* 2 = 2.56222 loss)
I0810 21:36:17.512173   463 solver.cpp:261]     Train net output #1: loss_coverage = 3.70491 (* 1 = 3.70491 loss)
I0810 21:36:17.512212   463 sgd_solver.cpp:106] Iteration 1518, lr = 1e-05
I0810 21:36:42.889420   463 solver.cpp:242] Iteration 1540 (0.866912 iter/s, 25.3774s/22 iter), loss = 15.2221
I0810 21:36:42.889531   463 solver.cpp:261]     Train net output #0: loss_bbox = 1.87427 (* 2 = 3.74854 loss)
I0810 21:36:42.889551   463 solver.cpp:261]     Train net output #1: loss_coverage = 11.4736 (* 1 = 11.4736 loss)
I0810 21:36:42.889573   463 sgd_solver.cpp:106] Iteration 1540, lr = 1e-05
I0810 21:37:08.296669   463 solver.cpp:242] Iteration 1562 (0.865893 iter/s, 25.4073s/22 iter), loss = 11.8559
I0810 21:37:08.296726   463 solver.cpp:261]     Train net output #0: loss_bbox = 1.73336 (* 2 = 3.46672 loss)
I0810 21:37:08.296739   463 solver.cpp:261]     Train net output #1: loss_coverage = 8.38921 (* 1 = 8.38921 loss)
I0810 21:37:08.296756   463 sgd_solver.cpp:106] Iteration 1562, lr = 1e-05
I0810 21:37:33.657637   463 solver.cpp:242] Iteration 1584 (0.867471 iter/s, 25.3611s/22 iter), loss = 10.7585
I0810 21:37:33.657990   463 solver.cpp:261]     Train net output #0: loss_bbox = 1.75273 (* 2 = 3.50547 loss)
I0810 21:37:33.658012   463 solver.cpp:261]     Train net output #1: loss_coverage = 7.25298 (* 1 = 7.25298 loss)
I0810 21:37:33.658035   463 sgd_solver.cpp:106] Iteration 1584, lr = 1e-05
I0810 21:37:53.265909   463 solver.cpp:479] Snapshotting to binary proto file snapshot_iter_1602.caffemodel
I0810 21:37:53.366176   463 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshot_iter_1602.solverstate
I0810 21:37:53.420359   463 solver.cpp:362] Iteration 1602, Testing net (#0)
I0810 21:37:53.420389   463 net.cpp:723] Ignoring source layer train_data
I0810 21:37:53.420397   463 net.cpp:723] Ignoring source layer train_label
I0810 21:37:53.420403   463 net.cpp:723] Ignoring source layer train_transform
I0810 21:38:04.372359   463 solver.cpp:429]     Test net output #0: loss_bbox = 1.4619 (* 2 = 2.9238 loss)
I0810 21:38:04.372426   463 solver.cpp:429]     Test net output #1: loss_coverage = 5.14286 (* 1 = 5.14286 loss)
I0810 21:38:04.372436   463 solver.cpp:429]     Test net output #2: mAP = 0
I0810 21:38:04.372443   463 solver.cpp:429]     Test net output #3: precision = 0
I0810 21:38:04.372450   463 solver.cpp:429]     Test net output #4: recall = 0
I0810 21:38:10.130728   463 solver.cpp:242] Iteration 1606 (0.603186 iter/s, 36.473s/22 iter), loss = 8.87194
I0810 21:38:10.130789   463 solver.cpp:261]     Train net output #0: loss_bbox = 0.938716 (* 2 = 1.87743 loss)
I0810 21:38:10.130801   463 solver.cpp:261]     Train net output #1: loss_coverage = 6.99451 (* 1 = 6.99451 loss)
I0810 21:38:10.130818   463 sgd_solver.cpp:106] Iteration 1606, lr = 1e-05
I0810 21:38:35.539944   463 solver.cpp:242] Iteration 1628 (0.865824 iter/s, 25.4093s/22 iter), loss = 15.4048
I0810 21:38:35.540199   463 solver.cpp:261]     Train net output #0: loss_bbox = 1.87803 (* 2 = 3.75605 loss)
I0810 21:38:35.540217   463 solver.cpp:261]     Train net output #1: loss_coverage = 11.6488 (* 1 = 11.6488 loss)
I0810 21:38:35.540236   463 sgd_solver.cpp:106] Iteration 1628, lr = 1e-05
I0810 21:39:00.947144   463 solver.cpp:242] Iteration 1650 (0.865899 iter/s, 25.4071s/22 iter), loss = 7.84777
I0810 21:39:00.947206   463 solver.cpp:261]     Train net output #0: loss_bbox = 1.29224 (* 2 = 2.58447 loss)
I0810 21:39:00.947221   463 solver.cpp:261]     Train net output #1: loss_coverage = 5.2633 (* 1 = 5.2633 loss)
I0810 21:39:00.947237   463 sgd_solver.cpp:106] Iteration 1650, lr = 1e-05
I0810 21:39:26.350508   463 solver.cpp:242] Iteration 1672 (0.866024 iter/s, 25.4035s/22 iter), loss = 11.4184
I0810 21:39:26.350651   463 solver.cpp:261]     Train net output #0: loss_bbox = 1.98949 (* 2 = 3.97898 loss)
I0810 21:39:26.350667   463 solver.cpp:261]     Train net output #1: loss_coverage = 7.43937 (* 1 = 7.43937 loss)
I0810 21:39:26.350687   463 sgd_solver.cpp:106] Iteration 1672, lr = 1e-05
I0810 21:39:51.720824   463 solver.cpp:242] Iteration 1694 (0.867154 iter/s, 25.3703s/22 iter), loss = 12.4971
I0810 21:39:51.720876   463 solver.cpp:261]     Train net output #0: loss_bbox = 1.81749 (* 2 = 3.63499 loss)
I0810 21:39:51.720907   463 solver.cpp:261]     Train net output #1: loss_coverage = 8.86213 (* 1 = 8.86213 loss)
I0810 21:39:51.720926   463 sgd_solver.cpp:106] Iteration 1694, lr = 1e-05
I0810 21:40:17.123463   463 solver.cpp:242] Iteration 1716 (0.866048 iter/s, 25.4027s/22 iter), loss = 8.03319
I0810 21:40:17.123725   463 solver.cpp:261]     Train net output #0: loss_bbox = 1.53231 (* 2 = 3.06461 loss)
I0810 21:40:17.123741   463 solver.cpp:261]     Train net output #1: loss_coverage = 4.96857 (* 1 = 4.96857 loss)
I0810 21:40:17.123759   463 sgd_solver.cpp:106] Iteration 1716, lr = 1e-05
I0810 21:40:42.544167   463 solver.cpp:242] Iteration 1738 (0.86544 iter/s, 25.4206s/22 iter), loss = 3.91536
I0810 21:40:42.544226   463 solver.cpp:261]     Train net output #0: loss_bbox = 0.481758 (* 2 = 0.963516 loss)
I0810 21:40:42.544239   463 solver.cpp:261]     Train net output #1: loss_coverage = 2.95184 (* 1 = 2.95184 loss)
I0810 21:40:42.544256   463 sgd_solver.cpp:106] Iteration 1738, lr = 1e-05
I0810 21:41:07.932643   463 solver.cpp:242] Iteration 1760 (0.866532 iter/s, 25.3886s/22 iter), loss = 8.96342
I0810 21:41:07.932991   463 solver.cpp:261]     Train net output #0: loss_bbox = 1.26025 (* 2 = 2.5205 loss)
I0810 21:41:07.933013   463 solver.cpp:261]     Train net output #1: loss_coverage = 6.44292 (* 1 = 6.44292 loss)
I0810 21:41:07.933038   463 sgd_solver.cpp:106] Iteration 1760, lr = 1e-05
I0810 21:41:29.880544   463 solver.cpp:479] Snapshotting to binary proto file snapshot_iter_1780.caffemodel
I0810 21:41:29.985821   463 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshot_iter_1780.solverstate
I0810 21:41:30.042070   463 solver.cpp:362] Iteration 1780, Testing net (#0)
I0810 21:41:30.042104   463 net.cpp:723] Ignoring source layer train_data
I0810 21:41:30.042136   463 net.cpp:723] Ignoring source layer train_label
I0810 21:41:30.042142   463 net.cpp:723] Ignoring source layer train_transform
I0810 21:41:40.994714   463 solver.cpp:429]     Test net output #0: loss_bbox = 1.46847 (* 2 = 2.93694 loss)
I0810 21:41:40.994889   463 solver.cpp:429]     Test net output #1: loss_coverage = 4.69903 (* 1 = 4.69903 loss)
I0810 21:41:40.994900   463 solver.cpp:429]     Test net output #2: mAP = 0
I0810 21:41:40.994909   463 solver.cpp:429]     Test net output #3: precision = 0
I0810 21:41:40.994916   463 solver.cpp:429]     Test net output #4: recall = 0
I0810 21:41:44.453773   463 solver.cpp:242] Iteration 1782 (0.602393 iter/s, 36.521s/22 iter), loss = 11.1301
I0810 21:41:44.453827   463 solver.cpp:261]     Train net output #0: loss_bbox = 1.69993 (* 2 = 3.39986 loss)
I0810 21:41:44.453840   463 solver.cpp:261]     Train net output #1: loss_coverage = 7.73019 (* 1 = 7.73019 loss)
I0810 21:41:44.453857   463 sgd_solver.cpp:106] Iteration 1782, lr = 1e-05
I0810 21:42:09.854279   463 solver.cpp:242] Iteration 1804 (0.866121 iter/s, 25.4006s/22 iter), loss = 4.40315
I0810 21:42:09.854334   463 solver.cpp:261]     Train net output #0: loss_bbox = 0.972824 (* 2 = 1.94565 loss)
I0810 21:42:09.854347   463 solver.cpp:261]     Train net output #1: loss_coverage = 2.45749 (* 1 = 2.45749 loss)
I0810 21:42:09.854363   463 sgd_solver.cpp:106] Iteration 1804, lr = 1e-05
I0810 21:42:35.238333   463 solver.cpp:242] Iteration 1826 (0.866682 iter/s, 25.3842s/22 iter), loss = 9.42248
I0810 21:42:35.238626   463 solver.cpp:261]     Train net output #0: loss_bbox = 1.43455 (* 2 = 2.86909 loss)
I0810 21:42:35.238643   463 solver.cpp:261]     Train net output #1: loss_coverage = 6.55338 (* 1 = 6.55338 loss)
I0810 21:42:35.238662   463 sgd_solver.cpp:106] Iteration 1826, lr = 1e-05
I0810 21:43:00.593308   463 solver.cpp:242] Iteration 1848 (0.867684 iter/s, 25.3548s/22 iter), loss = 4.38898
I0810 21:43:00.593364   463 solver.cpp:261]     Train net output #0: loss_bbox = 0.790023 (* 2 = 1.58005 loss)
I0810 21:43:00.593377   463 solver.cpp:261]     Train net output #1: loss_coverage = 2.80893 (* 1 = 2.80893 loss)
I0810 21:43:00.593394   463 sgd_solver.cpp:106] Iteration 1848, lr = 1e-05
I0810 21:43:26.007726   463 solver.cpp:242] Iteration 1870 (0.865647 iter/s, 25.4145s/22 iter), loss = 2.94509
I0810 21:43:26.007995   463 solver.cpp:261]     Train net output #0: loss_bbox = 0.480168 (* 2 = 0.960335 loss)
I0810 21:43:26.008016   463 solver.cpp:261]     Train net output #1: loss_coverage = 1.98474 (* 1 = 1.98474 loss)
I0810 21:43:26.008038   463 sgd_solver.cpp:106] Iteration 1870, lr = 1e-05
I0810 21:43:51.375422   463 solver.cpp:242] Iteration 1892 (0.867248 iter/s, 25.3676s/22 iter), loss = 3.56017
I0810 21:43:51.375483   463 solver.cpp:261]     Train net output #0: loss_bbox = 0.777862 (* 2 = 1.55572 loss)
I0810 21:43:51.375496   463 solver.cpp:261]     Train net output #1: loss_coverage = 2.00444 (* 1 = 2.00444 loss)
I0810 21:43:51.375514   463 sgd_solver.cpp:106] Iteration 1892, lr = 1e-05
I0810 21:44:16.769875   463 solver.cpp:242] Iteration 1914 (0.866328 iter/s, 25.3945s/22 iter), loss = 9.89089
I0810 21:44:16.770082   463 solver.cpp:261]     Train net output #0: loss_bbox = 1.66753 (* 2 = 3.33507 loss)
I0810 21:44:16.770099   463 solver.cpp:261]     Train net output #1: loss_coverage = 6.55582 (* 1 = 6.55582 loss)
I0810 21:44:16.770141   463 sgd_solver.cpp:106] Iteration 1914, lr = 1e-05
I0810 21:44:42.179313   463 solver.cpp:242] Iteration 1936 (0.865821 iter/s, 25.4094s/22 iter), loss = 8.3753
I0810 21:44:42.179373   463 solver.cpp:261]     Train net output #0: loss_bbox = 1.47744 (* 2 = 2.95488 loss)
I0810 21:44:42.179385   463 solver.cpp:261]     Train net output #1: loss_coverage = 5.42041 (* 1 = 5.42041 loss)
I0810 21:44:42.179402   463 sgd_solver.cpp:106] Iteration 1936, lr = 1e-05
I0810 21:45:06.434156   463 solver.cpp:479] Snapshotting to binary proto file snapshot_iter_1958.caffemodel
I0810 21:45:06.533870   463 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshot_iter_1958.solverstate
I0810 21:45:06.590747   463 solver.cpp:362] Iteration 1958, Testing net (#0)
I0810 21:45:06.590775   463 net.cpp:723] Ignoring source layer train_data
I0810 21:45:06.590781   463 net.cpp:723] Ignoring source layer train_label
I0810 21:45:06.590787   463 net.cpp:723] Ignoring source layer train_transform
I0810 21:45:17.541718   463 solver.cpp:429]     Test net output #0: loss_bbox = 1.41837 (* 2 = 2.83675 loss)
I0810 21:45:17.541755   463 solver.cpp:429]     Test net output #1: loss_coverage = 5.20698 (* 1 = 5.20698 loss)
I0810 21:45:17.541764   463 solver.cpp:429]     Test net output #2: mAP = 0
I0810 21:45:17.541771   463 solver.cpp:429]     Test net output #3: precision = 0
I0810 21:45:17.541779   463 solver.cpp:429]     Test net output #4: recall = 0
I0810 21:45:18.691509   463 solver.cpp:242] Iteration 1958 (0.602535 iter/s, 36.5124s/22 iter), loss = 5.95812
I0810 21:45:18.691577   463 solver.cpp:261]     Train net output #0: loss_bbox = 1.45581 (* 2 = 2.91162 loss)
I0810 21:45:18.691591   463 solver.cpp:261]     Train net output #1: loss_coverage = 3.04649 (* 1 = 3.04649 loss)
I0810 21:45:18.691607   463 sgd_solver.cpp:106] Iteration 1958, lr = 1e-05
I0810 21:45:44.074754   463 solver.cpp:242] Iteration 1980 (0.86671 iter/s, 25.3833s/22 iter), loss = 12.8393
I0810 21:45:44.075158   463 solver.cpp:261]     Train net output #0: loss_bbox = 1.74344 (* 2 = 3.48688 loss)
I0810 21:45:44.075178   463 solver.cpp:261]     Train net output #1: loss_coverage = 9.35237 (* 1 = 9.35237 loss)
I0810 21:45:44.075199   463 sgd_solver.cpp:106] Iteration 1980, lr = 1e-05
I0810 21:46:09.472762   463 solver.cpp:242] Iteration 2002 (0.866218 iter/s, 25.3978s/22 iter), loss = 7.27455
I0810 21:46:09.472823   463 solver.cpp:261]     Train net output #0: loss_bbox = 1.29226 (* 2 = 2.58451 loss)
I0810 21:46:09.472836   463 solver.cpp:261]     Train net output #1: loss_coverage = 4.69004 (* 1 = 4.69004 loss)
I0810 21:46:09.472852   463 sgd_solver.cpp:106] Iteration 2002, lr = 1e-05
I0810 21:46:34.853886   463 solver.cpp:242] Iteration 2024 (0.866782 iter/s, 25.3812s/22 iter), loss = 3.1894
I0810 21:46:34.854084   463 solver.cpp:261]     Train net output #0: loss_bbox = 0.458136 (* 2 = 0.916271 loss)
I0810 21:46:34.854133   463 solver.cpp:261]     Train net output #1: loss_coverage = 2.27312 (* 1 = 2.27312 loss)
I0810 21:46:34.854154   463 sgd_solver.cpp:106] Iteration 2024, lr = 1e-05
I0810 21:47:00.221655   463 solver.cpp:242] Iteration 2046 (0.867244 iter/s, 25.3677s/22 iter), loss = 10.8108
I0810 21:47:00.221717   463 solver.cpp:261]     Train net output #0: loss_bbox = 1.53439 (* 2 = 3.06877 loss)
I0810 21:47:00.221730   463 solver.cpp:261]     Train net output #1: loss_coverage = 7.74205 (* 1 = 7.74205 loss)
I0810 21:47:00.221748   463 sgd_solver.cpp:106] Iteration 2046, lr = 1e-05
I0810 21:47:25.624857   463 solver.cpp:242] Iteration 2068 (0.866029 iter/s, 25.4033s/22 iter), loss = 8.33214
I0810 21:47:25.625140   463 solver.cpp:261]     Train net output #0: loss_bbox = 1.00845 (* 2 = 2.0169 loss)
I0810 21:47:25.625157   463 solver.cpp:261]     Train net output #1: loss_coverage = 6.31523 (* 1 = 6.31523 loss)
I0810 21:47:25.625176   463 sgd_solver.cpp:106] Iteration 2068, lr = 1e-05
I0810 21:47:50.993273   463 solver.cpp:242] Iteration 2090 (0.867224 iter/s, 25.3683s/22 iter), loss = 6.36819
I0810 21:47:50.993333   463 solver.cpp:261]     Train net output #0: loss_bbox = 1.24197 (* 2 = 2.48393 loss)
I0810 21:47:50.993346   463 solver.cpp:261]     Train net output #1: loss_coverage = 3.88425 (* 1 = 3.88425 loss)
I0810 21:47:50.993363   463 sgd_solver.cpp:106] Iteration 2090, lr = 1e-05
I0810 21:48:16.387517   463 solver.cpp:242] Iteration 2112 (0.866335 iter/s, 25.3943s/22 iter), loss = 9.96952
I0810 21:48:16.387748   463 solver.cpp:261]     Train net output #0: loss_bbox = 1.39494 (* 2 = 2.78987 loss)
I0810 21:48:16.387763   463 solver.cpp:261]     Train net output #1: loss_coverage = 7.17964 (* 1 = 7.17964 loss)
I0810 21:48:16.387780   463 sgd_solver.cpp:106] Iteration 2112, lr = 1e-05
I0810 21:48:41.780005   463 solver.cpp:242] Iteration 2134 (0.8664 iter/s, 25.3924s/22 iter), loss = 5.09417
I0810 21:48:41.780061   463 solver.cpp:261]     Train net output #0: loss_bbox = 0.963583 (* 2 = 1.92717 loss)
I0810 21:48:41.780074   463 solver.cpp:261]     Train net output #1: loss_coverage = 3.167 (* 1 = 3.167 loss)
I0810 21:48:41.780091   463 sgd_solver.cpp:106] Iteration 2134, lr = 1e-05
I0810 21:48:42.928164   463 solver.cpp:479] Snapshotting to binary proto file snapshot_iter_2136.caffemodel
I0810 21:48:43.027513   463 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshot_iter_2136.solverstate
I0810 21:48:43.082573   463 solver.cpp:362] Iteration 2136, Testing net (#0)
I0810 21:48:43.082604   463 net.cpp:723] Ignoring source layer train_data
I0810 21:48:43.082613   463 net.cpp:723] Ignoring source layer train_label
I0810 21:48:43.082621   463 net.cpp:723] Ignoring source layer train_transform
I0810 21:48:54.014479   463 solver.cpp:429]     Test net output #0: loss_bbox = 1.39 (* 2 = 2.78001 loss)
I0810 21:48:54.014730   463 solver.cpp:429]     Test net output #1: loss_coverage = 4.83099 (* 1 = 4.83099 loss)
I0810 21:48:54.014742   463 solver.cpp:429]     Test net output #2: mAP = 0
I0810 21:48:54.014750   463 solver.cpp:429]     Test net output #3: precision = 0
I0810 21:48:54.014758   463 solver.cpp:429]     Test net output #4: recall = 0
I0810 21:49:18.254626   463 solver.cpp:242] Iteration 2156 (0.603156 iter/s, 36.4748s/22 iter), loss = 9.51296
I0810 21:49:18.254683   463 solver.cpp:261]     Train net output #0: loss_bbox = 1.59403 (* 2 = 3.18805 loss)
I0810 21:49:18.254696   463 solver.cpp:261]     Train net output #1: loss_coverage = 6.3249 (* 1 = 6.3249 loss)
I0810 21:49:18.254714   463 sgd_solver.cpp:106] Iteration 2156, lr = 1e-05
I0810 21:49:43.606220   463 solver.cpp:242] Iteration 2178 (0.867792 iter/s, 25.3517s/22 iter), loss = 8.63631
I0810 21:49:43.606505   463 solver.cpp:261]     Train net output #0: loss_bbox = 1.3108 (* 2 = 2.6216 loss)
I0810 21:49:43.606531   463 solver.cpp:261]     Train net output #1: loss_coverage = 6.0147 (* 1 = 6.0147 loss)
I0810 21:49:43.606551   463 sgd_solver.cpp:106] Iteration 2178, lr = 1e-05
I0810 21:50:08.975186   463 solver.cpp:242] Iteration 2200 (0.867205 iter/s, 25.3688s/22 iter), loss = 10.4351
I0810 21:50:08.975245   463 solver.cpp:261]     Train net output #0: loss_bbox = 1.83314 (* 2 = 3.66628 loss)
I0810 21:50:08.975258   463 solver.cpp:261]     Train net output #1: loss_coverage = 6.76882 (* 1 = 6.76882 loss)
I0810 21:50:08.975275   463 sgd_solver.cpp:106] Iteration 2200, lr = 1e-05
I0810 21:50:34.314286   463 solver.cpp:242] Iteration 2222 (0.86822 iter/s, 25.3392s/22 iter), loss = 5.19286
I0810 21:50:34.314615   463 solver.cpp:261]     Train net output #0: loss_bbox = 1.11662 (* 2 = 2.23324 loss)
I0810 21:50:34.314630   463 solver.cpp:261]     Train net output #1: loss_coverage = 2.95961 (* 1 = 2.95961 loss)
I0810 21:50:34.314651   463 sgd_solver.cpp:106] Iteration 2222, lr = 1e-05
I0810 21:50:59.673607   463 solver.cpp:242] Iteration 2244 (0.867536 iter/s, 25.3592s/22 iter), loss = 10.2031
I0810 21:50:59.673667   463 solver.cpp:261]     Train net output #0: loss_bbox = 1.72505 (* 2 = 3.45009 loss)
I0810 21:50:59.673681   463 solver.cpp:261]     Train net output #1: loss_coverage = 6.75301 (* 1 = 6.75301 loss)
I0810 21:50:59.673697   463 sgd_solver.cpp:106] Iteration 2244, lr = 1e-05
I0810 21:51:25.104913   463 solver.cpp:242] Iteration 2266 (0.865072 iter/s, 25.4314s/22 iter), loss = 5.09976
I0810 21:51:25.105166   463 solver.cpp:261]     Train net output #0: loss_bbox = 1.12715 (* 2 = 2.25429 loss)
I0810 21:51:25.105182   463 solver.cpp:261]     Train net output #1: loss_coverage = 2.84547 (* 1 = 2.84547 loss)
I0810 21:51:25.105201   463 sgd_solver.cpp:106] Iteration 2266, lr = 1e-05
I0810 21:51:50.475683   463 solver.cpp:242] Iteration 2288 (0.867143 iter/s, 25.3707s/22 iter), loss = 6.98912
I0810 21:51:50.475744   463 solver.cpp:261]     Train net output #0: loss_bbox = 0.853105 (* 2 = 1.70621 loss)
I0810 21:51:50.475757   463 solver.cpp:261]     Train net output #1: loss_coverage = 5.2829 (* 1 = 5.2829 loss)
I0810 21:51:50.475775   463 sgd_solver.cpp:106] Iteration 2288, lr = 1e-05
I0810 21:52:15.841143   463 solver.cpp:242] Iteration 2310 (0.867318 iter/s, 25.3656s/22 iter), loss = 6.88186
I0810 21:52:15.841308   463 solver.cpp:261]     Train net output #0: loss_bbox = 1.3371 (* 2 = 2.67421 loss)
I0810 21:52:15.841325   463 solver.cpp:261]     Train net output #1: loss_coverage = 4.20764 (* 1 = 4.20764 loss)
I0810 21:52:15.841342   463 sgd_solver.cpp:106] Iteration 2310, lr = 1e-05
I0810 21:52:19.304460   463 solver.cpp:479] Snapshotting to binary proto file snapshot_iter_2314.caffemodel
I0810 21:52:19.403218   463 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshot_iter_2314.solverstate
I0810 21:52:19.457219   463 solver.cpp:362] Iteration 2314, Testing net (#0)
I0810 21:52:19.457248   463 net.cpp:723] Ignoring source layer train_data
I0810 21:52:19.457257   463 net.cpp:723] Ignoring source layer train_label
I0810 21:52:19.457262   463 net.cpp:723] Ignoring source layer train_transform
I0810 21:52:30.403275   463 solver.cpp:429]     Test net output #0: loss_bbox = 1.3817 (* 2 = 2.7634 loss)
I0810 21:52:30.403316   463 solver.cpp:429]     Test net output #1: loss_coverage = 5.50937 (* 1 = 5.50937 loss)
I0810 21:52:30.403323   463 solver.cpp:429]     Test net output #2: mAP = 0
I0810 21:52:30.403333   463 solver.cpp:429]     Test net output #3: precision = 0
I0810 21:52:30.403340   463 solver.cpp:429]     Test net output #4: recall = 0
I0810 21:52:52.298463   463 solver.cpp:242] Iteration 2332 (0.603444 iter/s, 36.4574s/22 iter), loss = 7.73536
I0810 21:52:52.298746   463 solver.cpp:261]     Train net output #0: loss_bbox = 0.984765 (* 2 = 1.96953 loss)
I0810 21:52:52.298763   463 solver.cpp:261]     Train net output #1: loss_coverage = 5.76583 (* 1 = 5.76583 loss)
I0810 21:52:52.298780   463 sgd_solver.cpp:106] Iteration 2332, lr = 1e-05
I0810 21:53:17.692657   463 solver.cpp:242] Iteration 2354 (0.866344 iter/s, 25.3941s/22 iter), loss = 4.23977
I0810 21:53:17.692713   463 solver.cpp:261]     Train net output #0: loss_bbox = 1.00573 (* 2 = 2.01146 loss)
I0810 21:53:17.692725   463 solver.cpp:261]     Train net output #1: loss_coverage = 2.2283 (* 1 = 2.2283 loss)
I0810 21:53:17.692741   463 sgd_solver.cpp:106] Iteration 2354, lr = 1e-05
I0810 21:53:43.072674   463 solver.cpp:242] Iteration 2376 (0.86682 iter/s, 25.3801s/22 iter), loss = 3.30897
I0810 21:53:43.072988   463 solver.cpp:261]     Train net output #0: loss_bbox = 0.869661 (* 2 = 1.73932 loss)
I0810 21:53:43.073007   463 solver.cpp:261]     Train net output #1: loss_coverage = 1.56964 (* 1 = 1.56964 loss)
I0810 21:53:43.073029   463 sgd_solver.cpp:106] Iteration 2376, lr = 1e-05
I0810 21:54:08.447281   463 solver.cpp:242] Iteration 2398 (0.867013 iter/s, 25.3745s/22 iter), loss = 3.66133
I0810 21:54:08.447356   463 solver.cpp:261]     Train net output #0: loss_bbox = 0.716986 (* 2 = 1.43397 loss)
I0810 21:54:08.447374   463 solver.cpp:261]     Train net output #1: loss_coverage = 2.22735 (* 1 = 2.22735 loss)
I0810 21:54:08.447396   463 sgd_solver.cpp:106] Iteration 2398, lr = 1e-05
I0810 21:54:33.833185   463 solver.cpp:242] Iteration 2420 (0.866619 iter/s, 25.386s/22 iter), loss = 7.30227
I0810 21:54:33.833420   463 solver.cpp:261]     Train net output #0: loss_bbox = 1.1885 (* 2 = 2.37699 loss)
I0810 21:54:33.833436   463 solver.cpp:261]     Train net output #1: loss_coverage = 4.92527 (* 1 = 4.92527 loss)
I0810 21:54:33.833453   463 sgd_solver.cpp:106] Iteration 2420, lr = 1e-05
I0810 21:54:59.212733   463 solver.cpp:242] Iteration 2442 (0.866842 iter/s, 25.3795s/22 iter), loss = 5.7801
I0810 21:54:59.212792   463 solver.cpp:261]     Train net output #0: loss_bbox = 1.14525 (* 2 = 2.29051 loss)
I0810 21:54:59.212805   463 solver.cpp:261]     Train net output #1: loss_coverage = 3.48958 (* 1 = 3.48958 loss)
I0810 21:54:59.212821   463 sgd_solver.cpp:106] Iteration 2442, lr = 1e-05
I0810 21:55:24.606343   463 solver.cpp:242] Iteration 2464 (0.866356 iter/s, 25.3937s/22 iter), loss = 8.91957
I0810 21:55:24.606612   463 solver.cpp:261]     Train net output #0: loss_bbox = 1.22566 (* 2 = 2.45132 loss)
I0810 21:55:24.606627   463 solver.cpp:261]     Train net output #1: loss_coverage = 6.46825 (* 1 = 6.46825 loss)
I0810 21:55:24.606645   463 sgd_solver.cpp:106] Iteration 2464, lr = 1e-05
I0810 21:55:49.979475   463 solver.cpp:242] Iteration 2486 (0.867063 iter/s, 25.373s/22 iter), loss = 4.7049
I0810 21:55:49.979537   463 solver.cpp:261]     Train net output #0: loss_bbox = 0.903403 (* 2 = 1.80681 loss)
I0810 21:55:49.979549   463 solver.cpp:261]     Train net output #1: loss_coverage = 2.89809 (* 1 = 2.89809 loss)
I0810 21:55:49.979566   463 sgd_solver.cpp:106] Iteration 2486, lr = 1e-05
I0810 21:55:55.756086   463 solver.cpp:479] Snapshotting to binary proto file snapshot_iter_2492.caffemodel
I0810 21:55:55.884542   463 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshot_iter_2492.solverstate
I0810 21:55:55.940212   463 solver.cpp:362] Iteration 2492, Testing net (#0)
I0810 21:55:55.940243   463 net.cpp:723] Ignoring source layer train_data
I0810 21:55:55.940251   463 net.cpp:723] Ignoring source layer train_label
I0810 21:55:55.940256   463 net.cpp:723] Ignoring source layer train_transform
I0810 21:56:06.897236   463 solver.cpp:429]     Test net output #0: loss_bbox = 1.31546 (* 2 = 2.63092 loss)
I0810 21:56:06.897271   463 solver.cpp:429]     Test net output #1: loss_coverage = 5.01917 (* 1 = 5.01917 loss)
I0810 21:56:06.897280   463 solver.cpp:429]     Test net output #2: mAP = 0
I0810 21:56:06.897289   463 solver.cpp:429]     Test net output #3: precision = 0
I0810 21:56:06.897295   463 solver.cpp:429]     Test net output #4: recall = 0
I0810 21:56:26.527060   463 solver.cpp:242] Iteration 2508 (0.601952 iter/s, 36.5478s/22 iter), loss = 9.92033
I0810 21:56:26.527315   463 solver.cpp:261]     Train net output #0: loss_bbox = 1.32527 (* 2 = 2.65055 loss)
I0810 21:56:26.527331   463 solver.cpp:261]     Train net output #1: loss_coverage = 7.26978 (* 1 = 7.26978 loss)
I0810 21:56:26.527348   463 sgd_solver.cpp:106] Iteration 2508, lr = 1e-05
I0810 21:56:51.921757   463 solver.cpp:242] Iteration 2530 (0.866326 iter/s, 25.3946s/22 iter), loss = 9.13459
I0810 21:56:51.921814   463 solver.cpp:261]     Train net output #0: loss_bbox = 1.56908 (* 2 = 3.13817 loss)
I0810 21:56:51.921826   463 solver.cpp:261]     Train net output #1: loss_coverage = 5.99641 (* 1 = 5.99641 loss)
I0810 21:56:51.921842   463 sgd_solver.cpp:106] Iteration 2530, lr = 1e-05
I0810 21:57:17.326647   463 solver.cpp:242] Iteration 2552 (0.865972 iter/s, 25.405s/22 iter), loss = 7.7849
I0810 21:57:17.326920   463 solver.cpp:261]     Train net output #0: loss_bbox = 1.29875 (* 2 = 2.59749 loss)
I0810 21:57:17.326936   463 solver.cpp:261]     Train net output #1: loss_coverage = 5.1874 (* 1 = 5.1874 loss)
I0810 21:57:17.326952   463 sgd_solver.cpp:106] Iteration 2552, lr = 1e-05
I0810 21:57:42.736739   463 solver.cpp:242] Iteration 2574 (0.865801 iter/s, 25.41s/22 iter), loss = 5.55775
I0810 21:57:42.736796   463 solver.cpp:261]     Train net output #0: loss_bbox = 0.923893 (* 2 = 1.84779 loss)
I0810 21:57:42.736810   463 solver.cpp:261]     Train net output #1: loss_coverage = 3.70996 (* 1 = 3.70996 loss)
I0810 21:57:42.736826   463 sgd_solver.cpp:106] Iteration 2574, lr = 1e-05
I0810 21:58:08.127182   463 solver.cpp:242] Iteration 2596 (0.866465 iter/s, 25.3905s/22 iter), loss = 5.06368
I0810 21:58:08.127454   463 solver.cpp:261]     Train net output #0: loss_bbox = 0.888235 (* 2 = 1.77647 loss)
I0810 21:58:08.127470   463 solver.cpp:261]     Train net output #1: loss_coverage = 3.2872 (* 1 = 3.2872 loss)
I0810 21:58:08.127488   463 sgd_solver.cpp:106] Iteration 2596, lr = 1e-05
I0810 21:58:33.520083   463 solver.cpp:242] Iteration 2618 (0.866388 iter/s, 25.3928s/22 iter), loss = 8.85444
I0810 21:58:33.520165   463 solver.cpp:261]     Train net output #0: loss_bbox = 1.53276 (* 2 = 3.06553 loss)
I0810 21:58:33.520179   463 solver.cpp:261]     Train net output #1: loss_coverage = 5.78891 (* 1 = 5.78891 loss)
I0810 21:58:33.520196   463 sgd_solver.cpp:106] Iteration 2618, lr = 1e-05
I0810 21:58:58.922886   463 solver.cpp:242] Iteration 2640 (0.866044 iter/s, 25.4029s/22 iter), loss = 10.1995
I0810 21:58:58.923192   463 solver.cpp:261]     Train net output #0: loss_bbox = 1.46988 (* 2 = 2.93975 loss)
I0810 21:58:58.923209   463 solver.cpp:261]     Train net output #1: loss_coverage = 7.25969 (* 1 = 7.25969 loss)
I0810 21:58:58.923228   463 sgd_solver.cpp:106] Iteration 2640, lr = 1e-05
I0810 21:59:24.322875   463 solver.cpp:242] Iteration 2662 (0.866147 iter/s, 25.3998s/22 iter), loss = 6.5883
I0810 21:59:24.322934   463 solver.cpp:261]     Train net output #0: loss_bbox = 0.975711 (* 2 = 1.95142 loss)
I0810 21:59:24.322948   463 solver.cpp:261]     Train net output #1: loss_coverage = 4.63687 (* 1 = 4.63687 loss)
I0810 21:59:24.322965   463 sgd_solver.cpp:106] Iteration 2662, lr = 1e-05
I0810 21:59:32.424319   463 solver.cpp:479] Snapshotting to binary proto file snapshot_iter_2670.caffemodel
I0810 21:59:32.523449   463 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshot_iter_2670.solverstate
I0810 21:59:32.577383   463 solver.cpp:362] Iteration 2670, Testing net (#0)
I0810 21:59:32.577415   463 net.cpp:723] Ignoring source layer train_data
I0810 21:59:32.577422   463 net.cpp:723] Ignoring source layer train_label
I0810 21:59:32.577428   463 net.cpp:723] Ignoring source layer train_transform
I0810 21:59:43.550343   463 solver.cpp:429]     Test net output #0: loss_bbox = 1.25679 (* 2 = 2.51358 loss)
I0810 21:59:43.550377   463 solver.cpp:429]     Test net output #1: loss_coverage = 5.42879 (* 1 = 5.42879 loss)
I0810 21:59:43.550386   463 solver.cpp:429]     Test net output #2: mAP = 0
I0810 21:59:43.550393   463 solver.cpp:429]     Test net output #3: precision = 0
I0810 21:59:43.550400   463 solver.cpp:429]     Test net output #4: recall = 0
I0810 22:00:00.850540   463 solver.cpp:242] Iteration 2684 (0.60228 iter/s, 36.5278s/22 iter), loss = 6.75598
I0810 22:00:00.850601   463 solver.cpp:261]     Train net output #0: loss_bbox = 1.11777 (* 2 = 2.23553 loss)
I0810 22:00:00.850615   463 solver.cpp:261]     Train net output #1: loss_coverage = 4.52044 (* 1 = 4.52044 loss)
I0810 22:00:00.850632   463 sgd_solver.cpp:106] Iteration 2684, lr = 1e-05
I0810 22:00:26.212872   463 solver.cpp:242] Iteration 2706 (0.867425 iter/s, 25.3624s/22 iter), loss = 11.224
I0810 22:00:26.213125   463 solver.cpp:261]     Train net output #0: loss_bbox = 1.26032 (* 2 = 2.52065 loss)
I0810 22:00:26.213141   463 solver.cpp:261]     Train net output #1: loss_coverage = 8.70335 (* 1 = 8.70335 loss)
I0810 22:00:26.213158   463 sgd_solver.cpp:106] Iteration 2706, lr = 1e-05
I0810 22:00:51.585866   463 solver.cpp:242] Iteration 2728 (0.867067 iter/s, 25.3729s/22 iter), loss = 2.99412
I0810 22:00:51.585927   463 solver.cpp:261]     Train net output #0: loss_bbox = 0.421933 (* 2 = 0.843866 loss)
I0810 22:00:51.585942   463 solver.cpp:261]     Train net output #1: loss_coverage = 2.15025 (* 1 = 2.15025 loss)
I0810 22:00:51.585958   463 sgd_solver.cpp:106] Iteration 2728, lr = 1e-05
I0810 22:01:16.954397   463 solver.cpp:242] Iteration 2750 (0.867213 iter/s, 25.3686s/22 iter), loss = 11.605
I0810 22:01:16.954658   463 solver.cpp:261]     Train net output #0: loss_bbox = 1.81755 (* 2 = 3.63511 loss)
I0810 22:01:16.954674   463 solver.cpp:261]     Train net output #1: loss_coverage = 7.96992 (* 1 = 7.96992 loss)
I0810 22:01:16.954692   463 sgd_solver.cpp:106] Iteration 2750, lr = 1e-05
I0810 22:01:42.307883   463 solver.cpp:242] Iteration 2772 (0.867734 iter/s, 25.3534s/22 iter), loss = 8.23304
I0810 22:01:42.307945   463 solver.cpp:261]     Train net output #0: loss_bbox = 0.969999 (* 2 = 1.94 loss)
I0810 22:01:42.307960   463 solver.cpp:261]     Train net output #1: loss_coverage = 6.29304 (* 1 = 6.29304 loss)
I0810 22:01:42.307976   463 sgd_solver.cpp:106] Iteration 2772, lr = 1e-05
I0810 22:02:07.661504   463 solver.cpp:242] Iteration 2794 (0.867723 iter/s, 25.3537s/22 iter), loss = 9.78639
I0810 22:02:07.661715   463 solver.cpp:261]     Train net output #0: loss_bbox = 1.65426 (* 2 = 3.30852 loss)
I0810 22:02:07.661739   463 solver.cpp:261]     Train net output #1: loss_coverage = 6.47786 (* 1 = 6.47786 loss)
I0810 22:02:07.661756   463 sgd_solver.cpp:106] Iteration 2794, lr = 1e-05
I0810 22:02:33.019853   463 solver.cpp:242] Iteration 2816 (0.867566 iter/s, 25.3583s/22 iter), loss = 8.17341
I0810 22:02:33.019912   463 solver.cpp:261]     Train net output #0: loss_bbox = 0.991574 (* 2 = 1.98315 loss)
I0810 22:02:33.019924   463 solver.cpp:261]     Train net output #1: loss_coverage = 6.19026 (* 1 = 6.19026 loss)
I0810 22:02:33.019942   463 sgd_solver.cpp:106] Iteration 2816, lr = 1e-05
I0810 22:02:58.431351   463 solver.cpp:242] Iteration 2838 (0.865746 iter/s, 25.4116s/22 iter), loss = 11.6357
I0810 22:02:58.431658   463 solver.cpp:261]     Train net output #0: loss_bbox = 1.73767 (* 2 = 3.47533 loss)
I0810 22:02:58.431674   463 solver.cpp:261]     Train net output #1: loss_coverage = 8.16034 (* 1 = 8.16034 loss)
I0810 22:02:58.431692   463 sgd_solver.cpp:106] Iteration 2838, lr = 1e-05
I0810 22:03:08.840416   463 solver.cpp:479] Snapshotting to binary proto file snapshot_iter_2848.caffemodel
I0810 22:03:08.957849   463 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshot_iter_2848.solverstate
I0810 22:03:09.017529   463 solver.cpp:362] Iteration 2848, Testing net (#0)
I0810 22:03:09.017572   463 net.cpp:723] Ignoring source layer train_data
I0810 22:03:09.017581   463 net.cpp:723] Ignoring source layer train_label
I0810 22:03:09.017587   463 net.cpp:723] Ignoring source layer train_transform
I0810 22:03:19.950893   463 solver.cpp:429]     Test net output #0: loss_bbox = 1.19323 (* 2 = 2.38645 loss)
I0810 22:03:19.950929   463 solver.cpp:429]     Test net output #1: loss_coverage = 4.57458 (* 1 = 4.57458 loss)
I0810 22:03:19.950938   463 solver.cpp:429]     Test net output #2: mAP = 0
I0810 22:03:19.950945   463 solver.cpp:429]     Test net output #3: precision = 0
I0810 22:03:19.950953   463 solver.cpp:429]     Test net output #4: recall = 0
I0810 22:03:34.919878   463 solver.cpp:242] Iteration 2860 (0.60293 iter/s, 36.4885s/22 iter), loss = 6.20776
I0810 22:03:34.920220   463 solver.cpp:261]     Train net output #0: loss_bbox = 1.03331 (* 2 = 2.06663 loss)
I0810 22:03:34.920239   463 solver.cpp:261]     Train net output #1: loss_coverage = 4.14113 (* 1 = 4.14113 loss)
I0810 22:03:34.920260   463 sgd_solver.cpp:106] Iteration 2860, lr = 1e-05
I0810 22:04:00.285753   463 solver.cpp:242] Iteration 2882 (0.867313 iter/s, 25.3657s/22 iter), loss = 7.89842
I0810 22:04:00.285812   463 solver.cpp:261]     Train net output #0: loss_bbox = 1.37994 (* 2 = 2.75988 loss)
I0810 22:04:00.285825   463 solver.cpp:261]     Train net output #1: loss_coverage = 5.13852 (* 1 = 5.13852 loss)
I0810 22:04:00.285842   463 sgd_solver.cpp:106] Iteration 2882, lr = 1e-05
I0810 22:04:25.646198   463 solver.cpp:242] Iteration 2904 (0.867489 iter/s, 25.3605s/22 iter), loss = 10.6184
I0810 22:04:25.646437   463 solver.cpp:261]     Train net output #0: loss_bbox = 1.47441 (* 2 = 2.94883 loss)
I0810 22:04:25.646453   463 solver.cpp:261]     Train net output #1: loss_coverage = 7.66952 (* 1 = 7.66952 loss)
I0810 22:04:25.646471   463 sgd_solver.cpp:106] Iteration 2904, lr = 1e-05
I0810 22:04:51.028969   463 solver.cpp:242] Iteration 2926 (0.866732 iter/s, 25.3827s/22 iter), loss = 6.0844
I0810 22:04:51.029024   463 solver.cpp:261]     Train net output #0: loss_bbox = 1.01563 (* 2 = 2.03126 loss)
I0810 22:04:51.029038   463 solver.cpp:261]     Train net output #1: loss_coverage = 4.05314 (* 1 = 4.05314 loss)
I0810 22:04:51.029054   463 sgd_solver.cpp:106] Iteration 2926, lr = 1e-05
I0810 22:05:16.387717   463 solver.cpp:242] Iteration 2948 (0.867548 iter/s, 25.3588s/22 iter), loss = 4.91652
I0810 22:05:16.388068   463 solver.cpp:261]     Train net output #0: loss_bbox = 0.915284 (* 2 = 1.83057 loss)
I0810 22:05:16.388115   463 solver.cpp:261]     Train net output #1: loss_coverage = 3.08594 (* 1 = 3.08594 loss)
I0810 22:05:16.388147   463 sgd_solver.cpp:106] Iteration 2948, lr = 1e-05
I0810 22:05:41.809797   463 solver.cpp:242] Iteration 2970 (0.865396 iter/s, 25.4219s/22 iter), loss = 7.94474
I0810 22:05:41.809856   463 solver.cpp:261]     Train net output #0: loss_bbox = 1.18433 (* 2 = 2.36867 loss)
I0810 22:05:41.809870   463 solver.cpp:261]     Train net output #1: loss_coverage = 5.57607 (* 1 = 5.57607 loss)
I0810 22:05:41.809886   463 sgd_solver.cpp:106] Iteration 2970, lr = 1e-05
I0810 22:06:07.216140   463 solver.cpp:242] Iteration 2992 (0.865923 iter/s, 25.4064s/22 iter), loss = 4.35491
I0810 22:06:07.216460   463 solver.cpp:261]     Train net output #0: loss_bbox = 0.581569 (* 2 = 1.16314 loss)
I0810 22:06:07.216481   463 solver.cpp:261]     Train net output #1: loss_coverage = 3.19177 (* 1 = 3.19177 loss)
I0810 22:06:07.216514   463 sgd_solver.cpp:106] Iteration 2992, lr = 1e-05
I0810 22:06:32.575928   463 solver.cpp:242] Iteration 3014 (0.867521 iter/s, 25.3596s/22 iter), loss = 7.31728
I0810 22:06:32.575992   463 solver.cpp:261]     Train net output #0: loss_bbox = 1.3399 (* 2 = 2.67981 loss)
I0810 22:06:32.576006   463 solver.cpp:261]     Train net output #1: loss_coverage = 4.63747 (* 1 = 4.63747 loss)
I0810 22:06:32.576025   463 sgd_solver.cpp:106] Iteration 3014, lr = 1e-05
I0810 22:06:45.266464   463 solver.cpp:479] Snapshotting to binary proto file snapshot_iter_3026.caffemodel
I0810 22:06:45.367614   463 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshot_iter_3026.solverstate
I0810 22:06:45.423148   463 solver.cpp:362] Iteration 3026, Testing net (#0)
I0810 22:06:45.423179   463 net.cpp:723] Ignoring source layer train_data
I0810 22:06:45.423187   463 net.cpp:723] Ignoring source layer train_label
I0810 22:06:45.423192   463 net.cpp:723] Ignoring source layer train_transform
I0810 22:06:56.374982   463 solver.cpp:429]     Test net output #0: loss_bbox = 1.03088 (* 2 = 2.06175 loss)
I0810 22:06:56.375018   463 solver.cpp:429]     Test net output #1: loss_coverage = 5.17987 (* 1 = 5.17987 loss)
I0810 22:06:56.375038   463 solver.cpp:429]     Test net output #2: mAP = 0
I0810 22:06:56.375046   463 solver.cpp:429]     Test net output #3: precision = 0
I0810 22:06:56.375053   463 solver.cpp:429]     Test net output #4: recall = 0
I0810 22:07:09.078397   463 solver.cpp:242] Iteration 3036 (0.602696 iter/s, 36.5026s/22 iter), loss = 12.4598
I0810 22:07:09.078455   463 solver.cpp:261]     Train net output #0: loss_bbox = 1.40782 (* 2 = 2.81565 loss)
I0810 22:07:09.078469   463 solver.cpp:261]     Train net output #1: loss_coverage = 9.64418 (* 1 = 9.64418 loss)
I0810 22:07:09.078486   463 sgd_solver.cpp:106] Iteration 3036, lr = 1e-05
I0810 22:07:34.485368   463 solver.cpp:242] Iteration 3058 (0.865901 iter/s, 25.4071s/22 iter), loss = 4.57647
I0810 22:07:34.485622   463 solver.cpp:261]     Train net output #0: loss_bbox = 0.655422 (* 2 = 1.31084 loss)
I0810 22:07:34.485640   463 solver.cpp:261]     Train net output #1: loss_coverage = 3.26562 (* 1 = 3.26562 loss)
I0810 22:07:34.485658   463 sgd_solver.cpp:106] Iteration 3058, lr = 1e-05
I0810 22:07:59.910861   463 solver.cpp:242] Iteration 3080 (0.865276 iter/s, 25.4254s/22 iter), loss = 6.71491
I0810 22:07:59.910923   463 solver.cpp:261]     Train net output #0: loss_bbox = 1.09975 (* 2 = 2.19949 loss)
I0810 22:07:59.910939   463 solver.cpp:261]     Train net output #1: loss_coverage = 4.51541 (* 1 = 4.51541 loss)
I0810 22:07:59.910964   463 sgd_solver.cpp:106] Iteration 3080, lr = 1e-05
I0810 22:08:25.296846   463 solver.cpp:242] Iteration 3102 (0.866616 iter/s, 25.3861s/22 iter), loss = 7.2233
I0810 22:08:25.297122   463 solver.cpp:261]     Train net output #0: loss_bbox = 0.85317 (* 2 = 1.70634 loss)
I0810 22:08:25.297139   463 solver.cpp:261]     Train net output #1: loss_coverage = 5.51695 (* 1 = 5.51695 loss)
I0810 22:08:25.297158   463 sgd_solver.cpp:106] Iteration 3102, lr = 1e-05
I0810 22:08:50.716068   463 solver.cpp:242] Iteration 3124 (0.86549 iter/s, 25.4191s/22 iter), loss = 4.61318
I0810 22:08:50.716152   463 solver.cpp:261]     Train net output #0: loss_bbox = 0.818603 (* 2 = 1.63721 loss)
I0810 22:08:50.716166   463 solver.cpp:261]     Train net output #1: loss_coverage = 2.97597 (* 1 = 2.97597 loss)
I0810 22:08:50.716182   463 sgd_solver.cpp:106] Iteration 3124, lr = 1e-05
I0810 22:09:16.097035   463 solver.cpp:242] Iteration 3146 (0.866789 iter/s, 25.381s/22 iter), loss = 8.68577
I0810 22:09:16.097266   463 solver.cpp:261]     Train net output #0: loss_bbox = 1.4533 (* 2 = 2.90659 loss)
I0810 22:09:16.097283   463 solver.cpp:261]     Train net output #1: loss_coverage = 5.77918 (* 1 = 5.77918 loss)
I0810 22:09:16.097302   463 sgd_solver.cpp:106] Iteration 3146, lr = 1e-05
I0810 22:09:41.469156   463 solver.cpp:242] Iteration 3168 (0.867096 iter/s, 25.3721s/22 iter), loss = 9.207
I0810 22:09:41.469213   463 solver.cpp:261]     Train net output #0: loss_bbox = 1.19581 (* 2 = 2.39162 loss)
I0810 22:09:41.469224   463 solver.cpp:261]     Train net output #1: loss_coverage = 6.81538 (* 1 = 6.81538 loss)
I0810 22:09:41.469240   463 sgd_solver.cpp:106] Iteration 3168, lr = 1e-05
I0810 22:10:06.886456   463 solver.cpp:242] Iteration 3190 (0.865549 iter/s, 25.4174s/22 iter), loss = 8.26961
I0810 22:10:06.886770   463 solver.cpp:261]     Train net output #0: loss_bbox = 1.02026 (* 2 = 2.04052 loss)
I0810 22:10:06.886786   463 solver.cpp:261]     Train net output #1: loss_coverage = 6.22908 (* 1 = 6.22908 loss)
I0810 22:10:06.886804   463 sgd_solver.cpp:106] Iteration 3190, lr = 1e-05
I0810 22:10:21.899713   463 solver.cpp:479] Snapshotting to binary proto file snapshot_iter_3204.caffemodel
I0810 22:10:21.998363   463 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshot_iter_3204.solverstate
I0810 22:10:22.052757   463 solver.cpp:362] Iteration 3204, Testing net (#0)
I0810 22:10:22.052788   463 net.cpp:723] Ignoring source layer train_data
I0810 22:10:22.052794   463 net.cpp:723] Ignoring source layer train_label
I0810 22:10:22.052800   463 net.cpp:723] Ignoring source layer train_transform
I0810 22:10:33.014356   463 solver.cpp:429]     Test net output #0: loss_bbox = 0.768623 (* 2 = 1.53725 loss)
I0810 22:10:33.014390   463 solver.cpp:429]     Test net output #1: loss_coverage = 5.22758 (* 1 = 5.22758 loss)
I0810 22:10:33.014400   463 solver.cpp:429]     Test net output #2: mAP = 0
I0810 22:10:33.014406   463 solver.cpp:429]     Test net output #3: precision = 0
I0810 22:10:33.014413   463 solver.cpp:429]     Test net output #4: recall = 0
I0810 22:10:43.398703   463 solver.cpp:242] Iteration 3212 (0.602539 iter/s, 36.5122s/22 iter), loss = 3.83829
I0810 22:10:43.398957   463 solver.cpp:261]     Train net output #0: loss_bbox = 0.499731 (* 2 = 0.999462 loss)
I0810 22:10:43.398974   463 solver.cpp:261]     Train net output #1: loss_coverage = 2.83882 (* 1 = 2.83882 loss)
I0810 22:10:43.398993   463 sgd_solver.cpp:106] Iteration 3212, lr = 1e-05
I0810 22:11:08.777922   463 solver.cpp:242] Iteration 3234 (0.866854 iter/s, 25.3791s/22 iter), loss = 5.9944
I0810 22:11:08.777990   463 solver.cpp:261]     Train net output #0: loss_bbox = 0.82834 (* 2 = 1.65668 loss)
I0810 22:11:08.778007   463 solver.cpp:261]     Train net output #1: loss_coverage = 4.33771 (* 1 = 4.33771 loss)
I0810 22:11:08.778023   463 sgd_solver.cpp:106] Iteration 3234, lr = 1e-05
I0810 22:11:34.160354   463 solver.cpp:242] Iteration 3256 (0.866738 iter/s, 25.3825s/22 iter), loss = 3.43459
I0810 22:11:34.160452   463 solver.cpp:261]     Train net output #0: loss_bbox = 0.486737 (* 2 = 0.973474 loss)
I0810 22:11:34.160467   463 solver.cpp:261]     Train net output #1: loss_coverage = 2.46111 (* 1 = 2.46111 loss)
I0810 22:11:34.160485   463 sgd_solver.cpp:106] Iteration 3256, lr = 1e-05
I0810 22:11:59.560686   463 solver.cpp:242] Iteration 3278 (0.866128 iter/s, 25.4004s/22 iter), loss = 10.2839
I0810 22:11:59.560757   463 solver.cpp:261]     Train net output #0: loss_bbox = 0.831497 (* 2 = 1.66299 loss)
I0810 22:11:59.560775   463 solver.cpp:261]     Train net output #1: loss_coverage = 8.62088 (* 1 = 8.62088 loss)
I0810 22:11:59.560794   463 sgd_solver.cpp:106] Iteration 3278, lr = 1e-05
I0810 22:12:24.978495   463 solver.cpp:242] Iteration 3300 (0.865532 iter/s, 25.4179s/22 iter), loss = 4.02384
I0810 22:12:24.978794   463 solver.cpp:261]     Train net output #0: loss_bbox = 0.636115 (* 2 = 1.27223 loss)
I0810 22:12:24.978811   463 solver.cpp:261]     Train net output #1: loss_coverage = 2.75161 (* 1 = 2.75161 loss)
I0810 22:12:24.978828   463 sgd_solver.cpp:106] Iteration 3300, lr = 1e-05
I0810 22:12:50.372448   463 solver.cpp:242] Iteration 3322 (0.866353 iter/s, 25.3938s/22 iter), loss = 6.65458
I0810 22:12:50.372516   463 solver.cpp:261]     Train net output #0: loss_bbox = 0.938742 (* 2 = 1.87748 loss)
I0810 22:12:50.372530   463 solver.cpp:261]     Train net output #1: loss_coverage = 4.77709 (* 1 = 4.77709 loss)
I0810 22:12:50.372547   463 sgd_solver.cpp:106] Iteration 3322, lr = 1e-05
I0810 22:13:15.754693   463 solver.cpp:242] Iteration 3344 (0.866745 iter/s, 25.3823s/22 iter), loss = 5.52853
I0810 22:13:15.755002   463 solver.cpp:261]     Train net output #0: loss_bbox = 0.687725 (* 2 = 1.37545 loss)
I0810 22:13:15.755020   463 solver.cpp:261]     Train net output #1: loss_coverage = 4.15308 (* 1 = 4.15308 loss)
I0810 22:13:15.755038   463 sgd_solver.cpp:106] Iteration 3344, lr = 1e-05
I0810 22:13:41.150682   463 solver.cpp:242] Iteration 3366 (0.866284 iter/s, 25.3958s/22 iter), loss = 14.4995
I0810 22:13:41.150745   463 solver.cpp:261]     Train net output #0: loss_bbox = 1.18357 (* 2 = 2.36715 loss)
I0810 22:13:41.150760   463 solver.cpp:261]     Train net output #1: loss_coverage = 12.1323 (* 1 = 12.1323 loss)
I0810 22:13:41.150777   463 sgd_solver.cpp:106] Iteration 3366, lr = 1e-05
I0810 22:13:58.426281   463 solver.cpp:479] Snapshotting to binary proto file snapshot_iter_3382.caffemodel
I0810 22:13:58.526814   463 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshot_iter_3382.solverstate
I0810 22:13:58.581008   463 solver.cpp:362] Iteration 3382, Testing net (#0)
I0810 22:13:58.581039   463 net.cpp:723] Ignoring source layer train_data
I0810 22:13:58.581048   463 net.cpp:723] Ignoring source layer train_label
I0810 22:13:58.581054   463 net.cpp:723] Ignoring source layer train_transform
I0810 22:14:09.520390   463 solver.cpp:429]     Test net output #0: loss_bbox = 0.65898 (* 2 = 1.31796 loss)
I0810 22:14:09.520426   463 solver.cpp:429]     Test net output #1: loss_coverage = 4.96125 (* 1 = 4.96125 loss)
I0810 22:14:09.520436   463 solver.cpp:429]     Test net output #2: mAP = 0
I0810 22:14:09.520442   463 solver.cpp:429]     Test net output #3: precision = 0
I0810 22:14:09.520450   463 solver.cpp:429]     Test net output #4: recall = 0
I0810 22:14:17.583999   463 solver.cpp:242] Iteration 3388 (0.60384 iter/s, 36.4335s/22 iter), loss = 6.44867
I0810 22:14:17.584061   463 solver.cpp:261]     Train net output #0: loss_bbox = 0.696796 (* 2 = 1.39359 loss)
I0810 22:14:17.584074   463 solver.cpp:261]     Train net output #1: loss_coverage = 5.05508 (* 1 = 5.05508 loss)
I0810 22:14:17.584091   463 sgd_solver.cpp:106] Iteration 3388, lr = 1e-05
I0810 22:14:42.962323   463 solver.cpp:242] Iteration 3410 (0.866878 iter/s, 25.3784s/22 iter), loss = 3.55087
I0810 22:14:42.962473   463 solver.cpp:261]     Train net output #0: loss_bbox = 0.576436 (* 2 = 1.15287 loss)
I0810 22:14:42.962488   463 solver.cpp:261]     Train net output #1: loss_coverage = 2.39799 (* 1 = 2.39799 loss)
I0810 22:14:42.962507   463 sgd_solver.cpp:106] Iteration 3410, lr = 1e-05
I0810 22:15:08.355211   463 solver.cpp:242] Iteration 3432 (0.866384 iter/s, 25.3929s/22 iter), loss = 5.39974
I0810 22:15:08.355273   463 solver.cpp:261]     Train net output #0: loss_bbox = 0.742004 (* 2 = 1.48401 loss)
I0810 22:15:08.355288   463 solver.cpp:261]     Train net output #1: loss_coverage = 3.91573 (* 1 = 3.91573 loss)
I0810 22:15:08.355305   463 sgd_solver.cpp:106] Iteration 3432, lr = 1e-05
I0810 22:15:33.699137   463 solver.cpp:242] Iteration 3454 (0.868056 iter/s, 25.344s/22 iter), loss = 6.02692
I0810 22:15:33.699388   463 solver.cpp:261]     Train net output #0: loss_bbox = 0.670603 (* 2 = 1.34121 loss)
I0810 22:15:33.699405   463 solver.cpp:261]     Train net output #1: loss_coverage = 4.68571 (* 1 = 4.68571 loss)
I0810 22:15:33.699424   463 sgd_solver.cpp:106] Iteration 3454, lr = 1e-05
I0810 22:15:59.099653   463 solver.cpp:242] Iteration 3476 (0.866127 iter/s, 25.4004s/22 iter), loss = 3.45925
I0810 22:15:59.099711   463 solver.cpp:261]     Train net output #0: loss_bbox = 0.483103 (* 2 = 0.966205 loss)
I0810 22:15:59.099725   463 solver.cpp:261]     Train net output #1: loss_coverage = 2.49304 (* 1 = 2.49304 loss)
I0810 22:15:59.099740   463 sgd_solver.cpp:106] Iteration 3476, lr = 1e-05
I0810 22:16:24.509047   463 solver.cpp:242] Iteration 3498 (0.865818 iter/s, 25.4095s/22 iter), loss = 7.29321
I0810 22:16:24.509198   463 solver.cpp:261]     Train net output #0: loss_bbox = 0.899041 (* 2 = 1.79808 loss)
I0810 22:16:24.509214   463 solver.cpp:261]     Train net output #1: loss_coverage = 5.49512 (* 1 = 5.49512 loss)
I0810 22:16:24.509232   463 sgd_solver.cpp:106] Iteration 3498, lr = 1e-05
I0810 22:16:49.876914   463 solver.cpp:242] Iteration 3520 (0.867239 iter/s, 25.3679s/22 iter), loss = 5.70351
I0810 22:16:49.876972   463 solver.cpp:261]     Train net output #0: loss_bbox = 0.762953 (* 2 = 1.52591 loss)
I0810 22:16:49.876986   463 solver.cpp:261]     Train net output #1: loss_coverage = 4.1776 (* 1 = 4.1776 loss)
I0810 22:16:49.877002   463 sgd_solver.cpp:106] Iteration 3520, lr = 1e-05
I0810 22:17:15.236953   463 solver.cpp:242] Iteration 3542 (0.867503 iter/s, 25.3601s/22 iter), loss = 7.22702
I0810 22:17:15.237221   463 solver.cpp:261]     Train net output #0: loss_bbox = 0.750019 (* 2 = 1.50004 loss)
I0810 22:17:15.237237   463 solver.cpp:261]     Train net output #1: loss_coverage = 5.72697 (* 1 = 5.72697 loss)
I0810 22:17:15.237257   463 sgd_solver.cpp:106] Iteration 3542, lr = 1e-05
I0810 22:17:34.851292   463 solver.cpp:479] Snapshotting to binary proto file snapshot_iter_3560.caffemodel
I0810 22:17:34.954797   463 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshot_iter_3560.solverstate
I0810 22:17:35.010462   463 solver.cpp:362] Iteration 3560, Testing net (#0)
I0810 22:17:35.010491   463 net.cpp:723] Ignoring source layer train_data
I0810 22:17:35.010499   463 net.cpp:723] Ignoring source layer train_label
I0810 22:17:35.010504   463 net.cpp:723] Ignoring source layer train_transform
I0810 22:17:45.971479   463 solver.cpp:429]     Test net output #0: loss_bbox = 0.610499 (* 2 = 1.221 loss)
I0810 22:17:45.971632   463 solver.cpp:429]     Test net output #1: loss_coverage = 5.41684 (* 1 = 5.41684 loss)
I0810 22:17:45.971643   463 solver.cpp:429]     Test net output #2: mAP = 0
I0810 22:17:45.971652   463 solver.cpp:429]     Test net output #3: precision = 0
I0810 22:17:45.971658   463 solver.cpp:429]     Test net output #4: recall = 0
I0810 22:17:51.732322   463 solver.cpp:242] Iteration 3564 (0.602817 iter/s, 36.4953s/22 iter), loss = 4.66814
I0810 22:17:51.732380   463 solver.cpp:261]     Train net output #0: loss_bbox = 0.494574 (* 2 = 0.989148 loss)
I0810 22:17:51.732393   463 solver.cpp:261]     Train net output #1: loss_coverage = 3.67899 (* 1 = 3.67899 loss)
I0810 22:17:51.732410   463 sgd_solver.cpp:106] Iteration 3564, lr = 1e-05
I0810 22:18:17.104614   463 solver.cpp:242] Iteration 3586 (0.867084 iter/s, 25.3724s/22 iter), loss = 5.12157
I0810 22:18:17.104856   463 solver.cpp:261]     Train net output #0: loss_bbox = 0.410389 (* 2 = 0.820778 loss)
I0810 22:18:17.104871   463 solver.cpp:261]     Train net output #1: loss_coverage = 4.30079 (* 1 = 4.30079 loss)
I0810 22:18:17.104908   463 sgd_solver.cpp:106] Iteration 3586, lr = 1e-05
I0810 22:18:42.494946   463 solver.cpp:242] Iteration 3608 (0.866474 iter/s, 25.3903s/22 iter), loss = 4.30895
I0810 22:18:42.495005   463 solver.cpp:261]     Train net output #0: loss_bbox = 0.655818 (* 2 = 1.31164 loss)
I0810 22:18:42.495018   463 solver.cpp:261]     Train net output #1: loss_coverage = 2.99731 (* 1 = 2.99731 loss)
I0810 22:18:42.495034   463 sgd_solver.cpp:106] Iteration 3608, lr = 1e-05
I0810 22:19:07.889499   463 solver.cpp:242] Iteration 3630 (0.866324 iter/s, 25.3946s/22 iter), loss = 6.66361
I0810 22:19:07.889627   463 solver.cpp:261]     Train net output #0: loss_bbox = 0.696252 (* 2 = 1.3925 loss)
I0810 22:19:07.889643   463 solver.cpp:261]     Train net output #1: loss_coverage = 5.2711 (* 1 = 5.2711 loss)
I0810 22:19:07.889662   463 sgd_solver.cpp:106] Iteration 3630, lr = 1e-05
I0810 22:19:33.281658   463 solver.cpp:242] Iteration 3652 (0.866408 iter/s, 25.3922s/22 iter), loss = 4.86422
I0810 22:19:33.281720   463 solver.cpp:261]     Train net output #0: loss_bbox = 0.646472 (* 2 = 1.29294 loss)
I0810 22:19:33.281734   463 solver.cpp:261]     Train net output #1: loss_coverage = 3.57128 (* 1 = 3.57128 loss)
I0810 22:19:33.281751   463 sgd_solver.cpp:106] Iteration 3652, lr = 1e-05
I0810 22:19:58.675199   463 solver.cpp:242] Iteration 3674 (0.866359 iter/s, 25.3936s/22 iter), loss = 9.70366
I0810 22:19:58.675628   463 solver.cpp:261]     Train net output #0: loss_bbox = 0.738791 (* 2 = 1.47758 loss)
I0810 22:19:58.675652   463 solver.cpp:261]     Train net output #1: loss_coverage = 8.22607 (* 1 = 8.22607 loss)
I0810 22:19:58.675675   463 sgd_solver.cpp:106] Iteration 3674, lr = 1e-05
I0810 22:20:24.061799   463 solver.cpp:242] Iteration 3696 (0.866608 iter/s, 25.3863s/22 iter), loss = 7.92376
I0810 22:20:24.061852   463 solver.cpp:261]     Train net output #0: loss_bbox = 0.921949 (* 2 = 1.8439 loss)
I0810 22:20:24.061866   463 solver.cpp:261]     Train net output #1: loss_coverage = 6.07985 (* 1 = 6.07985 loss)
I0810 22:20:24.061882   463 sgd_solver.cpp:106] Iteration 3696, lr = 1e-05
I0810 22:20:49.421942   463 solver.cpp:242] Iteration 3718 (0.867499 iter/s, 25.3602s/22 iter), loss = 6.62337
I0810 22:20:49.422227   463 solver.cpp:261]     Train net output #0: loss_bbox = 0.837755 (* 2 = 1.67551 loss)
I0810 22:20:49.422245   463 solver.cpp:261]     Train net output #1: loss_coverage = 4.94786 (* 1 = 4.94786 loss)
I0810 22:20:49.422263   463 sgd_solver.cpp:106] Iteration 3718, lr = 1e-05
I0810 22:21:11.372692   463 solver.cpp:479] Snapshotting to binary proto file snapshot_iter_3738.caffemodel
I0810 22:21:11.470217   463 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshot_iter_3738.solverstate
I0810 22:21:11.523159   463 solver.cpp:362] Iteration 3738, Testing net (#0)
I0810 22:21:11.523190   463 net.cpp:723] Ignoring source layer train_data
I0810 22:21:11.523196   463 net.cpp:723] Ignoring source layer train_label
I0810 22:21:11.523202   463 net.cpp:723] Ignoring source layer train_transform
I0810 22:21:22.485810   463 solver.cpp:429]     Test net output #0: loss_bbox = 0.581612 (* 2 = 1.16322 loss)
I0810 22:21:22.486012   463 solver.cpp:429]     Test net output #1: loss_coverage = 4.72392 (* 1 = 4.72392 loss)
I0810 22:21:22.486024   463 solver.cpp:429]     Test net output #2: mAP = 0
I0810 22:21:22.486033   463 solver.cpp:429]     Test net output #3: precision = 0
I0810 22:21:22.486040   463 solver.cpp:429]     Test net output #4: recall = 0
I0810 22:21:25.946547   463 solver.cpp:242] Iteration 3740 (0.602334 iter/s, 36.5246s/22 iter), loss = 4.95418
I0810 22:21:25.946607   463 solver.cpp:261]     Train net output #0: loss_bbox = 0.602927 (* 2 = 1.20585 loss)
I0810 22:21:25.946621   463 solver.cpp:261]     Train net output #1: loss_coverage = 3.74832 (* 1 = 3.74832 loss)
I0810 22:21:25.946640   463 sgd_solver.cpp:106] Iteration 3740, lr = 1e-05
I0810 22:21:51.335826   463 solver.cpp:242] Iteration 3762 (0.866504 iter/s, 25.3894s/22 iter), loss = 11.3129
I0810 22:21:51.335906   463 solver.cpp:261]     Train net output #0: loss_bbox = 0.82732 (* 2 = 1.65464 loss)
I0810 22:21:51.335919   463 solver.cpp:261]     Train net output #1: loss_coverage = 9.65821 (* 1 = 9.65821 loss)
I0810 22:21:51.335937   463 sgd_solver.cpp:106] Iteration 3762, lr = 1e-05
I0810 22:22:16.703372   463 solver.cpp:242] Iteration 3784 (0.867247 iter/s, 25.3676s/22 iter), loss = 3.85067
I0810 22:22:16.703752   463 solver.cpp:261]     Train net output #0: loss_bbox = 0.383646 (* 2 = 0.767292 loss)
I0810 22:22:16.703773   463 solver.cpp:261]     Train net output #1: loss_coverage = 3.08337 (* 1 = 3.08337 loss)
I0810 22:22:16.703795   463 sgd_solver.cpp:106] Iteration 3784, lr = 1e-05
I0810 22:22:42.096485   463 solver.cpp:242] Iteration 3806 (0.866384 iter/s, 25.3929s/22 iter), loss = 5.60493
I0810 22:22:42.096549   463 solver.cpp:261]     Train net output #0: loss_bbox = 0.620774 (* 2 = 1.24155 loss)
I0810 22:22:42.096565   463 solver.cpp:261]     Train net output #1: loss_coverage = 4.36338 (* 1 = 4.36338 loss)
I0810 22:22:42.096585   463 sgd_solver.cpp:106] Iteration 3806, lr = 1e-05
I0810 22:23:07.500967   463 solver.cpp:242] Iteration 3828 (0.865986 iter/s, 25.4046s/22 iter), loss = 4.76571
I0810 22:23:07.501343   463 solver.cpp:261]     Train net output #0: loss_bbox = 0.380442 (* 2 = 0.760884 loss)
I0810 22:23:07.501363   463 solver.cpp:261]     Train net output #1: loss_coverage = 4.00482 (* 1 = 4.00482 loss)
I0810 22:23:07.501384   463 sgd_solver.cpp:106] Iteration 3828, lr = 1e-05
I0810 22:23:32.918800   463 solver.cpp:242] Iteration 3850 (0.865541 iter/s, 25.4176s/22 iter), loss = 6.16148
I0810 22:23:32.918864   463 solver.cpp:261]     Train net output #0: loss_bbox = 0.623545 (* 2 = 1.24709 loss)
I0810 22:23:32.918879   463 solver.cpp:261]     Train net output #1: loss_coverage = 4.91439 (* 1 = 4.91439 loss)
I0810 22:23:32.918896   463 sgd_solver.cpp:106] Iteration 3850, lr = 1e-05
I0810 22:23:58.283649   463 solver.cpp:242] Iteration 3872 (0.867339 iter/s, 25.3649s/22 iter), loss = 6.59942
I0810 22:23:58.283944   463 solver.cpp:261]     Train net output #0: loss_bbox = 0.54423 (* 2 = 1.08846 loss)
I0810 22:23:58.283960   463 solver.cpp:261]     Train net output #1: loss_coverage = 5.51096 (* 1 = 5.51096 loss)
I0810 22:23:58.283978   463 sgd_solver.cpp:106] Iteration 3872, lr = 1e-05
I0810 22:24:23.705368   463 solver.cpp:242] Iteration 3894 (0.865407 iter/s, 25.4216s/22 iter), loss = 9.00405
I0810 22:24:23.705447   463 solver.cpp:261]     Train net output #0: loss_bbox = 0.727722 (* 2 = 1.45544 loss)
I0810 22:24:23.705461   463 solver.cpp:261]     Train net output #1: loss_coverage = 7.5486 (* 1 = 7.5486 loss)
I0810 22:24:23.705479   463 sgd_solver.cpp:106] Iteration 3894, lr = 1e-05
I0810 22:24:47.912268   463 solver.cpp:479] Snapshotting to binary proto file snapshot_iter_3916.caffemodel
I0810 22:24:48.011826   463 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshot_iter_3916.solverstate
I0810 22:24:48.069658   463 solver.cpp:362] Iteration 3916, Testing net (#0)
I0810 22:24:48.069680   463 net.cpp:723] Ignoring source layer train_data
I0810 22:24:48.069687   463 net.cpp:723] Ignoring source layer train_label
I0810 22:24:48.069694   463 net.cpp:723] Ignoring source layer train_transform
I0810 22:24:59.058516   463 solver.cpp:429]     Test net output #0: loss_bbox = 0.561305 (* 2 = 1.12261 loss)
I0810 22:24:59.058562   463 solver.cpp:429]     Test net output #1: loss_coverage = 4.94366 (* 1 = 4.94366 loss)
I0810 22:24:59.058573   463 solver.cpp:429]     Test net output #2: mAP = 0
I0810 22:24:59.058579   463 solver.cpp:429]     Test net output #3: precision = 0
I0810 22:24:59.058588   463 solver.cpp:429]     Test net output #4: recall = 0
I0810 22:25:00.218519   463 solver.cpp:242] Iteration 3916 (0.60252 iter/s, 36.5133s/22 iter), loss = 8.868
I0810 22:25:00.218580   463 solver.cpp:261]     Train net output #0: loss_bbox = 0.628454 (* 2 = 1.25691 loss)
I0810 22:25:00.218595   463 solver.cpp:261]     Train net output #1: loss_coverage = 7.61109 (* 1 = 7.61109 loss)
I0810 22:25:00.218611   463 sgd_solver.cpp:106] Iteration 3916, lr = 1e-05
I0810 22:25:25.624485   463 solver.cpp:242] Iteration 3938 (0.865935 iter/s, 25.4061s/22 iter), loss = 4.47394
I0810 22:25:25.624791   463 solver.cpp:261]     Train net output #0: loss_bbox = 0.41659 (* 2 = 0.83318 loss)
I0810 22:25:25.624811   463 solver.cpp:261]     Train net output #1: loss_coverage = 3.64075 (* 1 = 3.64075 loss)
I0810 22:25:25.624832   463 sgd_solver.cpp:106] Iteration 3938, lr = 1e-05
I0810 22:25:51.008122   463 solver.cpp:242] Iteration 3960 (0.866706 iter/s, 25.3835s/22 iter), loss = 4.56823
I0810 22:25:51.008173   463 solver.cpp:261]     Train net output #0: loss_bbox = 0.464341 (* 2 = 0.928683 loss)
I0810 22:25:51.008186   463 solver.cpp:261]     Train net output #1: loss_coverage = 3.63954 (* 1 = 3.63954 loss)
I0810 22:25:51.008203   463 sgd_solver.cpp:106] Iteration 3960, lr = 1e-05
I0810 22:26:16.399425   463 solver.cpp:242] Iteration 3982 (0.866435 iter/s, 25.3914s/22 iter), loss = 7.10792
I0810 22:26:16.399664   463 solver.cpp:261]     Train net output #0: loss_bbox = 0.726413 (* 2 = 1.45283 loss)
I0810 22:26:16.399682   463 solver.cpp:261]     Train net output #1: loss_coverage = 5.65509 (* 1 = 5.65509 loss)
I0810 22:26:16.399711   463 sgd_solver.cpp:106] Iteration 3982, lr = 1e-05
I0810 22:26:41.766849   463 solver.cpp:242] Iteration 4004 (0.867257 iter/s, 25.3673s/22 iter), loss = 9.24439
I0810 22:26:41.766916   463 solver.cpp:261]     Train net output #0: loss_bbox = 0.752282 (* 2 = 1.50456 loss)
I0810 22:26:41.766932   463 solver.cpp:261]     Train net output #1: loss_coverage = 7.73982 (* 1 = 7.73982 loss)
I0810 22:26:41.766952   463 sgd_solver.cpp:106] Iteration 4004, lr = 1e-05
I0810 22:27:07.117344   463 solver.cpp:242] Iteration 4026 (0.86783 iter/s, 25.3506s/22 iter), loss = 3.28044
I0810 22:27:07.117579   463 solver.cpp:261]     Train net output #0: loss_bbox = 0.347142 (* 2 = 0.694283 loss)
I0810 22:27:07.117599   463 solver.cpp:261]     Train net output #1: loss_coverage = 2.58615 (* 1 = 2.58615 loss)
I0810 22:27:07.117619   463 sgd_solver.cpp:106] Iteration 4026, lr = 1e-05
I0810 22:27:32.506057   463 solver.cpp:242] Iteration 4048 (0.866529 iter/s, 25.3886s/22 iter), loss = 8.37185
I0810 22:27:32.506145   463 solver.cpp:261]     Train net output #0: loss_bbox = 0.832773 (* 2 = 1.66555 loss)
I0810 22:27:32.506160   463 solver.cpp:261]     Train net output #1: loss_coverage = 6.7063 (* 1 = 6.7063 loss)
I0810 22:27:32.506177   463 sgd_solver.cpp:106] Iteration 4048, lr = 1e-05
I0810 22:27:57.907990   463 solver.cpp:242] Iteration 4070 (0.866073 iter/s, 25.402s/22 iter), loss = 7.29855
I0810 22:27:57.908257   463 solver.cpp:261]     Train net output #0: loss_bbox = 0.534295 (* 2 = 1.06859 loss)
I0810 22:27:57.908274   463 solver.cpp:261]     Train net output #1: loss_coverage = 6.22995 (* 1 = 6.22995 loss)
I0810 22:27:57.908293   463 sgd_solver.cpp:106] Iteration 4070, lr = 1e-05
I0810 22:28:23.297690   463 solver.cpp:242] Iteration 4092 (0.866496 iter/s, 25.3896s/22 iter), loss = 2.2652
I0810 22:28:23.297750   463 solver.cpp:261]     Train net output #0: loss_bbox = 0.27438 (* 2 = 0.54876 loss)
I0810 22:28:23.297763   463 solver.cpp:261]     Train net output #1: loss_coverage = 1.71643 (* 1 = 1.71643 loss)
I0810 22:28:23.297780   463 sgd_solver.cpp:106] Iteration 4092, lr = 1e-05
I0810 22:28:24.447718   463 solver.cpp:479] Snapshotting to binary proto file snapshot_iter_4094.caffemodel
I0810 22:28:24.548275   463 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshot_iter_4094.solverstate
I0810 22:28:24.605455   463 solver.cpp:362] Iteration 4094, Testing net (#0)
I0810 22:28:24.605507   463 net.cpp:723] Ignoring source layer train_data
I0810 22:28:24.605515   463 net.cpp:723] Ignoring source layer train_label
I0810 22:28:24.605521   463 net.cpp:723] Ignoring source layer train_transform
I0810 22:28:35.535274   463 solver.cpp:429]     Test net output #0: loss_bbox = 0.566496 (* 2 = 1.13299 loss)
I0810 22:28:35.535477   463 solver.cpp:429]     Test net output #1: loss_coverage = 4.96411 (* 1 = 4.96411 loss)
I0810 22:28:35.535490   463 solver.cpp:429]     Test net output #2: mAP = 0
I0810 22:28:35.535497   463 solver.cpp:429]     Test net output #3: precision = 0
I0810 22:28:35.535504   463 solver.cpp:429]     Test net output #4: recall = 0
I0810 22:28:59.764968   463 solver.cpp:242] Iteration 4114 (0.603278 iter/s, 36.4675s/22 iter), loss = 11.5638
I0810 22:28:59.765025   463 solver.cpp:261]     Train net output #0: loss_bbox = 0.770704 (* 2 = 1.54141 loss)
I0810 22:28:59.765039   463 solver.cpp:261]     Train net output #1: loss_coverage = 10.0224 (* 1 = 10.0224 loss)
I0810 22:28:59.765056   463 sgd_solver.cpp:106] Iteration 4114, lr = 1e-05
I0810 22:29:25.171192   463 solver.cpp:242] Iteration 4136 (0.865926 iter/s, 25.4063s/22 iter), loss = 4.73691
I0810 22:29:25.171452   463 solver.cpp:261]     Train net output #0: loss_bbox = 0.375549 (* 2 = 0.751098 loss)
I0810 22:29:25.171469   463 solver.cpp:261]     Train net output #1: loss_coverage = 3.9858 (* 1 = 3.9858 loss)
I0810 22:29:25.171490   463 sgd_solver.cpp:106] Iteration 4136, lr = 1e-05
I0810 22:29:50.527489   463 solver.cpp:242] Iteration 4158 (0.867638 iter/s, 25.3562s/22 iter), loss = 5.35237
I0810 22:29:50.527550   463 solver.cpp:261]     Train net output #0: loss_bbox = 0.509668 (* 2 = 1.01934 loss)
I0810 22:29:50.527564   463 solver.cpp:261]     Train net output #1: loss_coverage = 4.33303 (* 1 = 4.33303 loss)
I0810 22:29:50.527581   463 sgd_solver.cpp:106] Iteration 4158, lr = 1e-05
I0810 22:30:15.889828   463 solver.cpp:242] Iteration 4180 (0.867424 iter/s, 25.3624s/22 iter), loss = 9.47004
I0810 22:30:15.890174   463 solver.cpp:261]     Train net output #0: loss_bbox = 0.842388 (* 2 = 1.68478 loss)
I0810 22:30:15.890194   463 solver.cpp:261]     Train net output #1: loss_coverage = 7.78526 (* 1 = 7.78526 loss)
I0810 22:30:15.890214   463 sgd_solver.cpp:106] Iteration 4180, lr = 1e-05
I0810 22:30:41.261569   463 solver.cpp:242] Iteration 4202 (0.867113 iter/s, 25.3716s/22 iter), loss = 7.88583
I0810 22:30:41.261632   463 solver.cpp:261]     Train net output #0: loss_bbox = 0.498174 (* 2 = 0.996348 loss)
I0810 22:30:41.261647   463 solver.cpp:261]     Train net output #1: loss_coverage = 6.88947 (* 1 = 6.88947 loss)
I0810 22:30:41.261664   463 sgd_solver.cpp:106] Iteration 4202, lr = 1e-05
I0810 22:31:06.622459   463 solver.cpp:242] Iteration 4224 (0.867474 iter/s, 25.361s/22 iter), loss = 4.59359
I0810 22:31:06.622797   463 solver.cpp:261]     Train net output #0: loss_bbox = 0.471039 (* 2 = 0.942077 loss)
I0810 22:31:06.622817   463 solver.cpp:261]     Train net output #1: loss_coverage = 3.65151 (* 1 = 3.65151 loss)
I0810 22:31:06.622838   463 sgd_solver.cpp:106] Iteration 4224, lr = 1e-05
I0810 22:31:32.016979   463 solver.cpp:242] Iteration 4246 (0.866334 iter/s, 25.3943s/22 iter), loss = 11.2763
I0810 22:31:32.017040   463 solver.cpp:261]     Train net output #0: loss_bbox = 0.478011 (* 2 = 0.956022 loss)
I0810 22:31:32.017052   463 solver.cpp:261]     Train net output #1: loss_coverage = 10.3203 (* 1 = 10.3203 loss)
I0810 22:31:32.017071   463 sgd_solver.cpp:106] Iteration 4246, lr = 1e-05
I0810 22:31:57.397145   463 solver.cpp:242] Iteration 4268 (0.866816 iter/s, 25.3803s/22 iter), loss = 5.70985
I0810 22:31:57.397480   463 solver.cpp:261]     Train net output #0: loss_bbox = 0.430859 (* 2 = 0.861718 loss)
I0810 22:31:57.397496   463 solver.cpp:261]     Train net output #1: loss_coverage = 4.84813 (* 1 = 4.84813 loss)
I0810 22:31:57.397514   463 sgd_solver.cpp:106] Iteration 4268, lr = 1e-05
I0810 22:32:00.848821   463 solver.cpp:479] Snapshotting to binary proto file snapshot_iter_4272.caffemodel
I0810 22:32:00.948848   463 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshot_iter_4272.solverstate
I0810 22:32:01.003579   463 solver.cpp:362] Iteration 4272, Testing net (#0)
I0810 22:32:01.003612   463 net.cpp:723] Ignoring source layer train_data
I0810 22:32:01.003620   463 net.cpp:723] Ignoring source layer train_label
I0810 22:32:01.003628   463 net.cpp:723] Ignoring source layer train_transform
I0810 22:32:11.966713   463 solver.cpp:429]     Test net output #0: loss_bbox = 0.558636 (* 2 = 1.11727 loss)
I0810 22:32:11.966749   463 solver.cpp:429]     Test net output #1: loss_coverage = 4.98995 (* 1 = 4.98995 loss)
I0810 22:32:11.966758   463 solver.cpp:429]     Test net output #2: mAP = 0
I0810 22:32:11.966765   463 solver.cpp:429]     Test net output #3: precision = 0
I0810 22:32:11.966773   463 solver.cpp:429]     Test net output #4: recall = 0
I0810 22:32:33.861825   463 solver.cpp:242] Iteration 4290 (0.603325 iter/s, 36.4646s/22 iter), loss = 4.92672
I0810 22:32:33.862130   463 solver.cpp:261]     Train net output #0: loss_bbox = 0.517543 (* 2 = 1.03509 loss)
I0810 22:32:33.862154   463 solver.cpp:261]     Train net output #1: loss_coverage = 3.89163 (* 1 = 3.89163 loss)
I0810 22:32:33.862177   463 sgd_solver.cpp:106] Iteration 4290, lr = 1e-05
I0810 22:32:59.283288   463 solver.cpp:242] Iteration 4312 (0.865414 iter/s, 25.4213s/22 iter), loss = 8.50035
I0810 22:32:59.283361   463 solver.cpp:261]     Train net output #0: loss_bbox = 0.543469 (* 2 = 1.08694 loss)
I0810 22:32:59.283378   463 solver.cpp:261]     Train net output #1: loss_coverage = 7.4134 (* 1 = 7.4134 loss)
I0810 22:32:59.283398   463 sgd_solver.cpp:106] Iteration 4312, lr = 1e-05
I0810 22:33:24.701752   463 solver.cpp:242] Iteration 4334 (0.865509 iter/s, 25.4186s/22 iter), loss = 4.80871
I0810 22:33:24.702091   463 solver.cpp:261]     Train net output #0: loss_bbox = 0.436865 (* 2 = 0.87373 loss)
I0810 22:33:24.702108   463 solver.cpp:261]     Train net output #1: loss_coverage = 3.93498 (* 1 = 3.93498 loss)
I0810 22:33:24.702126   463 sgd_solver.cpp:106] Iteration 4334, lr = 1e-05
I0810 22:33:50.207891   463 solver.cpp:242] Iteration 4356 (0.862543 iter/s, 25.506s/22 iter), loss = 3.52989
I0810 22:33:50.207948   463 solver.cpp:261]     Train net output #0: loss_bbox = 0.340253 (* 2 = 0.680506 loss)
I0810 22:33:50.207962   463 solver.cpp:261]     Train net output #1: loss_coverage = 2.84938 (* 1 = 2.84938 loss)
I0810 22:33:50.207978   463 sgd_solver.cpp:106] Iteration 4356, lr = 1e-05
I0810 22:34:15.940608   463 solver.cpp:242] Iteration 4378 (0.854939 iter/s, 25.7328s/22 iter), loss = 6.01019
I0810 22:34:15.940912   463 solver.cpp:261]     Train net output #0: loss_bbox = 0.575811 (* 2 = 1.15162 loss)
I0810 22:34:15.940934   463 solver.cpp:261]     Train net output #1: loss_coverage = 4.85856 (* 1 = 4.85856 loss)
I0810 22:34:15.940958   463 sgd_solver.cpp:106] Iteration 4378, lr = 1e-05
I0810 22:34:41.656487   463 solver.cpp:242] Iteration 4400 (0.855506 iter/s, 25.7158s/22 iter), loss = 4.86257
I0810 22:34:41.656563   463 solver.cpp:261]     Train net output #0: loss_bbox = 0.499368 (* 2 = 0.998736 loss)
I0810 22:34:41.656576   463 solver.cpp:261]     Train net output #1: loss_coverage = 3.86383 (* 1 = 3.86383 loss)
I0810 22:34:41.656594   463 sgd_solver.cpp:106] Iteration 4400, lr = 1e-05
I0810 22:35:07.389691   463 solver.cpp:242] Iteration 4422 (0.854923 iter/s, 25.7333s/22 iter), loss = 4.05908
I0810 22:35:07.389905   463 solver.cpp:261]     Train net output #0: loss_bbox = 0.286948 (* 2 = 0.573896 loss)
I0810 22:35:07.389921   463 solver.cpp:261]     Train net output #1: loss_coverage = 3.48517 (* 1 = 3.48517 loss)
I0810 22:35:07.389938   463 sgd_solver.cpp:106] Iteration 4422, lr = 1e-05
I0810 22:35:33.143203   463 solver.cpp:242] Iteration 4444 (0.854252 iter/s, 25.7535s/22 iter), loss = 3.82292
I0810 22:35:33.143263   463 solver.cpp:261]     Train net output #0: loss_bbox = 0.335256 (* 2 = 0.670512 loss)
I0810 22:35:33.143276   463 solver.cpp:261]     Train net output #1: loss_coverage = 3.1524 (* 1 = 3.1524 loss)
I0810 22:35:33.143293   463 sgd_solver.cpp:106] Iteration 4444, lr = 1e-05
I0810 22:35:38.984856   463 solver.cpp:479] Snapshotting to binary proto file snapshot_iter_4450.caffemodel
I0810 22:35:39.084404   463 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshot_iter_4450.solverstate
I0810 22:35:39.144613   463 solver.cpp:362] Iteration 4450, Testing net (#0)
I0810 22:35:39.144654   463 net.cpp:723] Ignoring source layer train_data
I0810 22:35:39.144662   463 net.cpp:723] Ignoring source layer train_label
I0810 22:35:39.144668   463 net.cpp:723] Ignoring source layer train_transform
I0810 22:35:50.274482   463 solver.cpp:429]     Test net output #0: loss_bbox = 0.573267 (* 2 = 1.14653 loss)
I0810 22:35:50.274516   463 solver.cpp:429]     Test net output #1: loss_coverage = 5.35515 (* 1 = 5.35515 loss)
I0810 22:35:50.274525   463 solver.cpp:429]     Test net output #2: mAP = 0
I0810 22:35:50.274533   463 solver.cpp:429]     Test net output #3: precision = 0
I0810 22:35:50.274549   463 solver.cpp:429]     Test net output #4: recall = 0
I0810 22:36:10.149626   463 solver.cpp:242] Iteration 4466 (0.594487 iter/s, 37.0067s/22 iter), loss = 6.08791
I0810 22:36:10.149796   463 solver.cpp:261]     Train net output #0: loss_bbox = 0.48461 (* 2 = 0.969221 loss)
I0810 22:36:10.149812   463 solver.cpp:261]     Train net output #1: loss_coverage = 5.11869 (* 1 = 5.11869 loss)
I0810 22:36:10.149829   463 sgd_solver.cpp:106] Iteration 4466, lr = 1e-05
I0810 22:36:35.899744   463 solver.cpp:242] Iteration 4488 (0.854363 iter/s, 25.7502s/22 iter), loss = 6.18259
I0810 22:36:35.899803   463 solver.cpp:261]     Train net output #0: loss_bbox = 0.491181 (* 2 = 0.982363 loss)
I0810 22:36:35.899816   463 solver.cpp:261]     Train net output #1: loss_coverage = 5.20022 (* 1 = 5.20022 loss)
I0810 22:36:35.899833   463 sgd_solver.cpp:106] Iteration 4488, lr = 1e-05
I0810 22:37:01.633585   463 solver.cpp:242] Iteration 4510 (0.8549 iter/s, 25.734s/22 iter), loss = 4.38083
I0810 22:37:01.633857   463 solver.cpp:261]     Train net output #0: loss_bbox = 0.482526 (* 2 = 0.965051 loss)
I0810 22:37:01.633877   463 solver.cpp:261]     Train net output #1: loss_coverage = 3.41577 (* 1 = 3.41577 loss)
I0810 22:37:01.633899   463 sgd_solver.cpp:106] Iteration 4510, lr = 1e-05
I0810 22:37:27.330893   463 solver.cpp:242] Iteration 4532 (0.856122 iter/s, 25.6973s/22 iter), loss = 5.92985
I0810 22:37:27.330952   463 solver.cpp:261]     Train net output #0: loss_bbox = 0.49484 (* 2 = 0.98968 loss)
I0810 22:37:27.330965   463 solver.cpp:261]     Train net output #1: loss_coverage = 4.94017 (* 1 = 4.94017 loss)
I0810 22:37:27.330981   463 sgd_solver.cpp:106] Iteration 4532, lr = 1e-05
I0810 22:37:53.024808   463 solver.cpp:242] Iteration 4554 (0.856228 iter/s, 25.6941s/22 iter), loss = 4.79458
I0810 22:37:53.025056   463 solver.cpp:261]     Train net output #0: loss_bbox = 0.428329 (* 2 = 0.856658 loss)
I0810 22:37:53.025080   463 solver.cpp:261]     Train net output #1: loss_coverage = 3.93792 (* 1 = 3.93792 loss)
I0810 22:37:53.025099   463 sgd_solver.cpp:106] Iteration 4554, lr = 1e-05
I0810 22:38:18.696957   463 solver.cpp:242] Iteration 4576 (0.85696 iter/s, 25.6721s/22 iter), loss = 6.24154
I0810 22:38:18.697013   463 solver.cpp:261]     Train net output #0: loss_bbox = 0.622265 (* 2 = 1.24453 loss)
I0810 22:38:18.697026   463 solver.cpp:261]     Train net output #1: loss_coverage = 4.99701 (* 1 = 4.99701 loss)
I0810 22:38:18.697044   463 sgd_solver.cpp:106] Iteration 4576, lr = 1e-05
I0810 22:38:44.413247   463 solver.cpp:242] Iteration 4598 (0.855484 iter/s, 25.7164s/22 iter), loss = 6.90672
I0810 22:38:44.413743   463 solver.cpp:261]     Train net output #0: loss_bbox = 0.562363 (* 2 = 1.12473 loss)
I0810 22:38:44.413767   463 solver.cpp:261]     Train net output #1: loss_coverage = 5.78199 (* 1 = 5.78199 loss)
I0810 22:38:44.413795   463 sgd_solver.cpp:106] Iteration 4598, lr = 1e-05
I0810 22:39:10.089088   463 solver.cpp:242] Iteration 4620 (0.856845 iter/s, 25.6756s/22 iter), loss = 2.78734
I0810 22:39:10.089177   463 solver.cpp:261]     Train net output #0: loss_bbox = 0.374283 (* 2 = 0.748567 loss)
I0810 22:39:10.089215   463 solver.cpp:261]     Train net output #1: loss_coverage = 2.03876 (* 1 = 2.03876 loss)
I0810 22:39:10.089233   463 sgd_solver.cpp:106] Iteration 4620, lr = 1e-05
I0810 22:39:18.270275   463 solver.cpp:479] Snapshotting to binary proto file snapshot_iter_4628.caffemodel
I0810 22:39:18.369992   463 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshot_iter_4628.solverstate
I0810 22:39:18.424623   463 solver.cpp:362] Iteration 4628, Testing net (#0)
I0810 22:39:18.424651   463 net.cpp:723] Ignoring source layer train_data
I0810 22:39:18.424661   463 net.cpp:723] Ignoring source layer train_label
I0810 22:39:18.424669   463 net.cpp:723] Ignoring source layer train_transform
I0810 22:39:29.558487   463 solver.cpp:429]     Test net output #0: loss_bbox = 0.570781 (* 2 = 1.14156 loss)
I0810 22:39:29.558522   463 solver.cpp:429]     Test net output #1: loss_coverage = 5.57452 (* 1 = 5.57452 loss)
I0810 22:39:29.558531   463 solver.cpp:429]     Test net output #2: mAP = 0
I0810 22:39:29.558549   463 solver.cpp:429]     Test net output #3: precision = 0
I0810 22:39:29.558557   463 solver.cpp:429]     Test net output #4: recall = 0
I0810 22:39:47.064352   463 solver.cpp:242] Iteration 4642 (0.594988 iter/s, 36.9755s/22 iter), loss = 6.90066
I0810 22:39:47.064407   463 solver.cpp:261]     Train net output #0: loss_bbox = 0.634052 (* 2 = 1.2681 loss)
I0810 22:39:47.064421   463 solver.cpp:261]     Train net output #1: loss_coverage = 5.63255 (* 1 = 5.63255 loss)
I0810 22:39:47.064437   463 sgd_solver.cpp:106] Iteration 4642, lr = 1e-05
I0810 22:40:12.755087   463 solver.cpp:242] Iteration 4664 (0.856334 iter/s, 25.6909s/22 iter), loss = 4.7225
I0810 22:40:12.755405   463 solver.cpp:261]     Train net output #0: loss_bbox = 0.40386 (* 2 = 0.807721 loss)
I0810 22:40:12.755424   463 solver.cpp:261]     Train net output #1: loss_coverage = 3.91477 (* 1 = 3.91477 loss)
I0810 22:40:12.755442   463 sgd_solver.cpp:106] Iteration 4664, lr = 1e-05
I0810 22:40:38.453495   463 solver.cpp:242] Iteration 4686 (0.856087 iter/s, 25.6983s/22 iter), loss = 5.89785
I0810 22:40:38.453552   463 solver.cpp:261]     Train net output #0: loss_bbox = 0.46143 (* 2 = 0.922861 loss)
I0810 22:40:38.453564   463 solver.cpp:261]     Train net output #1: loss_coverage = 4.97498 (* 1 = 4.97498 loss)
I0810 22:40:38.453588   463 sgd_solver.cpp:106] Iteration 4686, lr = 1e-05
I0810 22:41:04.145391   463 solver.cpp:242] Iteration 4708 (0.856296 iter/s, 25.6921s/22 iter), loss = 7.81129
I0810 22:41:04.145807   463 solver.cpp:261]     Train net output #0: loss_bbox = 0.574051 (* 2 = 1.1481 loss)
I0810 22:41:04.145828   463 solver.cpp:261]     Train net output #1: loss_coverage = 6.66318 (* 1 = 6.66318 loss)
I0810 22:41:04.145849   463 sgd_solver.cpp:106] Iteration 4708, lr = 1e-06
I0810 22:41:29.847260   463 solver.cpp:242] Iteration 4730 (0.855975 iter/s, 25.7017s/22 iter), loss = 4.41357
I0810 22:41:29.847321   463 solver.cpp:261]     Train net output #0: loss_bbox = 0.484704 (* 2 = 0.969408 loss)
I0810 22:41:29.847333   463 solver.cpp:261]     Train net output #1: loss_coverage = 3.44415 (* 1 = 3.44415 loss)
I0810 22:41:29.847350   463 sgd_solver.cpp:106] Iteration 4730, lr = 1e-06
I0810 22:41:55.510426   463 solver.cpp:242] Iteration 4752 (0.857255 iter/s, 25.6633s/22 iter), loss = 3.73924
I0810 22:41:55.510637   463 solver.cpp:261]     Train net output #0: loss_bbox = 0.417763 (* 2 = 0.835526 loss)
I0810 22:41:55.510653   463 solver.cpp:261]     Train net output #1: loss_coverage = 2.90371 (* 1 = 2.90371 loss)
I0810 22:41:55.510671   463 sgd_solver.cpp:106] Iteration 4752, lr = 1e-06
I0810 22:42:21.234823   463 solver.cpp:242] Iteration 4774 (0.855219 iter/s, 25.7244s/22 iter), loss = 6.31452
I0810 22:42:21.234882   463 solver.cpp:261]     Train net output #0: loss_bbox = 0.628553 (* 2 = 1.25711 loss)
I0810 22:42:21.234895   463 solver.cpp:261]     Train net output #1: loss_coverage = 5.05741 (* 1 = 5.05741 loss)
I0810 22:42:21.234912   463 sgd_solver.cpp:106] Iteration 4774, lr = 1e-06
I0810 22:42:46.897727   463 solver.cpp:242] Iteration 4796 (0.857263 iter/s, 25.6631s/22 iter), loss = 5.44042
I0810 22:42:46.898027   463 solver.cpp:261]     Train net output #0: loss_bbox = 0.427746 (* 2 = 0.855491 loss)
I0810 22:42:46.898047   463 solver.cpp:261]     Train net output #1: loss_coverage = 4.58492 (* 1 = 4.58492 loss)
I0810 22:42:46.898067   463 sgd_solver.cpp:106] Iteration 4796, lr = 1e-06
I0810 22:42:57.402148   463 solver.cpp:479] Snapshotting to binary proto file snapshot_iter_4806.caffemodel
I0810 22:42:57.501487   463 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshot_iter_4806.solverstate
I0810 22:42:57.556116   463 solver.cpp:362] Iteration 4806, Testing net (#0)
I0810 22:42:57.556149   463 net.cpp:723] Ignoring source layer train_data
I0810 22:42:57.556155   463 net.cpp:723] Ignoring source layer train_label
I0810 22:42:57.556161   463 net.cpp:723] Ignoring source layer train_transform
I0810 22:43:08.678028   463 solver.cpp:429]     Test net output #0: loss_bbox = 0.572699 (* 2 = 1.1454 loss)
I0810 22:43:08.678067   463 solver.cpp:429]     Test net output #1: loss_coverage = 5.12827 (* 1 = 5.12827 loss)
I0810 22:43:08.678076   463 solver.cpp:429]     Test net output #2: mAP = 0
I0810 22:43:08.678084   463 solver.cpp:429]     Test net output #3: precision = 0
I0810 22:43:08.678092   463 solver.cpp:429]     Test net output #4: recall = 0
I0810 22:43:23.872011   463 solver.cpp:242] Iteration 4818 (0.595008 iter/s, 36.9743s/22 iter), loss = 3.98551
I0810 22:43:23.872285   463 solver.cpp:261]     Train net output #0: loss_bbox = 0.37474 (* 2 = 0.74948 loss)
I0810 22:43:23.872301   463 solver.cpp:261]     Train net output #1: loss_coverage = 3.23603 (* 1 = 3.23603 loss)
I0810 22:43:23.872318   463 sgd_solver.cpp:106] Iteration 4818, lr = 1e-06
I0810 22:43:49.538118   463 solver.cpp:242] Iteration 4840 (0.857163 iter/s, 25.6661s/22 iter), loss = 8.49692
I0810 22:43:49.538177   463 solver.cpp:261]     Train net output #0: loss_bbox = 0.726634 (* 2 = 1.45327 loss)
I0810 22:43:49.538192   463 solver.cpp:261]     Train net output #1: loss_coverage = 7.04364 (* 1 = 7.04364 loss)
I0810 22:43:49.538208   463 sgd_solver.cpp:106] Iteration 4840, lr = 1e-06
I0810 22:44:15.215873   463 solver.cpp:242] Iteration 4862 (0.856768 iter/s, 25.6779s/22 iter), loss = 5.06675
I0810 22:44:15.216305   463 solver.cpp:261]     Train net output #0: loss_bbox = 0.467917 (* 2 = 0.935834 loss)
I0810 22:44:15.216325   463 solver.cpp:261]     Train net output #1: loss_coverage = 4.13091 (* 1 = 4.13091 loss)
I0810 22:44:15.216347   463 sgd_solver.cpp:106] Iteration 4862, lr = 1e-06
I0810 22:44:40.895571   463 solver.cpp:242] Iteration 4884 (0.856715 iter/s, 25.6795s/22 iter), loss = 6.91145
I0810 22:44:40.895637   463 solver.cpp:261]     Train net output #0: loss_bbox = 0.581334 (* 2 = 1.16267 loss)
I0810 22:44:40.895653   463 solver.cpp:261]     Train net output #1: loss_coverage = 5.74878 (* 1 = 5.74878 loss)
I0810 22:44:40.895673   463 sgd_solver.cpp:106] Iteration 4884, lr = 1e-06
I0810 22:45:06.601466   463 solver.cpp:242] Iteration 4906 (0.85583 iter/s, 25.7061s/22 iter), loss = 7.80424
I0810 22:45:06.601727   463 solver.cpp:261]     Train net output #0: loss_bbox = 0.548279 (* 2 = 1.09656 loss)
I0810 22:45:06.601747   463 solver.cpp:261]     Train net output #1: loss_coverage = 6.70767 (* 1 = 6.70767 loss)
I0810 22:45:06.601768   463 sgd_solver.cpp:106] Iteration 4906, lr = 1e-06
I0810 22:45:32.310853   463 solver.cpp:242] Iteration 4928 (0.85572 iter/s, 25.7094s/22 iter), loss = 6.55555
I0810 22:45:32.310914   463 solver.cpp:261]     Train net output #0: loss_bbox = 0.594469 (* 2 = 1.18894 loss)
I0810 22:45:32.310926   463 solver.cpp:261]     Train net output #1: loss_coverage = 5.36661 (* 1 = 5.36661 loss)
I0810 22:45:32.310942   463 sgd_solver.cpp:106] Iteration 4928, lr = 1e-06
I0810 22:45:58.038287   463 solver.cpp:242] Iteration 4950 (0.855113 iter/s, 25.7276s/22 iter), loss = 7.3402
I0810 22:45:58.038574   463 solver.cpp:261]     Train net output #0: loss_bbox = 0.457472 (* 2 = 0.914943 loss)
I0810 22:45:58.038595   463 solver.cpp:261]     Train net output #1: loss_coverage = 6.42525 (* 1 = 6.42525 loss)
I0810 22:45:58.038617   463 sgd_solver.cpp:106] Iteration 4950, lr = 1e-06
I0810 22:46:23.778439   463 solver.cpp:242] Iteration 4972 (0.854697 iter/s, 25.7401s/22 iter), loss = 3.99301
I0810 22:46:23.778497   463 solver.cpp:261]     Train net output #0: loss_bbox = 0.466118 (* 2 = 0.932236 loss)
I0810 22:46:23.778509   463 solver.cpp:261]     Train net output #1: loss_coverage = 3.06076 (* 1 = 3.06076 loss)
I0810 22:46:23.778527   463 sgd_solver.cpp:106] Iteration 4972, lr = 1e-06
I0810 22:46:36.631872   463 solver.cpp:479] Snapshotting to binary proto file snapshot_iter_4984.caffemodel
I0810 22:46:36.730687   463 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshot_iter_4984.solverstate
I0810 22:46:36.784483   463 solver.cpp:362] Iteration 4984, Testing net (#0)
I0810 22:46:36.784512   463 net.cpp:723] Ignoring source layer train_data
I0810 22:46:36.784520   463 net.cpp:723] Ignoring source layer train_label
I0810 22:46:36.784526   463 net.cpp:723] Ignoring source layer train_transform
I0810 22:46:47.894690   463 solver.cpp:429]     Test net output #0: loss_bbox = 0.576795 (* 2 = 1.15359 loss)
I0810 22:46:47.894731   463 solver.cpp:429]     Test net output #1: loss_coverage = 5.12949 (* 1 = 5.12949 loss)
I0810 22:46:47.894739   463 solver.cpp:429]     Test net output #2: mAP = 0
I0810 22:46:47.894747   463 solver.cpp:429]     Test net output #3: precision = 0
I0810 22:46:47.894754   463 solver.cpp:429]     Test net output #4: recall = 0
I0810 22:47:00.735168   463 solver.cpp:242] Iteration 4994 (0.595286 iter/s, 36.957s/22 iter), loss = 7.431
I0810 22:47:00.735229   463 solver.cpp:261]     Train net output #0: loss_bbox = 0.626236 (* 2 = 1.25247 loss)
I0810 22:47:00.735241   463 solver.cpp:261]     Train net output #1: loss_coverage = 6.17852 (* 1 = 6.17852 loss)
I0810 22:47:00.735258   463 sgd_solver.cpp:106] Iteration 4994, lr = 1e-06
I0810 22:47:26.426231   463 solver.cpp:242] Iteration 5016 (0.856323 iter/s, 25.6912s/22 iter), loss = 5.65714
I0810 22:47:26.426561   463 solver.cpp:261]     Train net output #0: loss_bbox = 0.387194 (* 2 = 0.774388 loss)
I0810 22:47:26.426579   463 solver.cpp:261]     Train net output #1: loss_coverage = 4.88274 (* 1 = 4.88274 loss)
I0810 22:47:26.426597   463 sgd_solver.cpp:106] Iteration 5016, lr = 1e-06
I0810 22:47:52.108603   463 solver.cpp:242] Iteration 5038 (0.856622 iter/s, 25.6823s/22 iter), loss = 4.35167
I0810 22:47:52.108660   463 solver.cpp:261]     Train net output #0: loss_bbox = 0.509912 (* 2 = 1.01982 loss)
I0810 22:47:52.108674   463 solver.cpp:261]     Train net output #1: loss_coverage = 3.33184 (* 1 = 3.33184 loss)
I0810 22:47:52.108690   463 sgd_solver.cpp:106] Iteration 5038, lr = 1e-06
I0810 22:48:17.818218   463 solver.cpp:242] Iteration 5060 (0.855705 iter/s, 25.7098s/22 iter), loss = 1.84285
I0810 22:48:17.818537   463 solver.cpp:261]     Train net output #0: loss_bbox = 0.226543 (* 2 = 0.453086 loss)
I0810 22:48:17.818557   463 solver.cpp:261]     Train net output #1: loss_coverage = 1.38976 (* 1 = 1.38976 loss)
I0810 22:48:17.818578   463 sgd_solver.cpp:106] Iteration 5060, lr = 1e-06
I0810 22:48:43.522328   463 solver.cpp:242] Iteration 5082 (0.855897 iter/s, 25.704s/22 iter), loss = 6.2813
I0810 22:48:43.522385   463 solver.cpp:261]     Train net output #0: loss_bbox = 0.573384 (* 2 = 1.14677 loss)
I0810 22:48:43.522398   463 solver.cpp:261]     Train net output #1: loss_coverage = 5.13453 (* 1 = 5.13453 loss)
I0810 22:48:43.522414   463 sgd_solver.cpp:106] Iteration 5082, lr = 1e-06
I0810 22:49:09.241745   463 solver.cpp:242] Iteration 5104 (0.85538 iter/s, 25.7196s/22 iter), loss = 4.64977
I0810 22:49:09.241840   463 solver.cpp:261]     Train net output #0: loss_bbox = 0.472837 (* 2 = 0.945673 loss)
I0810 22:49:09.241854   463 solver.cpp:261]     Train net output #1: loss_coverage = 3.70408 (* 1 = 3.70408 loss)
I0810 22:49:09.241873   463 sgd_solver.cpp:106] Iteration 5104, lr = 1e-06
I0810 22:49:34.938827   463 solver.cpp:242] Iteration 5126 (0.856124 iter/s, 25.6972s/22 iter), loss = 4.28588
I0810 22:49:34.938879   463 solver.cpp:261]     Train net output #0: loss_bbox = 0.319179 (* 2 = 0.638359 loss)
I0810 22:49:34.938892   463 solver.cpp:261]     Train net output #1: loss_coverage = 3.64752 (* 1 = 3.64752 loss)
I0810 22:49:34.938908   463 sgd_solver.cpp:106] Iteration 5126, lr = 1e-06
I0810 22:50:00.609953   463 solver.cpp:242] Iteration 5148 (0.856988 iter/s, 25.6713s/22 iter), loss = 5.51516
I0810 22:50:00.610244   463 solver.cpp:261]     Train net output #0: loss_bbox = 0.410354 (* 2 = 0.820707 loss)
I0810 22:50:00.610260   463 solver.cpp:261]     Train net output #1: loss_coverage = 4.69444 (* 1 = 4.69444 loss)
I0810 22:50:00.610277   463 sgd_solver.cpp:106] Iteration 5148, lr = 1e-06
I0810 22:50:15.780490   463 solver.cpp:479] Snapshotting to binary proto file snapshot_iter_5162.caffemodel
I0810 22:50:15.880704   463 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshot_iter_5162.solverstate
I0810 22:50:15.937183   463 solver.cpp:362] Iteration 5162, Testing net (#0)
I0810 22:50:15.937214   463 net.cpp:723] Ignoring source layer train_data
I0810 22:50:15.937222   463 net.cpp:723] Ignoring source layer train_label
I0810 22:50:15.937227   463 net.cpp:723] Ignoring source layer train_transform
I0810 22:50:27.074065   463 solver.cpp:429]     Test net output #0: loss_bbox = 0.577478 (* 2 = 1.15496 loss)
I0810 22:50:27.074103   463 solver.cpp:429]     Test net output #1: loss_coverage = 5.15383 (* 1 = 5.15383 loss)
I0810 22:50:27.074112   463 solver.cpp:429]     Test net output #2: mAP = 0
I0810 22:50:27.074120   463 solver.cpp:429]     Test net output #3: precision = 0
I0810 22:50:27.074127   463 solver.cpp:429]     Test net output #4: recall = 0
I0810 22:50:37.582026   463 solver.cpp:242] Iteration 5170 (0.595043 iter/s, 36.9721s/22 iter), loss = 7.5683
I0810 22:50:37.582327   463 solver.cpp:261]     Train net output #0: loss_bbox = 0.51004 (* 2 = 1.02008 loss)
I0810 22:50:37.582345   463 solver.cpp:261]     Train net output #1: loss_coverage = 6.54821 (* 1 = 6.54821 loss)
I0810 22:50:37.582362   463 sgd_solver.cpp:106] Iteration 5170, lr = 1e-06
I0810 22:51:03.332393   463 solver.cpp:242] Iteration 5192 (0.854359 iter/s, 25.7503s/22 iter), loss = 4.65367
I0810 22:51:03.332453   463 solver.cpp:261]     Train net output #0: loss_bbox = 0.421433 (* 2 = 0.842865 loss)
I0810 22:51:03.332465   463 solver.cpp:261]     Train net output #1: loss_coverage = 3.81079 (* 1 = 3.81079 loss)
I0810 22:51:03.332482   463 sgd_solver.cpp:106] Iteration 5192, lr = 1e-06
I0810 22:51:29.015218   463 solver.cpp:242] Iteration 5214 (0.856598 iter/s, 25.683s/22 iter), loss = 6.82758
I0810 22:51:29.015589   463 solver.cpp:261]     Train net output #0: loss_bbox = 0.573055 (* 2 = 1.14611 loss)
I0810 22:51:29.015610   463 solver.cpp:261]     Train net output #1: loss_coverage = 5.68146 (* 1 = 5.68146 loss)
I0810 22:51:29.015630   463 sgd_solver.cpp:106] Iteration 5214, lr = 1e-06
I0810 22:51:54.723129   463 solver.cpp:242] Iteration 5236 (0.855773 iter/s, 25.7078s/22 iter), loss = 2.53241
I0810 22:51:54.723186   463 solver.cpp:261]     Train net output #0: loss_bbox = 0.253653 (* 2 = 0.507305 loss)
I0810 22:51:54.723199   463 solver.cpp:261]     Train net output #1: loss_coverage = 2.0251 (* 1 = 2.0251 loss)
I0810 22:51:54.723217   463 sgd_solver.cpp:106] Iteration 5236, lr = 1e-06
I0810 22:52:20.419770   463 solver.cpp:242] Iteration 5258 (0.856138 iter/s, 25.6968s/22 iter), loss = 7.14397
I0810 22:52:20.420017   463 solver.cpp:261]     Train net output #0: loss_bbox = 0.635304 (* 2 = 1.27061 loss)
I0810 22:52:20.420033   463 solver.cpp:261]     Train net output #1: loss_coverage = 5.87335 (* 1 = 5.87335 loss)
I0810 22:52:20.420050   463 sgd_solver.cpp:106] Iteration 5258, lr = 1e-06
I0810 22:52:46.129400   463 solver.cpp:242] Iteration 5280 (0.855711 iter/s, 25.7096s/22 iter), loss = 8.87322
I0810 22:52:46.129463   463 solver.cpp:261]     Train net output #0: loss_bbox = 0.448256 (* 2 = 0.896513 loss)
I0810 22:52:46.129477   463 solver.cpp:261]     Train net output #1: loss_coverage = 7.97669 (* 1 = 7.97669 loss)
I0810 22:52:46.129494   463 sgd_solver.cpp:106] Iteration 5280, lr = 1e-06
I0810 22:53:11.838418   463 solver.cpp:242] Iteration 5302 (0.855726 iter/s, 25.7092s/22 iter), loss = 5.58801
I0810 22:53:11.838722   463 solver.cpp:261]     Train net output #0: loss_bbox = 0.482147 (* 2 = 0.964295 loss)
I0810 22:53:11.838742   463 solver.cpp:261]     Train net output #1: loss_coverage = 4.62371 (* 1 = 4.62371 loss)
I0810 22:53:11.838763   463 sgd_solver.cpp:106] Iteration 5302, lr = 1e-06
I0810 22:53:37.504828   463 solver.cpp:242] Iteration 5324 (0.857154 iter/s, 25.6663s/22 iter), loss = 5.65781
I0810 22:53:37.504904   463 solver.cpp:261]     Train net output #0: loss_bbox = 0.420732 (* 2 = 0.841464 loss)
I0810 22:53:37.504918   463 solver.cpp:261]     Train net output #1: loss_coverage = 4.81633 (* 1 = 4.81633 loss)
I0810 22:53:37.504935   463 sgd_solver.cpp:106] Iteration 5324, lr = 1e-06
I0810 22:53:55.060945   463 solver.cpp:479] Snapshotting to binary proto file snapshot_iter_5340.caffemodel
I0810 22:53:55.165441   463 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshot_iter_5340.solverstate
I0810 22:53:55.220144   463 solver.cpp:362] Iteration 5340, Testing net (#0)
I0810 22:53:55.220173   463 net.cpp:723] Ignoring source layer train_data
I0810 22:53:55.220181   463 net.cpp:723] Ignoring source layer train_label
I0810 22:53:55.220186   463 net.cpp:723] Ignoring source layer train_transform
I0810 22:54:06.323776   463 solver.cpp:429]     Test net output #0: loss_bbox = 0.574562 (* 2 = 1.14912 loss)
I0810 22:54:06.323812   463 solver.cpp:429]     Test net output #1: loss_coverage = 4.92391 (* 1 = 4.92391 loss)
I0810 22:54:06.323820   463 solver.cpp:429]     Test net output #2: mAP = 0
I0810 22:54:06.323828   463 solver.cpp:429]     Test net output #3: precision = 0
I0810 22:54:06.323835   463 solver.cpp:429]     Test net output #4: recall = 0
I0810 22:54:14.498330   463 solver.cpp:242] Iteration 5346 (0.594695 iter/s, 36.9938s/22 iter), loss = 5.96055
I0810 22:54:14.498387   463 solver.cpp:261]     Train net output #0: loss_bbox = 0.502605 (* 2 = 1.00521 loss)
I0810 22:54:14.498400   463 solver.cpp:261]     Train net output #1: loss_coverage = 4.95533 (* 1 = 4.95533 loss)
I0810 22:54:14.498416   463 sgd_solver.cpp:106] Iteration 5346, lr = 1e-06
I0810 22:54:40.223960   463 solver.cpp:242] Iteration 5368 (0.855173 iter/s, 25.7258s/22 iter), loss = 2.62343
I0810 22:54:40.224380   463 solver.cpp:261]     Train net output #0: loss_bbox = 0.219145 (* 2 = 0.438291 loss)
I0810 22:54:40.224401   463 solver.cpp:261]     Train net output #1: loss_coverage = 2.18512 (* 1 = 2.18512 loss)
I0810 22:54:40.224423   463 sgd_solver.cpp:106] Iteration 5368, lr = 1e-06
I0810 22:55:05.908386   463 solver.cpp:242] Iteration 5390 (0.856556 iter/s, 25.6842s/22 iter), loss = 1.77261
I0810 22:55:05.908447   463 solver.cpp:261]     Train net output #0: loss_bbox = 0.149762 (* 2 = 0.299524 loss)
I0810 22:55:05.908460   463 solver.cpp:261]     Train net output #1: loss_coverage = 1.47307 (* 1 = 1.47307 loss)
I0810 22:55:05.908476   463 sgd_solver.cpp:106] Iteration 5390, lr = 1e-06
I0810 22:55:31.582597   463 solver.cpp:242] Iteration 5412 (0.856886 iter/s, 25.6744s/22 iter), loss = 7.79446
I0810 22:55:31.582761   463 solver.cpp:261]     Train net output #0: loss_bbox = 0.545787 (* 2 = 1.09157 loss)
I0810 22:55:31.582777   463 solver.cpp:261]     Train net output #1: loss_coverage = 6.70287 (* 1 = 6.70287 loss)
I0810 22:55:31.582793   463 sgd_solver.cpp:106] Iteration 5412, lr = 1e-06
I0810 22:55:57.307664   463 solver.cpp:242] Iteration 5434 (0.855195 iter/s, 25.7251s/22 iter), loss = 4.77672
I0810 22:55:57.307718   463 solver.cpp:261]     Train net output #0: loss_bbox = 0.591462 (* 2 = 1.18292 loss)
I0810 22:55:57.307731   463 solver.cpp:261]     Train net output #1: loss_coverage = 3.59378 (* 1 = 3.59378 loss)
I0810 22:55:57.307747   463 sgd_solver.cpp:106] Iteration 5434, lr = 1e-06
I0810 22:56:23.004822   463 solver.cpp:242] Iteration 5456 (0.85612 iter/s, 25.6973s/22 iter), loss = 6.33208
I0810 22:56:23.005028   463 solver.cpp:261]     Train net output #0: loss_bbox = 0.65552 (* 2 = 1.31104 loss)
I0810 22:56:23.005045   463 solver.cpp:261]     Train net output #1: loss_coverage = 5.02102 (* 1 = 5.02102 loss)
I0810 22:56:23.005064   463 sgd_solver.cpp:106] Iteration 5456, lr = 1e-06
I0810 22:56:48.703835   463 solver.cpp:242] Iteration 5478 (0.856063 iter/s, 25.699s/22 iter), loss = 4.55441
I0810 22:56:48.703896   463 solver.cpp:261]     Train net output #0: loss_bbox = 0.521598 (* 2 = 1.0432 loss)
I0810 22:56:48.703909   463 solver.cpp:261]     Train net output #1: loss_coverage = 3.5112 (* 1 = 3.5112 loss)
I0810 22:56:48.703927   463 sgd_solver.cpp:106] Iteration 5478, lr = 1e-06
I0810 22:57:14.362537   463 solver.cpp:242] Iteration 5500 (0.857404 iter/s, 25.6589s/22 iter), loss = 7.2306
I0810 22:57:14.362721   463 solver.cpp:261]     Train net output #0: loss_bbox = 0.505495 (* 2 = 1.01099 loss)
I0810 22:57:14.362737   463 solver.cpp:261]     Train net output #1: loss_coverage = 6.21959 (* 1 = 6.21959 loss)
I0810 22:57:14.362754   463 sgd_solver.cpp:106] Iteration 5500, lr = 1e-06
I0810 22:57:34.198596   463 solver.cpp:479] Snapshotting to binary proto file snapshot_iter_5518.caffemodel
I0810 22:57:34.296130   463 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshot_iter_5518.solverstate
I0810 22:57:34.349262   463 solver.cpp:362] Iteration 5518, Testing net (#0)
I0810 22:57:34.349292   463 net.cpp:723] Ignoring source layer train_data
I0810 22:57:34.349298   463 net.cpp:723] Ignoring source layer train_label
I0810 22:57:34.349304   463 net.cpp:723] Ignoring source layer train_transform
I0810 22:57:45.440834   463 solver.cpp:429]     Test net output #0: loss_bbox = 0.580039 (* 2 = 1.16008 loss)
I0810 22:57:45.440980   463 solver.cpp:429]     Test net output #1: loss_coverage = 5.12601 (* 1 = 5.12601 loss)
I0810 22:57:45.440992   463 solver.cpp:429]     Test net output #2: mAP = 0
I0810 22:57:45.440999   463 solver.cpp:429]     Test net output #3: precision = 0
I0810 22:57:45.441006   463 solver.cpp:429]     Test net output #4: recall = 0
I0810 22:57:51.267136   463 solver.cpp:242] Iteration 5522 (0.59613 iter/s, 36.9047s/22 iter), loss = 1.97484
I0810 22:57:51.267191   463 solver.cpp:261]     Train net output #0: loss_bbox = 0.29741 (* 2 = 0.59482 loss)
I0810 22:57:51.267204   463 solver.cpp:261]     Train net output #1: loss_coverage = 1.38001 (* 1 = 1.38001 loss)
I0810 22:57:51.267221   463 sgd_solver.cpp:106] Iteration 5522, lr = 1e-06
I0810 22:58:16.952415   463 solver.cpp:242] Iteration 5544 (0.856516 iter/s, 25.6854s/22 iter), loss = 5.25579
I0810 22:58:16.952612   463 solver.cpp:261]     Train net output #0: loss_bbox = 0.44271 (* 2 = 0.885419 loss)
I0810 22:58:16.952630   463 solver.cpp:261]     Train net output #1: loss_coverage = 4.37036 (* 1 = 4.37036 loss)
I0810 22:58:16.952647   463 sgd_solver.cpp:106] Iteration 5544, lr = 1e-06
I0810 22:58:42.644177   463 solver.cpp:242] Iteration 5566 (0.856306 iter/s, 25.6917s/22 iter), loss = 3.92409
I0810 22:58:42.644356   463 solver.cpp:261]     Train net output #0: loss_bbox = 0.296567 (* 2 = 0.593135 loss)
I0810 22:58:42.644372   463 solver.cpp:261]     Train net output #1: loss_coverage = 3.33094 (* 1 = 3.33094 loss)
I0810 22:58:42.644398   463 sgd_solver.cpp:106] Iteration 5566, lr = 1e-06
I0810 22:59:08.352686   463 solver.cpp:242] Iteration 5588 (0.855746 iter/s, 25.7086s/22 iter), loss = 5.55504
I0810 22:59:08.352923   463 solver.cpp:261]     Train net output #0: loss_bbox = 0.37221 (* 2 = 0.74442 loss)
I0810 22:59:08.352939   463 solver.cpp:261]     Train net output #1: loss_coverage = 4.81061 (* 1 = 4.81061 loss)
I0810 22:59:08.352957   463 sgd_solver.cpp:106] Iteration 5588, lr = 1e-06
I0810 22:59:34.074622   463 solver.cpp:242] Iteration 5610 (0.855301 iter/s, 25.7219s/22 iter), loss = 2.67139
I0810 22:59:34.074683   463 solver.cpp:261]     Train net output #0: loss_bbox = 0.322136 (* 2 = 0.644273 loss)
I0810 22:59:34.074697   463 solver.cpp:261]     Train net output #1: loss_coverage = 2.02711 (* 1 = 2.02711 loss)
I0810 22:59:34.074713   463 sgd_solver.cpp:106] Iteration 5610, lr = 1e-06
I0810 22:59:59.735400   463 solver.cpp:242] Iteration 5632 (0.857334 iter/s, 25.6609s/22 iter), loss = 6.89942
I0810 22:59:59.735687   463 solver.cpp:261]     Train net output #0: loss_bbox = 0.500085 (* 2 = 1.00017 loss)
I0810 22:59:59.735703   463 solver.cpp:261]     Train net output #1: loss_coverage = 5.89923 (* 1 = 5.89923 loss)
I0810 22:59:59.735721   463 sgd_solver.cpp:106] Iteration 5632, lr = 1e-06
I0810 23:00:25.492854   463 solver.cpp:242] Iteration 5654 (0.854124 iter/s, 25.7574s/22 iter), loss = 7.48368
I0810 23:00:25.492936   463 solver.cpp:261]     Train net output #0: loss_bbox = 0.587596 (* 2 = 1.17519 loss)
I0810 23:00:25.492950   463 solver.cpp:261]     Train net output #1: loss_coverage = 6.30848 (* 1 = 6.30848 loss)
I0810 23:00:25.492969   463 sgd_solver.cpp:106] Iteration 5654, lr = 1e-06
I0810 23:00:51.192996   463 solver.cpp:242] Iteration 5676 (0.856022 iter/s, 25.7003s/22 iter), loss = 5.28379
I0810 23:00:51.193320   463 solver.cpp:261]     Train net output #0: loss_bbox = 0.493398 (* 2 = 0.986796 loss)
I0810 23:00:51.193337   463 solver.cpp:261]     Train net output #1: loss_coverage = 4.29699 (* 1 = 4.29699 loss)
I0810 23:00:51.193356   463 sgd_solver.cpp:106] Iteration 5676, lr = 1e-06
I0810 23:01:13.368938   463 solver.cpp:479] Snapshotting to binary proto file snapshot_iter_5696.caffemodel
I0810 23:01:13.474449   463 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshot_iter_5696.solverstate
I0810 23:01:13.533541   463 solver.cpp:362] Iteration 5696, Testing net (#0)
I0810 23:01:13.533576   463 net.cpp:723] Ignoring source layer train_data
I0810 23:01:13.533586   463 net.cpp:723] Ignoring source layer train_label
I0810 23:01:13.533592   463 net.cpp:723] Ignoring source layer train_transform
I0810 23:01:24.648914   463 solver.cpp:429]     Test net output #0: loss_bbox = 0.569651 (* 2 = 1.1393 loss)
I0810 23:01:24.649215   463 solver.cpp:429]     Test net output #1: loss_coverage = 4.98185 (* 1 = 4.98185 loss)
I0810 23:01:24.649227   463 solver.cpp:429]     Test net output #2: mAP = 0
I0810 23:01:24.649235   463 solver.cpp:429]     Test net output #3: precision = 0
I0810 23:01:24.649243   463 solver.cpp:429]     Test net output #4: recall = 0
I0810 23:01:28.147212   463 solver.cpp:242] Iteration 5698 (0.595331 iter/s, 36.9542s/22 iter), loss = 5.3583
I0810 23:01:28.147271   463 solver.cpp:261]     Train net output #0: loss_bbox = 0.376084 (* 2 = 0.752168 loss)
I0810 23:01:28.147284   463 solver.cpp:261]     Train net output #1: loss_coverage = 4.60612 (* 1 = 4.60612 loss)
I0810 23:01:28.147300   463 sgd_solver.cpp:106] Iteration 5698, lr = 1e-06
I0810 23:01:53.819375   463 solver.cpp:242] Iteration 5720 (0.856954 iter/s, 25.6723s/22 iter), loss = 7.00391
I0810 23:01:53.819432   463 solver.cpp:261]     Train net output #0: loss_bbox = 0.655917 (* 2 = 1.31183 loss)
I0810 23:01:53.819445   463 solver.cpp:261]     Train net output #1: loss_coverage = 5.69206 (* 1 = 5.69206 loss)
I0810 23:01:53.819461   463 sgd_solver.cpp:106] Iteration 5720, lr = 1e-06
I0810 23:02:19.525027   463 solver.cpp:242] Iteration 5742 (0.855838 iter/s, 25.7058s/22 iter), loss = 5.58524
I0810 23:02:19.525279   463 solver.cpp:261]     Train net output #0: loss_bbox = 0.527289 (* 2 = 1.05458 loss)
I0810 23:02:19.525295   463 solver.cpp:261]     Train net output #1: loss_coverage = 4.53065 (* 1 = 4.53065 loss)
I0810 23:02:19.525315   463 sgd_solver.cpp:106] Iteration 5742, lr = 1e-06
I0810 23:02:45.280097   463 solver.cpp:242] Iteration 5764 (0.854202 iter/s, 25.755s/22 iter), loss = 5.19936
I0810 23:02:45.280179   463 solver.cpp:261]     Train net output #0: loss_bbox = 0.488742 (* 2 = 0.977484 loss)
I0810 23:02:45.280192   463 solver.cpp:261]     Train net output #1: loss_coverage = 4.22187 (* 1 = 4.22187 loss)
I0810 23:02:45.280210   463 sgd_solver.cpp:106] Iteration 5764, lr = 1e-06
I0810 23:03:10.983759   463 solver.cpp:242] Iteration 5786 (0.855905 iter/s, 25.7038s/22 iter), loss = 6.73147
I0810 23:03:10.984035   463 solver.cpp:261]     Train net output #0: loss_bbox = 0.53889 (* 2 = 1.07778 loss)
I0810 23:03:10.984051   463 solver.cpp:261]     Train net output #1: loss_coverage = 5.65368 (* 1 = 5.65368 loss)
I0810 23:03:10.984069   463 sgd_solver.cpp:106] Iteration 5786, lr = 1e-06
I0810 23:03:36.694034   463 solver.cpp:242] Iteration 5808 (0.855691 iter/s, 25.7102s/22 iter), loss = 6.29591
I0810 23:03:36.694095   463 solver.cpp:261]     Train net output #0: loss_bbox = 0.553079 (* 2 = 1.10616 loss)
I0810 23:03:36.694135   463 solver.cpp:261]     Train net output #1: loss_coverage = 5.18974 (* 1 = 5.18974 loss)
I0810 23:03:36.694154   463 sgd_solver.cpp:106] Iteration 5808, lr = 1e-06
I0810 23:04:02.339577   463 solver.cpp:242] Iteration 5830 (0.857843 iter/s, 25.6457s/22 iter), loss = 2.34818
I0810 23:04:02.339749   463 solver.cpp:261]     Train net output #0: loss_bbox = 0.176891 (* 2 = 0.353781 loss)
I0810 23:04:02.339764   463 solver.cpp:261]     Train net output #1: loss_coverage = 1.99439 (* 1 = 1.99439 loss)
I0810 23:04:02.339783   463 sgd_solver.cpp:106] Iteration 5830, lr = 1e-06
I0810 23:04:28.061182   463 solver.cpp:242] Iteration 5852 (0.85531 iter/s, 25.7217s/22 iter), loss = 8.16412
I0810 23:04:28.061242   463 solver.cpp:261]     Train net output #0: loss_bbox = 0.59465 (* 2 = 1.1893 loss)
I0810 23:04:28.061255   463 solver.cpp:261]     Train net output #1: loss_coverage = 6.9748 (* 1 = 6.9748 loss)
I0810 23:04:28.061273   463 sgd_solver.cpp:106] Iteration 5852, lr = 1e-06
I0810 23:04:52.653841   463 solver.cpp:479] Snapshotting to binary proto file snapshot_iter_5874.caffemodel
I0810 23:04:52.754787   463 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshot_iter_5874.solverstate
I0810 23:04:52.808933   463 solver.cpp:362] Iteration 5874, Testing net (#0)
I0810 23:04:52.808970   463 net.cpp:723] Ignoring source layer train_data
I0810 23:04:52.808979   463 net.cpp:723] Ignoring source layer train_label
I0810 23:04:52.808984   463 net.cpp:723] Ignoring source layer train_transform
I0810 23:05:03.922253   463 solver.cpp:429]     Test net output #0: loss_bbox = 0.579443 (* 2 = 1.15889 loss)
I0810 23:05:03.922287   463 solver.cpp:429]     Test net output #1: loss_coverage = 5.10569 (* 1 = 5.10569 loss)
I0810 23:05:03.922297   463 solver.cpp:429]     Test net output #2: mAP = 0
I0810 23:05:03.922303   463 solver.cpp:429]     Test net output #3: precision = 0
I0810 23:05:03.922312   463 solver.cpp:429]     Test net output #4: recall = 0
I0810 23:05:05.083969   463 solver.cpp:242] Iteration 5874 (0.594224 iter/s, 37.0231s/22 iter), loss = 8.02946
I0810 23:05:05.084029   463 solver.cpp:261]     Train net output #0: loss_bbox = 0.588868 (* 2 = 1.17774 loss)
I0810 23:05:05.084051   463 solver.cpp:261]     Train net output #1: loss_coverage = 6.85171 (* 1 = 6.85171 loss)
I0810 23:05:05.084071   463 sgd_solver.cpp:106] Iteration 5874, lr = 1e-06
I0810 23:05:30.751996   463 solver.cpp:242] Iteration 5896 (0.857092 iter/s, 25.6682s/22 iter), loss = 4.68142
I0810 23:05:30.752290   463 solver.cpp:261]     Train net output #0: loss_bbox = 0.454956 (* 2 = 0.909912 loss)
I0810 23:05:30.752307   463 solver.cpp:261]     Train net output #1: loss_coverage = 3.7715 (* 1 = 3.7715 loss)
I0810 23:05:30.752326   463 sgd_solver.cpp:106] Iteration 5896, lr = 1e-06
I0810 23:05:56.428547   463 solver.cpp:242] Iteration 5918 (0.856815 iter/s, 25.6765s/22 iter), loss = 4.73381
I0810 23:05:56.428637   463 solver.cpp:261]     Train net output #0: loss_bbox = 0.525732 (* 2 = 1.05146 loss)
I0810 23:05:56.428653   463 solver.cpp:261]     Train net output #1: loss_coverage = 3.68234 (* 1 = 3.68234 loss)
I0810 23:05:56.428671   463 sgd_solver.cpp:106] Iteration 5918, lr = 1e-06
I0810 23:06:22.166132   463 solver.cpp:242] Iteration 5940 (0.854777 iter/s, 25.7377s/22 iter), loss = 1.38128
I0810 23:06:22.166384   463 solver.cpp:261]     Train net output #0: loss_bbox = 0.165194 (* 2 = 0.330388 loss)
I0810 23:06:22.166400   463 solver.cpp:261]     Train net output #1: loss_coverage = 1.05087 (* 1 = 1.05087 loss)
I0810 23:06:22.166419   463 sgd_solver.cpp:106] Iteration 5940, lr = 1e-06
I0810 23:06:47.867707   463 solver.cpp:242] Iteration 5962 (0.85598 iter/s, 25.7015s/22 iter), loss = 1.95714
I0810 23:06:47.867763   463 solver.cpp:261]     Train net output #0: loss_bbox = 0.168097 (* 2 = 0.336195 loss)
I0810 23:06:47.867776   463 solver.cpp:261]     Train net output #1: loss_coverage = 1.62093 (* 1 = 1.62093 loss)
I0810 23:06:47.867794   463 sgd_solver.cpp:106] Iteration 5962, lr = 1e-06
I0810 23:07:13.593574   463 solver.cpp:242] Iteration 5984 (0.855165 iter/s, 25.726s/22 iter), loss = 3.14191
I0810 23:07:13.593794   463 solver.cpp:261]     Train net output #0: loss_bbox = 0.397368 (* 2 = 0.794735 loss)
I0810 23:07:13.593811   463 solver.cpp:261]     Train net output #1: loss_coverage = 2.34716 (* 1 = 2.34716 loss)
I0810 23:07:13.593828   463 sgd_solver.cpp:106] Iteration 5984, lr = 1e-06
I0810 23:07:39.284790   463 solver.cpp:242] Iteration 6006 (0.856324 iter/s, 25.6912s/22 iter), loss = 9.11416
I0810 23:07:39.284844   463 solver.cpp:261]     Train net output #0: loss_bbox = 0.680473 (* 2 = 1.36095 loss)
I0810 23:07:39.284857   463 solver.cpp:261]     Train net output #1: loss_coverage = 7.7532 (* 1 = 7.7532 loss)
I0810 23:07:39.284873   463 sgd_solver.cpp:106] Iteration 6006, lr = 1e-06
I0810 23:08:04.955397   463 solver.cpp:242] Iteration 6028 (0.857006 iter/s, 25.6708s/22 iter), loss = 7.35431
I0810 23:08:04.955690   463 solver.cpp:261]     Train net output #0: loss_bbox = 0.518122 (* 2 = 1.03624 loss)
I0810 23:08:04.955709   463 solver.cpp:261]     Train net output #1: loss_coverage = 6.31805 (* 1 = 6.31805 loss)
I0810 23:08:04.955729   463 sgd_solver.cpp:106] Iteration 6028, lr = 1e-06
I0810 23:08:30.626956   463 solver.cpp:242] Iteration 6050 (0.856982 iter/s, 25.6715s/22 iter), loss = 4.4308
I0810 23:08:30.627020   463 solver.cpp:261]     Train net output #0: loss_bbox = 0.468887 (* 2 = 0.937775 loss)
I0810 23:08:30.627035   463 solver.cpp:261]     Train net output #1: loss_coverage = 3.49301 (* 1 = 3.49301 loss)
I0810 23:08:30.627056   463 sgd_solver.cpp:106] Iteration 6050, lr = 1e-06
I0810 23:08:31.798914   463 solver.cpp:479] Snapshotting to binary proto file snapshot_iter_6052.caffemodel
I0810 23:08:31.897652   463 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshot_iter_6052.solverstate
I0810 23:08:31.951014   463 solver.cpp:362] Iteration 6052, Testing net (#0)
I0810 23:08:31.951042   463 net.cpp:723] Ignoring source layer train_data
I0810 23:08:31.951050   463 net.cpp:723] Ignoring source layer train_label
I0810 23:08:31.951056   463 net.cpp:723] Ignoring source layer train_transform
I0810 23:08:43.047765   463 solver.cpp:429]     Test net output #0: loss_bbox = 0.574752 (* 2 = 1.1495 loss)
I0810 23:08:43.047960   463 solver.cpp:429]     Test net output #1: loss_coverage = 5.1706 (* 1 = 5.1706 loss)
I0810 23:08:43.047973   463 solver.cpp:429]     Test net output #2: mAP = 0
I0810 23:08:43.047981   463 solver.cpp:429]     Test net output #3: precision = 0
I0810 23:08:43.047988   463 solver.cpp:429]     Test net output #4: recall = 0
I0810 23:09:07.597203   463 solver.cpp:242] Iteration 6072 (0.595069 iter/s, 36.9705s/22 iter), loss = 4.67638
I0810 23:09:07.597268   463 solver.cpp:261]     Train net output #0: loss_bbox = 0.462359 (* 2 = 0.924718 loss)
I0810 23:09:07.597282   463 solver.cpp:261]     Train net output #1: loss_coverage = 3.75165 (* 1 = 3.75165 loss)
I0810 23:09:07.597298   463 sgd_solver.cpp:106] Iteration 6072, lr = 1e-06
I0810 23:09:33.272972   463 solver.cpp:242] Iteration 6094 (0.856834 iter/s, 25.6759s/22 iter), loss = 3.38457
I0810 23:09:33.273337   463 solver.cpp:261]     Train net output #0: loss_bbox = 0.358683 (* 2 = 0.717366 loss)
I0810 23:09:33.273358   463 solver.cpp:261]     Train net output #1: loss_coverage = 2.66719 (* 1 = 2.66719 loss)
I0810 23:09:33.273381   463 sgd_solver.cpp:106] Iteration 6094, lr = 1e-06
I0810 23:09:58.980865   463 solver.cpp:242] Iteration 6116 (0.855773 iter/s, 25.7078s/22 iter), loss = 3.44906
I0810 23:09:58.980937   463 solver.cpp:261]     Train net output #0: loss_bbox = 0.240677 (* 2 = 0.481355 loss)
I0810 23:09:58.980952   463 solver.cpp:261]     Train net output #1: loss_coverage = 2.96769 (* 1 = 2.96769 loss)
I0810 23:09:58.980968   463 sgd_solver.cpp:106] Iteration 6116, lr = 1e-06
I0810 23:10:24.681056   463 solver.cpp:242] Iteration 6138 (0.85602 iter/s, 25.7003s/22 iter), loss = 7.20295
I0810 23:10:24.681347   463 solver.cpp:261]     Train net output #0: loss_bbox = 0.493028 (* 2 = 0.986057 loss)
I0810 23:10:24.681363   463 solver.cpp:261]     Train net output #1: loss_coverage = 6.21688 (* 1 = 6.21688 loss)
I0810 23:10:24.681381   463 sgd_solver.cpp:106] Iteration 6138, lr = 1e-06
I0810 23:10:50.314831   463 solver.cpp:242] Iteration 6160 (0.858245 iter/s, 25.6337s/22 iter), loss = 3.70666
I0810 23:10:50.314890   463 solver.cpp:261]     Train net output #0: loss_bbox = 0.333826 (* 2 = 0.667652 loss)
I0810 23:10:50.314903   463 solver.cpp:261]     Train net output #1: loss_coverage = 3.03899 (* 1 = 3.03899 loss)
I0810 23:10:50.314919   463 sgd_solver.cpp:106] Iteration 6160, lr = 1e-06
I0810 23:11:16.038234   463 solver.cpp:242] Iteration 6182 (0.855247 iter/s, 25.7236s/22 iter), loss = 4.83407
I0810 23:11:16.038535   463 solver.cpp:261]     Train net output #0: loss_bbox = 0.353128 (* 2 = 0.706255 loss)
I0810 23:11:16.038564   463 solver.cpp:261]     Train net output #1: loss_coverage = 4.1278 (* 1 = 4.1278 loss)
I0810 23:11:16.038585   463 sgd_solver.cpp:106] Iteration 6182, lr = 1e-06
I0810 23:11:41.749691   463 solver.cpp:242] Iteration 6204 (0.855652 iter/s, 25.7114s/22 iter), loss = 5.89132
I0810 23:11:41.749749   463 solver.cpp:261]     Train net output #0: loss_bbox = 0.533865 (* 2 = 1.06773 loss)
I0810 23:11:41.749763   463 solver.cpp:261]     Train net output #1: loss_coverage = 4.82357 (* 1 = 4.82357 loss)
I0810 23:11:41.749779   463 sgd_solver.cpp:106] Iteration 6204, lr = 1e-06
I0810 23:12:07.422391   463 solver.cpp:242] Iteration 6226 (0.856936 iter/s, 25.6729s/22 iter), loss = 2.23875
I0810 23:12:07.422719   463 solver.cpp:261]     Train net output #0: loss_bbox = 0.17247 (* 2 = 0.34494 loss)
I0810 23:12:07.422739   463 solver.cpp:261]     Train net output #1: loss_coverage = 1.8938 (* 1 = 1.8938 loss)
I0810 23:12:07.422760   463 sgd_solver.cpp:106] Iteration 6226, lr = 1e-06
I0810 23:12:10.936714   463 solver.cpp:479] Snapshotting to binary proto file snapshot_iter_6230.caffemodel
I0810 23:12:11.038615   463 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshot_iter_6230.solverstate
I0810 23:12:11.094054   463 solver.cpp:362] Iteration 6230, Testing net (#0)
I0810 23:12:11.094091   463 net.cpp:723] Ignoring source layer train_data
I0810 23:12:11.094099   463 net.cpp:723] Ignoring source layer train_label
I0810 23:12:11.094105   463 net.cpp:723] Ignoring source layer train_transform
I0810 23:12:22.239723   463 solver.cpp:429]     Test net output #0: loss_bbox = 0.574482 (* 2 = 1.14896 loss)
I0810 23:12:22.239761   463 solver.cpp:429]     Test net output #1: loss_coverage = 5.26129 (* 1 = 5.26129 loss)
I0810 23:12:22.239770   463 solver.cpp:429]     Test net output #2: mAP = 0
I0810 23:12:22.239778   463 solver.cpp:429]     Test net output #3: precision = 0
I0810 23:12:22.239785   463 solver.cpp:429]     Test net output #4: recall = 0
I0810 23:12:44.472147   463 solver.cpp:242] Iteration 6248 (0.593796 iter/s, 37.0498s/22 iter), loss = 6.79056
I0810 23:12:44.472321   463 solver.cpp:261]     Train net output #0: loss_bbox = 0.519863 (* 2 = 1.03973 loss)
I0810 23:12:44.472337   463 solver.cpp:261]     Train net output #1: loss_coverage = 5.75082 (* 1 = 5.75082 loss)
I0810 23:12:44.472354   463 sgd_solver.cpp:106] Iteration 6248, lr = 1e-06
I0810 23:13:10.135069   463 solver.cpp:242] Iteration 6270 (0.857266 iter/s, 25.663s/22 iter), loss = 6.46137
I0810 23:13:10.135164   463 solver.cpp:261]     Train net output #0: loss_bbox = 0.392915 (* 2 = 0.78583 loss)
I0810 23:13:10.135177   463 solver.cpp:261]     Train net output #1: loss_coverage = 5.67553 (* 1 = 5.67553 loss)
I0810 23:13:10.135195   463 sgd_solver.cpp:106] Iteration 6270, lr = 1e-06
I0810 23:13:35.831276   463 solver.cpp:242] Iteration 6292 (0.856153 iter/s, 25.6963s/22 iter), loss = 5.08451
I0810 23:13:35.831526   463 solver.cpp:261]     Train net output #0: loss_bbox = 0.421068 (* 2 = 0.842137 loss)
I0810 23:13:35.831542   463 solver.cpp:261]     Train net output #1: loss_coverage = 4.24236 (* 1 = 4.24236 loss)
I0810 23:13:35.831560   463 sgd_solver.cpp:106] Iteration 6292, lr = 1e-06
I0810 23:14:01.544473   463 solver.cpp:242] Iteration 6314 (0.855593 iter/s, 25.7132s/22 iter), loss = 7.17489
I0810 23:14:01.544533   463 solver.cpp:261]     Train net output #0: loss_bbox = 0.514619 (* 2 = 1.02924 loss)
I0810 23:14:01.544545   463 solver.cpp:261]     Train net output #1: loss_coverage = 6.14564 (* 1 = 6.14564 loss)
I0810 23:14:01.544562   463 sgd_solver.cpp:106] Iteration 6314, lr = 1e-06
I0810 23:14:27.261992   463 solver.cpp:242] Iteration 6336 (0.855443 iter/s, 25.7177s/22 iter), loss = 9.45331
I0810 23:14:27.262269   463 solver.cpp:261]     Train net output #0: loss_bbox = 0.561367 (* 2 = 1.12273 loss)
I0810 23:14:27.262286   463 solver.cpp:261]     Train net output #1: loss_coverage = 8.33056 (* 1 = 8.33056 loss)
I0810 23:14:27.262305   463 sgd_solver.cpp:106] Iteration 6336, lr = 1e-06
I0810 23:14:52.942916   463 solver.cpp:242] Iteration 6358 (0.856669 iter/s, 25.6809s/22 iter), loss = 2.08989
I0810 23:14:52.942976   463 solver.cpp:261]     Train net output #0: loss_bbox = 0.200928 (* 2 = 0.401856 loss)
I0810 23:14:52.942989   463 solver.cpp:261]     Train net output #1: loss_coverage = 1.68802 (* 1 = 1.68802 loss)
I0810 23:14:52.943006   463 sgd_solver.cpp:106] Iteration 6358, lr = 1e-06
I0810 23:15:18.646731   463 solver.cpp:242] Iteration 6380 (0.855899 iter/s, 25.704s/22 iter), loss = 3.57725
I0810 23:15:18.647068   463 solver.cpp:261]     Train net output #0: loss_bbox = 0.30139 (* 2 = 0.602779 loss)
I0810 23:15:18.647089   463 solver.cpp:261]     Train net output #1: loss_coverage = 2.97446 (* 1 = 2.97446 loss)
I0810 23:15:18.647136   463 sgd_solver.cpp:106] Iteration 6380, lr = 1e-06
I0810 23:15:44.352020   463 solver.cpp:242] Iteration 6402 (0.855859 iter/s, 25.7052s/22 iter), loss = 4.65283
I0810 23:15:44.352087   463 solver.cpp:261]     Train net output #0: loss_bbox = 0.545329 (* 2 = 1.09066 loss)
I0810 23:15:44.352123   463 solver.cpp:261]     Train net output #1: loss_coverage = 3.56216 (* 1 = 3.56216 loss)
I0810 23:15:44.352144   463 sgd_solver.cpp:106] Iteration 6402, lr = 1e-06
I0810 23:15:50.192631   463 solver.cpp:479] Snapshotting to binary proto file snapshot_iter_6408.caffemodel
I0810 23:15:50.293061   463 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshot_iter_6408.solverstate
I0810 23:15:50.348980   463 solver.cpp:362] Iteration 6408, Testing net (#0)
I0810 23:15:50.349011   463 net.cpp:723] Ignoring source layer train_data
I0810 23:15:50.349018   463 net.cpp:723] Ignoring source layer train_label
I0810 23:15:50.349025   463 net.cpp:723] Ignoring source layer train_transform
I0810 23:16:01.461495   463 solver.cpp:429]     Test net output #0: loss_bbox = 0.571294 (* 2 = 1.14259 loss)
I0810 23:16:01.461530   463 solver.cpp:429]     Test net output #1: loss_coverage = 5.08468 (* 1 = 5.08468 loss)
I0810 23:16:01.461539   463 solver.cpp:429]     Test net output #2: mAP = 0
I0810 23:16:01.461546   463 solver.cpp:429]     Test net output #3: precision = 0
I0810 23:16:01.461553   463 solver.cpp:429]     Test net output #4: recall = 0
I0810 23:16:21.335036   463 solver.cpp:242] Iteration 6424 (0.594863 iter/s, 36.9833s/22 iter), loss = 3.23497
I0810 23:16:21.335155   463 solver.cpp:261]     Train net output #0: loss_bbox = 0.312509 (* 2 = 0.625019 loss)
I0810 23:16:21.335170   463 solver.cpp:261]     Train net output #1: loss_coverage = 2.60994 (* 1 = 2.60994 loss)
I0810 23:16:21.335186   463 sgd_solver.cpp:106] Iteration 6424, lr = 1e-06
I0810 23:16:47.031342   463 solver.cpp:242] Iteration 6446 (0.856151 iter/s, 25.6964s/22 iter), loss = 0.982122
I0810 23:16:47.031401   463 solver.cpp:261]     Train net output #0: loss_bbox = 0.0839031 (* 2 = 0.167806 loss)
I0810 23:16:47.031414   463 solver.cpp:261]     Train net output #1: loss_coverage = 0.814303 (* 1 = 0.814303 loss)
I0810 23:16:47.031431   463 sgd_solver.cpp:106] Iteration 6446, lr = 1e-06
I0810 23:17:12.736289   463 solver.cpp:242] Iteration 6468 (0.855861 iter/s, 25.7051s/22 iter), loss = 2.09763
I0810 23:17:12.736544   463 solver.cpp:261]     Train net output #0: loss_bbox = 0.24654 (* 2 = 0.493079 loss)
I0810 23:17:12.736575   463 solver.cpp:261]     Train net output #1: loss_coverage = 1.60454 (* 1 = 1.60454 loss)
I0810 23:17:12.736594   463 sgd_solver.cpp:106] Iteration 6468, lr = 1e-06
I0810 23:17:38.433845   463 solver.cpp:242] Iteration 6490 (0.856114 iter/s, 25.6975s/22 iter), loss = 3.43986
I0810 23:17:38.433902   463 solver.cpp:261]     Train net output #0: loss_bbox = 0.323026 (* 2 = 0.646052 loss)
I0810 23:17:38.433917   463 solver.cpp:261]     Train net output #1: loss_coverage = 2.7938 (* 1 = 2.7938 loss)
I0810 23:17:38.433933   463 sgd_solver.cpp:106] Iteration 6490, lr = 1e-06
I0810 23:18:04.111289   463 solver.cpp:242] Iteration 6512 (0.856778 iter/s, 25.6776s/22 iter), loss = 6.54659
I0810 23:18:04.111690   463 solver.cpp:261]     Train net output #0: loss_bbox = 0.543859 (* 2 = 1.08772 loss)
I0810 23:18:04.111711   463 solver.cpp:261]     Train net output #1: loss_coverage = 5.45886 (* 1 = 5.45886 loss)
I0810 23:18:04.111732   463 sgd_solver.cpp:106] Iteration 6512, lr = 1e-06
I0810 23:18:29.808315   463 solver.cpp:242] Iteration 6534 (0.856136 iter/s, 25.6969s/22 iter), loss = 2.49616
I0810 23:18:29.808369   463 solver.cpp:261]     Train net output #0: loss_bbox = 0.293655 (* 2 = 0.58731 loss)
I0810 23:18:29.808382   463 solver.cpp:261]     Train net output #1: loss_coverage = 1.90884 (* 1 = 1.90884 loss)
I0810 23:18:29.808399   463 sgd_solver.cpp:106] Iteration 6534, lr = 1e-06
I0810 23:18:55.515476   463 solver.cpp:242] Iteration 6556 (0.855787 iter/s, 25.7073s/22 iter), loss = 5.99805
I0810 23:18:55.515738   463 solver.cpp:261]     Train net output #0: loss_bbox = 0.474933 (* 2 = 0.949867 loss)
I0810 23:18:55.515753   463 solver.cpp:261]     Train net output #1: loss_coverage = 5.04817 (* 1 = 5.04817 loss)
I0810 23:18:55.515771   463 sgd_solver.cpp:106] Iteration 6556, lr = 1e-06
I0810 23:19:21.220027   463 solver.cpp:242] Iteration 6578 (0.855881 iter/s, 25.7045s/22 iter), loss = 3.44399
I0810 23:19:21.220094   463 solver.cpp:261]     Train net output #0: loss_bbox = 0.228538 (* 2 = 0.457075 loss)
I0810 23:19:21.220108   463 solver.cpp:261]     Train net output #1: loss_coverage = 2.9869 (* 1 = 2.9869 loss)
I0810 23:19:21.220124   463 sgd_solver.cpp:106] Iteration 6578, lr = 1e-06
I0810 23:19:29.401684   463 solver.cpp:479] Snapshotting to binary proto file snapshot_iter_6586.caffemodel
I0810 23:19:29.503918   463 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshot_iter_6586.solverstate
I0810 23:19:29.560793   463 solver.cpp:362] Iteration 6586, Testing net (#0)
I0810 23:19:29.560824   463 net.cpp:723] Ignoring source layer train_data
I0810 23:19:29.560832   463 net.cpp:723] Ignoring source layer train_label
I0810 23:19:29.560837   463 net.cpp:723] Ignoring source layer train_transform
I0810 23:19:40.691177   463 solver.cpp:429]     Test net output #0: loss_bbox = 0.583066 (* 2 = 1.16613 loss)
I0810 23:19:40.691211   463 solver.cpp:429]     Test net output #1: loss_coverage = 5.0349 (* 1 = 5.0349 loss)
I0810 23:19:40.691220   463 solver.cpp:429]     Test net output #2: mAP = 0
I0810 23:19:40.691228   463 solver.cpp:429]     Test net output #3: precision = 0
I0810 23:19:40.691236   463 solver.cpp:429]     Test net output #4: recall = 0
I0810 23:19:58.243438   463 solver.cpp:242] Iteration 6600 (0.594214 iter/s, 37.0237s/22 iter), loss = 4.63034
I0810 23:19:58.243495   463 solver.cpp:261]     Train net output #0: loss_bbox = 0.312171 (* 2 = 0.624342 loss)
I0810 23:19:58.243508   463 solver.cpp:261]     Train net output #1: loss_coverage = 4.00598 (* 1 = 4.00598 loss)
I0810 23:19:58.243525   463 sgd_solver.cpp:106] Iteration 6600, lr = 1e-06
I0810 23:20:23.984184   463 solver.cpp:242] Iteration 6622 (0.854671 iter/s, 25.7409s/22 iter), loss = 4.95076
I0810 23:20:23.984477   463 solver.cpp:261]     Train net output #0: loss_bbox = 0.416128 (* 2 = 0.832256 loss)
I0810 23:20:23.984494   463 solver.cpp:261]     Train net output #1: loss_coverage = 4.11849 (* 1 = 4.11849 loss)
I0810 23:20:23.984513   463 sgd_solver.cpp:106] Iteration 6622, lr = 1e-06
I0810 23:20:49.693424   463 solver.cpp:242] Iteration 6644 (0.855726 iter/s, 25.7092s/22 iter), loss = 5.82924
I0810 23:20:49.693491   463 solver.cpp:261]     Train net output #0: loss_bbox = 0.497345 (* 2 = 0.99469 loss)
I0810 23:20:49.693506   463 solver.cpp:261]     Train net output #1: loss_coverage = 4.83453 (* 1 = 4.83453 loss)
I0810 23:20:49.693523   463 sgd_solver.cpp:106] Iteration 6644, lr = 1e-06
I0810 23:21:15.450990   463 solver.cpp:242] Iteration 6666 (0.854113 iter/s, 25.7577s/22 iter), loss = 3.84126
I0810 23:21:15.451305   463 solver.cpp:261]     Train net output #0: loss_bbox = 0.328873 (* 2 = 0.657746 loss)
I0810 23:21:15.451325   463 solver.cpp:261]     Train net output #1: loss_coverage = 3.1835 (* 1 = 3.1835 loss)
I0810 23:21:15.451346   463 sgd_solver.cpp:106] Iteration 6666, lr = 1e-06
I0810 23:21:41.180821   463 solver.cpp:242] Iteration 6688 (0.855041 iter/s, 25.7297s/22 iter), loss = 3.34524
I0810 23:21:41.180892   463 solver.cpp:261]     Train net output #0: loss_bbox = 0.281136 (* 2 = 0.562272 loss)
I0810 23:21:41.180908   463 solver.cpp:261]     Train net output #1: loss_coverage = 2.78295 (* 1 = 2.78295 loss)
I0810 23:21:41.180936   463 sgd_solver.cpp:106] Iteration 6688, lr = 1e-06
I0810 23:22:06.877507   463 solver.cpp:242] Iteration 6710 (0.856137 iter/s, 25.6968s/22 iter), loss = 8.85783
I0810 23:22:06.878118   463 solver.cpp:261]     Train net output #0: loss_bbox = 0.69613 (* 2 = 1.39226 loss)
I0810 23:22:06.878141   463 solver.cpp:261]     Train net output #1: loss_coverage = 7.46556 (* 1 = 7.46556 loss)
I0810 23:22:06.878172   463 sgd_solver.cpp:106] Iteration 6710, lr = 1e-06
I0810 23:22:32.614572   463 solver.cpp:242] Iteration 6732 (0.854809 iter/s, 25.7367s/22 iter), loss = 6.87539
I0810 23:22:32.614631   463 solver.cpp:261]     Train net output #0: loss_bbox = 0.536941 (* 2 = 1.07388 loss)
I0810 23:22:32.614645   463 solver.cpp:261]     Train net output #1: loss_coverage = 5.8015 (* 1 = 5.8015 loss)
I0810 23:22:32.614661   463 sgd_solver.cpp:106] Iteration 6732, lr = 1e-06
I0810 23:22:58.322916   463 solver.cpp:242] Iteration 6754 (0.855748 iter/s, 25.7085s/22 iter), loss = 3.29094
I0810 23:22:58.323242   463 solver.cpp:261]     Train net output #0: loss_bbox = 0.317681 (* 2 = 0.635362 loss)
I0810 23:22:58.323261   463 solver.cpp:261]     Train net output #1: loss_coverage = 2.65557 (* 1 = 2.65557 loss)
I0810 23:22:58.323282   463 sgd_solver.cpp:106] Iteration 6754, lr = 1e-06
I0810 23:23:08.831281   463 solver.cpp:479] Snapshotting to binary proto file snapshot_iter_6764.caffemodel
I0810 23:23:08.933136   463 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshot_iter_6764.solverstate
I0810 23:23:08.988245   463 solver.cpp:362] Iteration 6764, Testing net (#0)
I0810 23:23:08.988277   463 net.cpp:723] Ignoring source layer train_data
I0810 23:23:08.988284   463 net.cpp:723] Ignoring source layer train_label
I0810 23:23:08.988291   463 net.cpp:723] Ignoring source layer train_transform
I0810 23:23:20.107975   463 solver.cpp:429]     Test net output #0: loss_bbox = 0.585124 (* 2 = 1.17025 loss)
I0810 23:23:20.108011   463 solver.cpp:429]     Test net output #1: loss_coverage = 5.25785 (* 1 = 5.25785 loss)
I0810 23:23:20.108019   463 solver.cpp:429]     Test net output #2: mAP = 0
I0810 23:23:20.108037   463 solver.cpp:429]     Test net output #3: precision = 0
I0810 23:23:20.108045   463 solver.cpp:429]     Test net output #4: recall = 0
I0810 23:23:35.314152   463 solver.cpp:242] Iteration 6776 (0.594735 iter/s, 36.9912s/22 iter), loss = 5.75582
I0810 23:23:35.314415   463 solver.cpp:261]     Train net output #0: loss_bbox = 0.513357 (* 2 = 1.02671 loss)
I0810 23:23:35.314431   463 solver.cpp:261]     Train net output #1: loss_coverage = 4.72909 (* 1 = 4.72909 loss)
I0810 23:23:35.314450   463 sgd_solver.cpp:106] Iteration 6776, lr = 1e-06
I0810 23:24:01.025629   463 solver.cpp:242] Iteration 6798 (0.85565 iter/s, 25.7114s/22 iter), loss = 4.17744
I0810 23:24:01.025689   463 solver.cpp:261]     Train net output #0: loss_bbox = 0.366217 (* 2 = 0.732434 loss)
I0810 23:24:01.025702   463 solver.cpp:261]     Train net output #1: loss_coverage = 3.44499 (* 1 = 3.44499 loss)
I0810 23:24:01.025719   463 sgd_solver.cpp:106] Iteration 6798, lr = 1e-06
I0810 23:24:26.758594   463 solver.cpp:242] Iteration 6820 (0.854929 iter/s, 25.7331s/22 iter), loss = 3.62431
I0810 23:24:26.758817   463 solver.cpp:261]     Train net output #0: loss_bbox = 0.351853 (* 2 = 0.703705 loss)
I0810 23:24:26.758834   463 solver.cpp:261]     Train net output #1: loss_coverage = 2.9206 (* 1 = 2.9206 loss)
I0810 23:24:26.758852   463 sgd_solver.cpp:106] Iteration 6820, lr = 1e-06
I0810 23:24:52.457363   463 solver.cpp:242] Iteration 6842 (0.856072 iter/s, 25.6988s/22 iter), loss = 7.49863
I0810 23:24:52.457422   463 solver.cpp:261]     Train net output #0: loss_bbox = 0.610687 (* 2 = 1.22137 loss)
I0810 23:24:52.457434   463 solver.cpp:261]     Train net output #1: loss_coverage = 6.27725 (* 1 = 6.27725 loss)
I0810 23:24:52.457458   463 sgd_solver.cpp:106] Iteration 6842, lr = 1e-06
I0810 23:25:18.162261   463 solver.cpp:242] Iteration 6864 (0.855862 iter/s, 25.7051s/22 iter), loss = 5.40656
I0810 23:25:18.162575   463 solver.cpp:261]     Train net output #0: loss_bbox = 0.382287 (* 2 = 0.764574 loss)
I0810 23:25:18.162591   463 solver.cpp:261]     Train net output #1: loss_coverage = 4.64197 (* 1 = 4.64197 loss)
I0810 23:25:18.162611   463 sgd_solver.cpp:106] Iteration 6864, lr = 1e-06
I0810 23:25:43.860853   463 solver.cpp:242] Iteration 6886 (0.856081 iter/s, 25.6985s/22 iter), loss = 9.23806
I0810 23:25:43.860925   463 solver.cpp:261]     Train net output #0: loss_bbox = 0.653213 (* 2 = 1.30643 loss)
I0810 23:25:43.860939   463 solver.cpp:261]     Train net output #1: loss_coverage = 7.93162 (* 1 = 7.93162 loss)
I0810 23:25:43.860955   463 sgd_solver.cpp:106] Iteration 6886, lr = 1e-06
I0810 23:26:09.564327   463 solver.cpp:242] Iteration 6908 (0.85591 iter/s, 25.7036s/22 iter), loss = 5.41927
I0810 23:26:09.564610   463 solver.cpp:261]     Train net output #0: loss_bbox = 0.316272 (* 2 = 0.632544 loss)
I0810 23:26:09.564630   463 solver.cpp:261]     Train net output #1: loss_coverage = 4.78672 (* 1 = 4.78672 loss)
I0810 23:26:09.564649   463 sgd_solver.cpp:106] Iteration 6908, lr = 1e-06
I0810 23:26:35.270757   463 solver.cpp:242] Iteration 6930 (0.855819 iter/s, 25.7064s/22 iter), loss = 3.91249
I0810 23:26:35.270823   463 solver.cpp:261]     Train net output #0: loss_bbox = 0.494472 (* 2 = 0.988944 loss)
I0810 23:26:35.270838   463 solver.cpp:261]     Train net output #1: loss_coverage = 2.92353 (* 1 = 2.92353 loss)
I0810 23:26:35.270856   463 sgd_solver.cpp:106] Iteration 6930, lr = 1e-06
I0810 23:26:48.133028   463 solver.cpp:479] Snapshotting to binary proto file snapshot_iter_6942.caffemodel
I0810 23:26:48.235846   463 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshot_iter_6942.solverstate
I0810 23:26:48.290334   463 solver.cpp:362] Iteration 6942, Testing net (#0)
I0810 23:26:48.290366   463 net.cpp:723] Ignoring source layer train_data
I0810 23:26:48.290374   463 net.cpp:723] Ignoring source layer train_label
I0810 23:26:48.290380   463 net.cpp:723] Ignoring source layer train_transform
I0810 23:26:59.383697   463 solver.cpp:429]     Test net output #0: loss_bbox = 0.577483 (* 2 = 1.15497 loss)
I0810 23:26:59.383729   463 solver.cpp:429]     Test net output #1: loss_coverage = 5.30358 (* 1 = 5.30358 loss)
I0810 23:26:59.383738   463 solver.cpp:429]     Test net output #2: mAP = 0
I0810 23:26:59.383746   463 solver.cpp:429]     Test net output #3: precision = 0
I0810 23:26:59.383754   463 solver.cpp:429]     Test net output #4: recall = 0
I0810 23:27:12.227710   463 solver.cpp:242] Iteration 6952 (0.595283 iter/s, 36.9572s/22 iter), loss = 2.45158
I0810 23:27:12.227766   463 solver.cpp:261]     Train net output #0: loss_bbox = 0.267845 (* 2 = 0.535691 loss)
I0810 23:27:12.227778   463 solver.cpp:261]     Train net output #1: loss_coverage = 1.91587 (* 1 = 1.91587 loss)
I0810 23:27:12.227794   463 sgd_solver.cpp:106] Iteration 6952, lr = 1e-06
I0810 23:27:37.907162   463 solver.cpp:242] Iteration 6974 (0.85671 iter/s, 25.6796s/22 iter), loss = 6.41688
I0810 23:27:37.907439   463 solver.cpp:261]     Train net output #0: loss_bbox = 0.629806 (* 2 = 1.25961 loss)
I0810 23:27:37.907459   463 solver.cpp:261]     Train net output #1: loss_coverage = 5.15726 (* 1 = 5.15726 loss)
I0810 23:27:37.907480   463 sgd_solver.cpp:106] Iteration 6974, lr = 1e-06
I0810 23:28:03.591419   463 solver.cpp:242] Iteration 6996 (0.856557 iter/s, 25.6842s/22 iter), loss = 6.65876
I0810 23:28:03.591480   463 solver.cpp:261]     Train net output #0: loss_bbox = 0.534753 (* 2 = 1.06951 loss)
I0810 23:28:03.591493   463 solver.cpp:261]     Train net output #1: loss_coverage = 5.58925 (* 1 = 5.58925 loss)
I0810 23:28:03.591511   463 sgd_solver.cpp:106] Iteration 6996, lr = 1e-06
I0810 23:28:29.273365   463 solver.cpp:242] Iteration 7018 (0.856628 iter/s, 25.6821s/22 iter), loss = 5.88698
I0810 23:28:29.273571   463 solver.cpp:261]     Train net output #0: loss_bbox = 0.508595 (* 2 = 1.01719 loss)
I0810 23:28:29.273610   463 solver.cpp:261]     Train net output #1: loss_coverage = 4.86978 (* 1 = 4.86978 loss)
I0810 23:28:29.273630   463 sgd_solver.cpp:106] Iteration 7018, lr = 1e-06
I0810 23:28:54.965173   463 solver.cpp:242] Iteration 7040 (0.856304 iter/s, 25.6918s/22 iter), loss = 2.48661
I0810 23:28:54.965229   463 solver.cpp:261]     Train net output #0: loss_bbox = 0.29384 (* 2 = 0.58768 loss)
I0810 23:28:54.965242   463 solver.cpp:261]     Train net output #1: loss_coverage = 1.89892 (* 1 = 1.89892 loss)
I0810 23:28:54.965258   463 sgd_solver.cpp:106] Iteration 7040, lr = 1e-06
I0810 23:29:20.698202   463 solver.cpp:242] Iteration 7062 (0.854927 iter/s, 25.7332s/22 iter), loss = 5.41637
I0810 23:29:20.698477   463 solver.cpp:261]     Train net output #0: loss_bbox = 0.492589 (* 2 = 0.985179 loss)
I0810 23:29:20.698495   463 solver.cpp:261]     Train net output #1: loss_coverage = 4.43118 (* 1 = 4.43118 loss)
I0810 23:29:20.698516   463 sgd_solver.cpp:106] Iteration 7062, lr = 1e-06
I0810 23:29:46.387259   463 solver.cpp:242] Iteration 7084 (0.856397 iter/s, 25.689s/22 iter), loss = 0.960174
I0810 23:29:46.387320   463 solver.cpp:261]     Train net output #0: loss_bbox = 0.0869251 (* 2 = 0.17385 loss)
I0810 23:29:46.387334   463 solver.cpp:261]     Train net output #1: loss_coverage = 0.786314 (* 1 = 0.786314 loss)
I0810 23:29:46.387351   463 sgd_solver.cpp:106] Iteration 7084, lr = 1e-06
I0810 23:30:12.061671   463 solver.cpp:242] Iteration 7106 (0.856879 iter/s, 25.6746s/22 iter), loss = 3.37179
I0810 23:30:12.061908   463 solver.cpp:261]     Train net output #0: loss_bbox = 0.442967 (* 2 = 0.885935 loss)
I0810 23:30:12.061928   463 solver.cpp:261]     Train net output #1: loss_coverage = 2.48584 (* 1 = 2.48584 loss)
I0810 23:30:12.061949   463 sgd_solver.cpp:106] Iteration 7106, lr = 1e-06
I0810 23:30:27.242651   463 solver.cpp:479] Snapshotting to binary proto file snapshot_iter_7120.caffemodel
I0810 23:30:27.349357   463 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshot_iter_7120.solverstate
I0810 23:30:27.407547   463 solver.cpp:362] Iteration 7120, Testing net (#0)
I0810 23:30:27.407588   463 net.cpp:723] Ignoring source layer train_data
I0810 23:30:27.407596   463 net.cpp:723] Ignoring source layer train_label
I0810 23:30:27.407601   463 net.cpp:723] Ignoring source layer train_transform
I0810 23:30:38.510550   463 solver.cpp:429]     Test net output #0: loss_bbox = 0.581863 (* 2 = 1.16373 loss)
I0810 23:30:38.510583   463 solver.cpp:429]     Test net output #1: loss_coverage = 5.17675 (* 1 = 5.17675 loss)
I0810 23:30:38.510592   463 solver.cpp:429]     Test net output #2: mAP = 0
I0810 23:30:38.510601   463 solver.cpp:429]     Test net output #3: precision = 0
I0810 23:30:38.510607   463 solver.cpp:429]     Test net output #4: recall = 0
I0810 23:30:49.013553   463 solver.cpp:242] Iteration 7128 (0.595367 iter/s, 36.952s/22 iter), loss = 7.83883
I0810 23:30:49.013792   463 solver.cpp:261]     Train net output #0: loss_bbox = 0.583143 (* 2 = 1.16629 loss)
I0810 23:30:49.013808   463 solver.cpp:261]     Train net output #1: loss_coverage = 6.67254 (* 1 = 6.67254 loss)
I0810 23:30:49.013826   463 sgd_solver.cpp:106] Iteration 7128, lr = 1e-06
I0810 23:31:14.704174   463 solver.cpp:242] Iteration 7150 (0.856344 iter/s, 25.6906s/22 iter), loss = 2.11486
I0810 23:31:14.704247   463 solver.cpp:261]     Train net output #0: loss_bbox = 0.203322 (* 2 = 0.406643 loss)
I0810 23:31:14.704262   463 solver.cpp:261]     Train net output #1: loss_coverage = 1.7082 (* 1 = 1.7082 loss)
I0810 23:31:14.704278   463 sgd_solver.cpp:106] Iteration 7150, lr = 1e-06
I0810 23:31:40.425220   463 solver.cpp:242] Iteration 7172 (0.855326 iter/s, 25.7212s/22 iter), loss = 2.59779
I0810 23:31:40.425572   463 solver.cpp:261]     Train net output #0: loss_bbox = 0.280605 (* 2 = 0.561211 loss)
I0810 23:31:40.425592   463 solver.cpp:261]     Train net output #1: loss_coverage = 2.03657 (* 1 = 2.03657 loss)
I0810 23:31:40.425614   463 sgd_solver.cpp:106] Iteration 7172, lr = 1e-06
I0810 23:32:06.127163   463 solver.cpp:242] Iteration 7194 (0.85597 iter/s, 25.7018s/22 iter), loss = 5.53562
I0810 23:32:06.127223   463 solver.cpp:261]     Train net output #0: loss_bbox = 0.544767 (* 2 = 1.08953 loss)
I0810 23:32:06.127235   463 solver.cpp:261]     Train net output #1: loss_coverage = 4.44607 (* 1 = 4.44607 loss)
I0810 23:32:06.127254   463 sgd_solver.cpp:106] Iteration 7194, lr = 1e-06
I0810 23:32:31.825747   463 solver.cpp:242] Iteration 7216 (0.856073 iter/s, 25.6987s/22 iter), loss = 5.20085
I0810 23:32:31.826160   463 solver.cpp:261]     Train net output #0: loss_bbox = 0.47853 (* 2 = 0.95706 loss)
I0810 23:32:31.826184   463 solver.cpp:261]     Train net output #1: loss_coverage = 4.24378 (* 1 = 4.24378 loss)
I0810 23:32:31.826207   463 sgd_solver.cpp:106] Iteration 7216, lr = 1e-06
I0810 23:32:57.493821   463 solver.cpp:242] Iteration 7238 (0.857102 iter/s, 25.6679s/22 iter), loss = 6.33648
I0810 23:32:57.493899   463 solver.cpp:261]     Train net output #0: loss_bbox = 0.516215 (* 2 = 1.03243 loss)
I0810 23:32:57.493914   463 solver.cpp:261]     Train net output #1: loss_coverage = 5.30404 (* 1 = 5.30404 loss)
I0810 23:32:57.493932   463 sgd_solver.cpp:106] Iteration 7238, lr = 1e-06
I0810 23:33:23.231494   463 solver.cpp:242] Iteration 7260 (0.854773 iter/s, 25.7378s/22 iter), loss = 7.50644
I0810 23:33:23.231706   463 solver.cpp:261]     Train net output #0: loss_bbox = 0.683998 (* 2 = 1.368 loss)
I0810 23:33:23.231724   463 solver.cpp:261]     Train net output #1: loss_coverage = 6.13844 (* 1 = 6.13844 loss)
I0810 23:33:23.231741   463 sgd_solver.cpp:106] Iteration 7260, lr = 1e-06
I0810 23:33:48.918146   463 solver.cpp:242] Iteration 7282 (0.856475 iter/s, 25.6867s/22 iter), loss = 4.16315
I0810 23:33:48.918206   463 solver.cpp:261]     Train net output #0: loss_bbox = 0.378015 (* 2 = 0.756031 loss)
I0810 23:33:48.918220   463 solver.cpp:261]     Train net output #1: loss_coverage = 3.40711 (* 1 = 3.40711 loss)
I0810 23:33:48.918237   463 sgd_solver.cpp:106] Iteration 7282, lr = 1e-06
I0810 23:34:06.449542   463 solver.cpp:479] Snapshotting to binary proto file snapshot_iter_7298.caffemodel
I0810 23:34:06.552870   463 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshot_iter_7298.solverstate
I0810 23:34:06.609031   463 solver.cpp:362] Iteration 7298, Testing net (#0)
I0810 23:34:06.609066   463 net.cpp:723] Ignoring source layer train_data
I0810 23:34:06.609076   463 net.cpp:723] Ignoring source layer train_label
I0810 23:34:06.609107   463 net.cpp:723] Ignoring source layer train_transform
I0810 23:34:17.717108   463 solver.cpp:429]     Test net output #0: loss_bbox = 0.585713 (* 2 = 1.17143 loss)
I0810 23:34:17.717150   463 solver.cpp:429]     Test net output #1: loss_coverage = 4.95236 (* 1 = 4.95236 loss)
I0810 23:34:17.717160   463 solver.cpp:429]     Test net output #2: mAP = 0
I0810 23:34:17.717167   463 solver.cpp:429]     Test net output #3: precision = 0
I0810 23:34:17.717175   463 solver.cpp:429]     Test net output #4: recall = 0
I0810 23:34:25.874047   463 solver.cpp:242] Iteration 7304 (0.5953 iter/s, 36.9562s/22 iter), loss = 5.31937
I0810 23:34:25.874130   463 solver.cpp:261]     Train net output #0: loss_bbox = 0.479914 (* 2 = 0.959829 loss)
I0810 23:34:25.874145   463 solver.cpp:261]     Train net output #1: loss_coverage = 4.35953 (* 1 = 4.35953 loss)
I0810 23:34:25.874161   463 sgd_solver.cpp:106] Iteration 7304, lr = 1e-06
I0810 23:34:51.570149   463 solver.cpp:242] Iteration 7326 (0.856156 iter/s, 25.6962s/22 iter), loss = 8.17606
I0810 23:34:51.570443   463 solver.cpp:261]     Train net output #0: loss_bbox = 0.6118 (* 2 = 1.2236 loss)
I0810 23:34:51.570463   463 solver.cpp:261]     Train net output #1: loss_coverage = 6.95245 (* 1 = 6.95245 loss)
I0810 23:34:51.570483   463 sgd_solver.cpp:106] Iteration 7326, lr = 1e-06
I0810 23:35:17.279345   463 solver.cpp:242] Iteration 7348 (0.855727 iter/s, 25.7091s/22 iter), loss = 2.68823
I0810 23:35:17.279407   463 solver.cpp:261]     Train net output #0: loss_bbox = 0.306029 (* 2 = 0.612058 loss)
I0810 23:35:17.279422   463 solver.cpp:261]     Train net output #1: loss_coverage = 2.07617 (* 1 = 2.07617 loss)
I0810 23:35:17.279438   463 sgd_solver.cpp:106] Iteration 7348, lr = 1e-06
I0810 23:35:42.953261   463 solver.cpp:242] Iteration 7370 (0.856896 iter/s, 25.6741s/22 iter), loss = 6.02736
I0810 23:35:42.953693   463 solver.cpp:261]     Train net output #0: loss_bbox = 0.472409 (* 2 = 0.944819 loss)
I0810 23:35:42.953711   463 solver.cpp:261]     Train net output #1: loss_coverage = 5.08254 (* 1 = 5.08254 loss)
I0810 23:35:42.953733   463 sgd_solver.cpp:106] Iteration 7370, lr = 1e-06
I0810 23:36:08.698338   463 solver.cpp:242] Iteration 7392 (0.854539 iter/s, 25.7449s/22 iter), loss = 6.52656
I0810 23:36:08.698400   463 solver.cpp:261]     Train net output #0: loss_bbox = 0.467616 (* 2 = 0.935231 loss)
I0810 23:36:08.698412   463 solver.cpp:261]     Train net output #1: loss_coverage = 5.59132 (* 1 = 5.59132 loss)
I0810 23:36:08.698429   463 sgd_solver.cpp:106] Iteration 7392, lr = 1e-06
I0810 23:36:34.438704   463 solver.cpp:242] Iteration 7414 (0.854683 iter/s, 25.7405s/22 iter), loss = 7.2573
I0810 23:36:34.438994   463 solver.cpp:261]     Train net output #0: loss_bbox = 0.634468 (* 2 = 1.26894 loss)
I0810 23:36:34.439014   463 solver.cpp:261]     Train net output #1: loss_coverage = 5.98835 (* 1 = 5.98835 loss)
I0810 23:36:34.439035   463 sgd_solver.cpp:106] Iteration 7414, lr = 1e-06
I0810 23:37:00.100119   463 solver.cpp:242] Iteration 7436 (0.85732 iter/s, 25.6614s/22 iter), loss = 4.5484
I0810 23:37:00.100203   463 solver.cpp:261]     Train net output #0: loss_bbox = 0.393669 (* 2 = 0.787338 loss)
I0810 23:37:00.100216   463 solver.cpp:261]     Train net output #1: loss_coverage = 3.76105 (* 1 = 3.76105 loss)
I0810 23:37:00.100231   463 sgd_solver.cpp:106] Iteration 7436, lr = 1e-06
I0810 23:37:25.795478   463 solver.cpp:242] Iteration 7458 (0.856181 iter/s, 25.6955s/22 iter), loss = 12.0963
I0810 23:37:25.795850   463 solver.cpp:261]     Train net output #0: loss_bbox = 0.686925 (* 2 = 1.37385 loss)
I0810 23:37:25.795871   463 solver.cpp:261]     Train net output #1: loss_coverage = 10.7224 (* 1 = 10.7224 loss)
I0810 23:37:25.795895   463 sgd_solver.cpp:106] Iteration 7458, lr = 1e-06
I0810 23:37:45.644600   463 solver.cpp:479] Snapshotting to binary proto file snapshot_iter_7476.caffemodel
I0810 23:37:45.746708   463 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshot_iter_7476.solverstate
I0810 23:37:45.801757   463 solver.cpp:362] Iteration 7476, Testing net (#0)
I0810 23:37:45.801789   463 net.cpp:723] Ignoring source layer train_data
I0810 23:37:45.801796   463 net.cpp:723] Ignoring source layer train_label
I0810 23:37:45.801801   463 net.cpp:723] Ignoring source layer train_transform
I0810 23:37:56.897933   463 solver.cpp:429]     Test net output #0: loss_bbox = 0.582361 (* 2 = 1.16472 loss)
I0810 23:37:56.898185   463 solver.cpp:429]     Test net output #1: loss_coverage = 4.71263 (* 1 = 4.71263 loss)
I0810 23:37:56.898196   463 solver.cpp:429]     Test net output #2: mAP = 0
I0810 23:37:56.898205   463 solver.cpp:429]     Test net output #3: precision = 0
I0810 23:37:56.898211   463 solver.cpp:429]     Test net output #4: recall = 0
I0810 23:38:02.724040   463 solver.cpp:242] Iteration 7480 (0.595745 iter/s, 36.9285s/22 iter), loss = 7.16028
I0810 23:38:02.724095   463 solver.cpp:261]     Train net output #0: loss_bbox = 0.605982 (* 2 = 1.21196 loss)
I0810 23:38:02.724108   463 solver.cpp:261]     Train net output #1: loss_coverage = 5.9483 (* 1 = 5.9483 loss)
I0810 23:38:02.724123   463 sgd_solver.cpp:106] Iteration 7480, lr = 1e-06
I0810 23:38:28.417636   463 solver.cpp:242] Iteration 7502 (0.856239 iter/s, 25.6938s/22 iter), loss = 3.00451
I0810 23:38:28.417930   463 solver.cpp:261]     Train net output #0: loss_bbox = 0.285811 (* 2 = 0.571622 loss)
I0810 23:38:28.417946   463 solver.cpp:261]     Train net output #1: loss_coverage = 2.43287 (* 1 = 2.43287 loss)
I0810 23:38:28.417964   463 sgd_solver.cpp:106] Iteration 7502, lr = 1e-06
I0810 23:38:54.104429   463 solver.cpp:242] Iteration 7524 (0.856474 iter/s, 25.6867s/22 iter), loss = 2.29765
I0810 23:38:54.104485   463 solver.cpp:261]     Train net output #0: loss_bbox = 0.251335 (* 2 = 0.502671 loss)
I0810 23:38:54.104498   463 solver.cpp:261]     Train net output #1: loss_coverage = 1.79497 (* 1 = 1.79497 loss)
I0810 23:38:54.104514   463 sgd_solver.cpp:106] Iteration 7524, lr = 1e-06
I0810 23:39:19.792582   463 solver.cpp:242] Iteration 7546 (0.856421 iter/s, 25.6883s/22 iter), loss = 6.47031
I0810 23:39:19.792872   463 solver.cpp:261]     Train net output #0: loss_bbox = 0.478292 (* 2 = 0.956583 loss)
I0810 23:39:19.792919   463 solver.cpp:261]     Train net output #1: loss_coverage = 5.51372 (* 1 = 5.51372 loss)
I0810 23:39:19.792948   463 sgd_solver.cpp:106] Iteration 7546, lr = 1e-06
I0810 23:39:45.496349   463 solver.cpp:242] Iteration 7568 (0.855908 iter/s, 25.7037s/22 iter), loss = 3.83252
I0810 23:39:45.496407   463 solver.cpp:261]     Train net output #0: loss_bbox = 0.39262 (* 2 = 0.785241 loss)
I0810 23:39:45.496419   463 solver.cpp:261]     Train net output #1: loss_coverage = 3.04727 (* 1 = 3.04727 loss)
I0810 23:39:45.496436   463 sgd_solver.cpp:106] Iteration 7568, lr = 1e-06
I0810 23:40:11.210439   463 solver.cpp:242] Iteration 7590 (0.855557 iter/s, 25.7143s/22 iter), loss = 6.15185
I0810 23:40:11.210698   463 solver.cpp:261]     Train net output #0: loss_bbox = 0.603432 (* 2 = 1.20686 loss)
I0810 23:40:11.210717   463 solver.cpp:261]     Train net output #1: loss_coverage = 4.94498 (* 1 = 4.94498 loss)
I0810 23:40:11.210738   463 sgd_solver.cpp:106] Iteration 7590, lr = 1e-06
I0810 23:40:36.914533   463 solver.cpp:242] Iteration 7612 (0.855896 iter/s, 25.7041s/22 iter), loss = 4.46018
I0810 23:40:36.914610   463 solver.cpp:261]     Train net output #0: loss_bbox = 0.432199 (* 2 = 0.864399 loss)
I0810 23:40:36.914626   463 solver.cpp:261]     Train net output #1: loss_coverage = 3.59578 (* 1 = 3.59578 loss)
I0810 23:40:36.914645   463 sgd_solver.cpp:106] Iteration 7612, lr = 1e-06
I0810 23:41:02.633916   463 solver.cpp:242] Iteration 7634 (0.855381 iter/s, 25.7195s/22 iter), loss = 6.34976
I0810 23:41:02.634249   463 solver.cpp:261]     Train net output #0: loss_bbox = 0.538523 (* 2 = 1.07705 loss)
I0810 23:41:02.634266   463 solver.cpp:261]     Train net output #1: loss_coverage = 5.27271 (* 1 = 5.27271 loss)
I0810 23:41:02.634285   463 sgd_solver.cpp:106] Iteration 7634, lr = 1e-06
I0810 23:41:24.823704   463 solver.cpp:479] Snapshotting to binary proto file snapshot_iter_7654.caffemodel
I0810 23:41:24.923560   463 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshot_iter_7654.solverstate
I0810 23:41:24.978688   463 solver.cpp:362] Iteration 7654, Testing net (#0)
I0810 23:41:24.978718   463 net.cpp:723] Ignoring source layer train_data
I0810 23:41:24.978726   463 net.cpp:723] Ignoring source layer train_label
I0810 23:41:24.978732   463 net.cpp:723] Ignoring source layer train_transform
I0810 23:41:36.139575   463 solver.cpp:429]     Test net output #0: loss_bbox = 0.580834 (* 2 = 1.16167 loss)
I0810 23:41:36.139798   463 solver.cpp:429]     Test net output #1: loss_coverage = 5.07674 (* 1 = 5.07674 loss)
I0810 23:41:36.139816   463 solver.cpp:429]     Test net output #2: mAP = 0
I0810 23:41:36.139828   463 solver.cpp:429]     Test net output #3: precision = 0
I0810 23:41:36.139839   463 solver.cpp:429]     Test net output #4: recall = 0
I0810 23:41:39.642385   463 solver.cpp:242] Iteration 7656 (0.594458 iter/s, 37.0085s/22 iter), loss = 5.4214
I0810 23:41:39.642442   463 solver.cpp:261]     Train net output #0: loss_bbox = 0.52653 (* 2 = 1.05306 loss)
I0810 23:41:39.642457   463 solver.cpp:261]     Train net output #1: loss_coverage = 4.36833 (* 1 = 4.36833 loss)
I0810 23:41:39.642473   463 sgd_solver.cpp:106] Iteration 7656, lr = 1e-06
I0810 23:42:05.390122   463 solver.cpp:242] Iteration 7678 (0.854439 iter/s, 25.7479s/22 iter), loss = 3.9035
I0810 23:42:05.390192   463 solver.cpp:261]     Train net output #0: loss_bbox = 0.346061 (* 2 = 0.692122 loss)
I0810 23:42:05.390206   463 solver.cpp:261]     Train net output #1: loss_coverage = 3.21137 (* 1 = 3.21137 loss)
I0810 23:42:05.390226   463 sgd_solver.cpp:106] Iteration 7678, lr = 1e-06
I0810 23:42:31.114666   463 solver.cpp:242] Iteration 7700 (0.855209 iter/s, 25.7247s/22 iter), loss = 4.338
I0810 23:42:31.114960   463 solver.cpp:261]     Train net output #0: loss_bbox = 0.491932 (* 2 = 0.983864 loss)
I0810 23:42:31.114977   463 solver.cpp:261]     Train net output #1: loss_coverage = 3.35412 (* 1 = 3.35412 loss)
I0810 23:42:31.114996   463 sgd_solver.cpp:106] Iteration 7700, lr = 1e-06
I0810 23:42:56.798774   463 solver.cpp:242] Iteration 7722 (0.856563 iter/s, 25.684s/22 iter), loss = 6.35282
I0810 23:42:56.798843   463 solver.cpp:261]     Train net output #0: loss_bbox = 0.431239 (* 2 = 0.862477 loss)
I0810 23:42:56.798856   463 solver.cpp:261]     Train net output #1: loss_coverage = 5.49033 (* 1 = 5.49033 loss)
I0810 23:42:56.798874   463 sgd_solver.cpp:106] Iteration 7722, lr = 1e-06
I0810 23:43:22.554119   463 solver.cpp:242] Iteration 7744 (0.854187 iter/s, 25.7555s/22 iter), loss = 5.75108
I0810 23:43:22.554415   463 solver.cpp:261]     Train net output #0: loss_bbox = 0.523088 (* 2 = 1.04618 loss)
I0810 23:43:22.554431   463 solver.cpp:261]     Train net output #1: loss_coverage = 4.7049 (* 1 = 4.7049 loss)
I0810 23:43:22.554450   463 sgd_solver.cpp:106] Iteration 7744, lr = 1e-06
I0810 23:43:48.280663   463 solver.cpp:242] Iteration 7766 (0.85515 iter/s, 25.7265s/22 iter), loss = 2.48026
I0810 23:43:48.280719   463 solver.cpp:261]     Train net output #0: loss_bbox = 0.306691 (* 2 = 0.613383 loss)
I0810 23:43:48.280732   463 solver.cpp:261]     Train net output #1: loss_coverage = 1.86687 (* 1 = 1.86687 loss)
I0810 23:43:48.280748   463 sgd_solver.cpp:106] Iteration 7766, lr = 1e-06
I0810 23:44:13.983801   463 solver.cpp:242] Iteration 7788 (0.855921 iter/s, 25.7033s/22 iter), loss = 7.25125
I0810 23:44:13.984122   463 solver.cpp:261]     Train net output #0: loss_bbox = 0.65102 (* 2 = 1.30204 loss)
I0810 23:44:13.984143   463 solver.cpp:261]     Train net output #1: loss_coverage = 5.94921 (* 1 = 5.94921 loss)
I0810 23:44:13.984164   463 sgd_solver.cpp:106] Iteration 7788, lr = 1e-06
I0810 23:44:39.698101   463 solver.cpp:242] Iteration 7810 (0.855559 iter/s, 25.7142s/22 iter), loss = 6.65261
I0810 23:44:39.698161   463 solver.cpp:261]     Train net output #0: loss_bbox = 0.528755 (* 2 = 1.05751 loss)
I0810 23:44:39.698175   463 solver.cpp:261]     Train net output #1: loss_coverage = 5.59509 (* 1 = 5.59509 loss)
I0810 23:44:39.698192   463 sgd_solver.cpp:106] Iteration 7810, lr = 1e-06
I0810 23:45:04.223423   463 solver.cpp:479] Snapshotting to binary proto file snapshot_iter_7832.caffemodel
I0810 23:45:04.330502   463 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshot_iter_7832.solverstate
I0810 23:45:04.389292   463 solver.cpp:362] Iteration 7832, Testing net (#0)
I0810 23:45:04.389327   463 net.cpp:723] Ignoring source layer train_data
I0810 23:45:04.389334   463 net.cpp:723] Ignoring source layer train_label
I0810 23:45:04.389340   463 net.cpp:723] Ignoring source layer train_transform
I0810 23:45:15.496526   463 solver.cpp:429]     Test net output #0: loss_bbox = 0.579062 (* 2 = 1.15812 loss)
I0810 23:45:15.496562   463 solver.cpp:429]     Test net output #1: loss_coverage = 4.76032 (* 1 = 4.76032 loss)
I0810 23:45:15.496570   463 solver.cpp:429]     Test net output #2: mAP = 0
I0810 23:45:15.496577   463 solver.cpp:429]     Test net output #3: precision = 0
I0810 23:45:15.496585   463 solver.cpp:429]     Test net output #4: recall = 0
I0810 23:45:16.654474   463 solver.cpp:242] Iteration 7832 (0.595292 iter/s, 36.9566s/22 iter), loss = 3.21248
I0810 23:45:16.654539   463 solver.cpp:261]     Train net output #0: loss_bbox = 0.318512 (* 2 = 0.637024 loss)
I0810 23:45:16.654553   463 solver.cpp:261]     Train net output #1: loss_coverage = 2.57544 (* 1 = 2.57544 loss)
I0810 23:45:16.654572   463 sgd_solver.cpp:106] Iteration 7832, lr = 1e-06
I0810 23:45:42.352246   463 solver.cpp:242] Iteration 7854 (0.8561 iter/s, 25.6979s/22 iter), loss = 8.85837
I0810 23:45:42.352550   463 solver.cpp:261]     Train net output #0: loss_bbox = 0.60137 (* 2 = 1.20274 loss)
I0810 23:45:42.352566   463 solver.cpp:261]     Train net output #1: loss_coverage = 7.65562 (* 1 = 7.65562 loss)
I0810 23:45:42.352583   463 sgd_solver.cpp:106] Iteration 7854, lr = 1e-06
